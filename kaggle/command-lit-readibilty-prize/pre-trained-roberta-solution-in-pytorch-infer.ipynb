{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-unknown",
   "metadata": {
    "papermill": {
     "duration": 0.020521,
     "end_time": "2021-08-01T11:15:12.133110",
     "exception": false,
     "start_time": "2021-08-01T11:15:12.112589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "This is kernel is almost the same as [Lightweight Roberta solution in PyTorch](https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch), but instead of \"roberta-base\", it starts from [Maunish's pre-trained model](https://www.kaggle.com/maunish/clrp-roberta-base).\n",
    "\n",
    "Acknowledgments: some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pacific-georgia",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:12.187261Z",
     "iopub.status.busy": "2021-08-01T11:15:12.185709Z",
     "iopub.status.idle": "2021-08-01T11:15:21.529142Z",
     "shell.execute_reply": "2021-08-01T11:15:21.528368Z",
     "shell.execute_reply.started": "2021-07-29T12:57:49.093769Z"
    },
    "papermill": {
     "duration": 9.37712,
     "end_time": "2021-08-01T11:15:21.529374",
     "exception": false,
     "start_time": "2021-08-01T11:15:12.152254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "religious-source",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:21.574895Z",
     "iopub.status.busy": "2021-08-01T11:15:21.573785Z",
     "iopub.status.idle": "2021-08-01T11:15:21.632478Z",
     "shell.execute_reply": "2021-08-01T11:15:21.631826Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.095645Z"
    },
    "papermill": {
     "duration": 0.081951,
     "end_time": "2021-08-01T11:15:21.632621",
     "exception": false,
     "start_time": "2021-08-01T11:15:21.550670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 6#5\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 300#248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/pytorch_model.bin\"#\"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "TOKENIZER_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/\"\n",
    "CONFIG_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/config.json\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painful-warehouse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:21.678466Z",
     "iopub.status.busy": "2021-08-01T11:15:21.677459Z",
     "iopub.status.idle": "2021-08-01T11:15:21.681055Z",
     "shell.execute_reply": "2021-08-01T11:15:21.680534Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.149149Z"
    },
    "papermill": {
     "duration": 0.028859,
     "end_time": "2021-08-01T11:15:21.681202",
     "exception": false,
     "start_time": "2021-08-01T11:15:21.652343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "refined-branch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:21.727094Z",
     "iopub.status.busy": "2021-08-01T11:15:21.726403Z",
     "iopub.status.idle": "2021-08-01T11:15:21.856002Z",
     "shell.execute_reply": "2021-08-01T11:15:21.855405Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.158011Z"
    },
    "papermill": {
     "duration": 0.155589,
     "end_time": "2021-08-01T11:15:21.856197",
     "exception": false,
     "start_time": "2021-08-01T11:15:21.700608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\n",
    "\n",
    "# Remove incomplete entries if any.\n",
    "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
    "              inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "resistant-temple",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:21.899758Z",
     "iopub.status.busy": "2021-08-01T11:15:21.899082Z",
     "iopub.status.idle": "2021-08-01T11:15:22.108817Z",
     "shell.execute_reply": "2021-08-01T11:15:22.108189Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.27276Z"
    },
    "papermill": {
     "duration": 0.233372,
     "end_time": "2021-08-01T11:15:22.109014",
     "exception": false,
     "start_time": "2021-08-01T11:15:21.875642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-frost",
   "metadata": {
    "papermill": {
     "duration": 0.019266,
     "end_time": "2021-08-01T11:15:22.148102",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.128836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suburban-ratio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.198765Z",
     "iopub.status.busy": "2021-08-01T11:15:22.196453Z",
     "iopub.status.idle": "2021-08-01T11:15:22.199664Z",
     "shell.execute_reply": "2021-08-01T11:15:22.200410Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.416933Z"
    },
    "papermill": {
     "duration": 0.03305,
     "end_time": "2021-08-01T11:15:22.200586",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.167536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-permission",
   "metadata": {
    "papermill": {
     "duration": 0.019705,
     "end_time": "2021-08-01T11:15:22.239929",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.220224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expired-workplace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.284838Z",
     "iopub.status.busy": "2021-08-01T11:15:22.284120Z",
     "iopub.status.idle": "2021-08-01T11:15:22.288868Z",
     "shell.execute_reply": "2021-08-01T11:15:22.289400Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.4305Z"
    },
    "papermill": {
     "duration": 0.02978,
     "end_time": "2021-08-01T11:15:22.289556",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.259776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LitModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "#         config.update({\"output_hidden_states\":True, \n",
    "#                        \"hidden_dropout_prob\": 0.0,\n",
    "#                        \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "#         self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "#         self.attention = nn.Sequential(            \n",
    "#             nn.Linear(768, 512),            \n",
    "#             nn.Tanh(),                       \n",
    "#             nn.Linear(512, 1),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )        \n",
    "\n",
    "#         self.regressor = nn.Sequential(                        \n",
    "#             nn.Linear(768, 1)                        \n",
    "#         )\n",
    "        \n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         roberta_output = self.roberta(input_ids=input_ids,\n",
    "#                                       attention_mask=attention_mask)        \n",
    "\n",
    "#         # There are a total of 13 layers of hidden states.\n",
    "#         # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "#         # We take the hidden states from the last Roberta layer.\n",
    "#         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "#         # The number of cells is MAX_LEN.\n",
    "#         # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "#         # In order to condense hidden states of all cells to a context vector,\n",
    "#         # we compute a weighted average of the hidden states of all cells.\n",
    "#         # We compute the weight of each cell, using the attention neural network.\n",
    "#         weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "#         # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "#         # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "#         # Now we compute context_vector as the weighted average.\n",
    "#         # context_vector.shape is BATCH_SIZE x 768\n",
    "#         context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "#         # Now we reduce the context vector to the prediction score.\n",
    "#         return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elect-notice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.341874Z",
     "iopub.status.busy": "2021-08-01T11:15:22.340592Z",
     "iopub.status.idle": "2021-08-01T11:15:22.344053Z",
     "shell.execute_reply": "2021-08-01T11:15:22.343405Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.442038Z"
    },
    "papermill": {
     "duration": 0.035256,
     "end_time": "2021-08-01T11:15:22.344198",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.308942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2103.04083v1.pdf\n",
    "class LitModel(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "#                        \"attention_probs_dropout_prob\":0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "#         self.cnn1 = nn.Conv1d(768, MAX_LEN, kernel_size=1)\n",
    "#         self.cnn2 = nn.Conv1d(MAX_LEN, 1, kernel_size=1)\n",
    "        self.cnn1 = nn.Conv1d(768, 512, kernel_size=1)\n",
    "        self.cnn2 = nn.Conv1d(512, MAX_LEN, kernel_size=1)\n",
    "         \n",
    "#         self.layernorm = nn.LayerNorm(MAX_LEN,MAX_LEN)    \n",
    "        self.layernorm = nn.LayerNorm(MAX_LEN)\n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(MAX_LEN, MAX_LEN),            \n",
    "            nn.Tanh(),  \n",
    "            nn.Linear(MAX_LEN, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(      \n",
    "#             nn.LayerNorm(768),\n",
    "            nn.Linear(MAX_LEN, 1),          \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)   \n",
    "        last_hidden_state = roberta_output.hidden_states[-1]\n",
    "#         print(last_hidden_state.shape)\n",
    "        last_hidden_state = last_hidden_state.permute(0, 2, 1)#16*768*MAX_LEN\n",
    "#         print(last_hidden_state.shape)\n",
    "        cnn_embeddings = F.relu(self.cnn1(last_hidden_state))#16*512*MAX_LEN\n",
    "#         print(cnn_embeddings.shape)\n",
    "        cnn_embeddings = self.cnn2(cnn_embeddings)#16*MAX_LEN(embedding)*MAX_LEN(tokens)\n",
    "#         print(cnn_embeddings.shape)\n",
    "        cnn_embeddings = cnn_embeddings.permute(0, 2, 1)\n",
    "#         cnn_embeddings = self.layernorm(cnn_embeddings)\n",
    "#         print(cnn_embeddings.shape)\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "#         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "        \n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "#         print(cnn_embeddings.shape)\n",
    "        weights = self.attention(cnn_embeddings)#16*MAX_LEN*1\n",
    "#         print('weights.shape',weights.shape)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * cnn_embeddings, dim=1)#16*MAX_LEN   \n",
    "#         print('context_vector',context_vector.shape)\n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)#16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "level-champion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.391426Z",
     "iopub.status.busy": "2021-08-01T11:15:22.390277Z",
     "iopub.status.idle": "2021-08-01T11:15:22.393504Z",
     "shell.execute_reply": "2021-08-01T11:15:22.394017Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.457266Z"
    },
    "papermill": {
     "duration": 0.030062,
     "end_time": "2021-08-01T11:15:22.394183",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.364121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "junior-sessions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.441272Z",
     "iopub.status.busy": "2021-08-01T11:15:22.440190Z",
     "iopub.status.idle": "2021-08-01T11:15:22.443894Z",
     "shell.execute_reply": "2021-08-01T11:15:22.443329Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.469844Z"
    },
    "papermill": {
     "duration": 0.030473,
     "end_time": "2021-08-01T11:15:22.444037",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.413564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fatty-burton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.496737Z",
     "iopub.status.busy": "2021-08-01T11:15:22.495704Z",
     "iopub.status.idle": "2021-08-01T11:15:22.499336Z",
     "shell.execute_reply": "2021-08-01T11:15:22.498782Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.481478Z"
    },
    "papermill": {
     "duration": 0.035336,
     "end_time": "2021-08-01T11:15:22.499471",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.464135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, model_path, train_loader, val_loader,\n",
    "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
    "    best_val_rmse = None\n",
    "    best_epoch = 0\n",
    "    step = 0\n",
    "    last_eval_step = 0\n",
    "    eval_period = EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):                           \n",
    "        val_rmse = None         \n",
    "\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)            \n",
    "            target = target.to(DEVICE)                        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            pred = model(input_ids, attention_mask)\n",
    "                                                        \n",
    "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
    "                        \n",
    "            mse.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            if step >= last_eval_step + eval_period:\n",
    "                # Evaluate the model on val_loader.\n",
    "                elapsed_seconds = time.time() - start\n",
    "                num_steps = step - last_eval_step\n",
    "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                last_eval_step = step\n",
    "                \n",
    "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
    "\n",
    "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
    "                      f\"val_rmse: {val_rmse:0.4}\")\n",
    "\n",
    "                for rmse, period in EVAL_SCHEDULE:\n",
    "                    if val_rmse >= rmse:\n",
    "                        eval_period = period\n",
    "                        break                               \n",
    "                \n",
    "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
    "                    best_val_rmse = val_rmse\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "                else:       \n",
    "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "                          f\"(from epoch {best_epoch})\")                                    \n",
    "                    \n",
    "                start = time.time()\n",
    "                                            \n",
    "            step += 1\n",
    "                        \n",
    "    \n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "figured-equivalent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.550780Z",
     "iopub.status.busy": "2021-08-01T11:15:22.549728Z",
     "iopub.status.idle": "2021-08-01T11:15:22.553587Z",
     "shell.execute_reply": "2021-08-01T11:15:22.552904Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.498784Z"
    },
    "papermill": {
     "duration": 0.031311,
     "end_time": "2021-08-01T11:15:22.553714",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.522403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    named_parameters = list(model.named_parameters())    \n",
    "    \n",
    "    roberta_parameters = named_parameters[:197]    \n",
    "    attention_parameters = named_parameters[199:203]\n",
    "    regressor_parameters = named_parameters[203:]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "\n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group})\n",
    "    parameters.append({\"params\": regressor_group})\n",
    "\n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
    "\n",
    "        lr = 2e-5\n",
    "\n",
    "        if layer_num >= 69:        \n",
    "            lr = 5e-5\n",
    "\n",
    "        if layer_num >= 133:\n",
    "            lr = 1e-4\n",
    "\n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "\n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unauthorized-crystal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.598485Z",
     "iopub.status.busy": "2021-08-01T11:15:22.597290Z",
     "iopub.status.idle": "2021-08-01T11:15:22.600908Z",
     "shell.execute_reply": "2021-08-01T11:15:22.600295Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.513052Z"
    },
    "papermill": {
     "duration": 0.027758,
     "end_time": "2021-08-01T11:15:22.601041",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.573283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gc.collect()\n",
    "\n",
    "# SEED = 1000\n",
    "# list_val_rmse = []\n",
    "\n",
    "# kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "# for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
    "#     print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
    "#     model_path = f\"model_{fold + 1}.pth\"\n",
    "        \n",
    "#     set_random_seed(SEED + fold)\n",
    "    \n",
    "#     train_dataset = LitDataset(train_df.loc[train_indices])    \n",
    "#     val_dataset = LitDataset(train_df.loc[val_indices])    \n",
    "        \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "#                               drop_last=True, shuffle=True, num_workers=2)    \n",
    "#     val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "#                             drop_last=False, shuffle=False, num_workers=2)    \n",
    "        \n",
    "#     set_random_seed(SEED + fold)    \n",
    "    \n",
    "#     model = LitModel().to(DEVICE)\n",
    "    \n",
    "#     optimizer = create_optimizer(model)                        \n",
    "#     scheduler = get_cosine_schedule_with_warmup(\n",
    "#         optimizer,\n",
    "#         num_training_steps=NUM_EPOCHS * len(train_loader),\n",
    "#         num_warmup_steps=50)    \n",
    "    \n",
    "#     list_val_rmse.append(train(model, model_path, train_loader,\n",
    "#                                val_loader, optimizer, scheduler=scheduler))\n",
    "\n",
    "#     del model\n",
    "#     gc.collect()\n",
    "    \n",
    "#     print(\"\\nPerformance estimates:\")\n",
    "#     print(list_val_rmse)\n",
    "#     print(\"Mean:\", np.array(list_val_rmse).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-vacuum",
   "metadata": {
    "papermill": {
     "duration": 0.019758,
     "end_time": "2021-08-01T11:15:22.640584",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.620826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "biological-undergraduate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.686106Z",
     "iopub.status.busy": "2021-08-01T11:15:22.685416Z",
     "iopub.status.idle": "2021-08-01T11:15:22.704312Z",
     "shell.execute_reply": "2021-08-01T11:15:22.703703Z",
     "shell.execute_reply.started": "2021-07-29T12:57:01.523565Z"
    },
    "papermill": {
     "duration": 0.044444,
     "end_time": "2021-08-01T11:15:22.704443",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.659999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = LitDataset(test_df, inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "institutional-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:15:22.756062Z",
     "iopub.status.busy": "2021-08-01T11:15:22.754467Z",
     "iopub.status.idle": "2021-08-01T11:16:34.502495Z",
     "shell.execute_reply": "2021-08-01T11:16:34.503116Z",
     "shell.execute_reply.started": "2021-07-29T12:57:55.630223Z"
    },
    "papermill": {
     "duration": 71.779339,
     "end_time": "2021-08-01T11:16:34.503333",
     "exception": false,
     "start_time": "2021-08-01T11:15:22.723994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_2.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_3.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_4.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_5.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_6.pth\n"
     ]
    }
   ],
   "source": [
    "all_predictions = np.zeros((NUM_FOLDS, len(test_df)))\n",
    "\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "for index in range(NUM_FOLDS):            \n",
    "    model_path = f\"../input/pre-trained-roberta-solution-in-pytorch-train/model_{index + 1}.pth\" #../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_predictions[index] = predict(model, test_loader)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "human-failing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:16:34.552125Z",
     "iopub.status.busy": "2021-08-01T11:16:34.551179Z",
     "iopub.status.idle": "2021-08-01T11:16:34.555825Z",
     "shell.execute_reply": "2021-08-01T11:16:34.555269Z",
     "shell.execute_reply.started": "2021-07-29T12:58:28.324629Z"
    },
    "papermill": {
     "duration": 0.030587,
     "end_time": "2021-08-01T11:16:34.555970",
     "exception": false,
     "start_time": "2021-08-01T11:16:34.525383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = all_predictions.mean(axis=0)\n",
    "# submission_df.target = predictions\n",
    "# print(submission_df)\n",
    "# submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "israeli-middle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T11:16:34.612245Z",
     "iopub.status.busy": "2021-08-01T11:16:34.611510Z",
     "iopub.status.idle": "2021-08-01T11:16:34.784673Z",
     "shell.execute_reply": "2021-08-01T11:16:34.783730Z",
     "shell.execute_reply.started": "2021-07-29T12:58:28.331629Z"
    },
    "papermill": {
     "duration": 0.20732,
     "end_time": "2021-08-01T11:16:34.784941",
     "exception": false,
     "start_time": "2021-08-01T11:16:34.577621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.534043\n",
      "1  f0953f0a5 -0.554323\n",
      "2  0df072751 -0.468059\n",
      "3  04caf4e0c -2.560002\n",
      "4  0e63f8bea -1.818977\n",
      "5  12537fe78 -1.439899\n",
      "6  965e592c0  0.249321\n"
     ]
    }
   ],
   "source": [
    "test_df['target']=predictions\n",
    "# submission_df.target = predictions\n",
    "cols_to_keep=['id','target']\n",
    "print(test_df[cols_to_keep])\n",
    "test_df.loc[:, cols_to_keep].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-reconstruction",
   "metadata": {
    "papermill": {
     "duration": 0.021954,
     "end_time": "2021-08-01T11:16:34.828885",
     "exception": false,
     "start_time": "2021-08-01T11:16:34.806931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.946221,
   "end_time": "2021-08-01T11:16:37.486252",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-01T11:15:03.540031",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
