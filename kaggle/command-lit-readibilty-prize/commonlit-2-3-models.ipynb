{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-advice",
   "metadata": {
    "papermill": {
     "duration": 0.025067,
     "end_time": "2021-08-01T12:52:46.074844",
     "exception": false,
     "start_time": "2021-08-01T12:52:46.049777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook combines two models:\n",
    "\n",
    "Score 0.467: [https://www.kaggle.com/andretugan/pre-trained-roberta-solution-in-pytorch](https://www.kaggle.com/andretugan/pre-trained-roberta-solution-in-pytorch)\n",
    "\n",
    "Score 0.468: [https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3](https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-bride",
   "metadata": {
    "papermill": {
     "duration": 0.023553,
     "end_time": "2021-08-01T12:52:46.122836",
     "exception": false,
     "start_time": "2021-08-01T12:52:46.099283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forbidden-identification",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:46.181867Z",
     "iopub.status.busy": "2021-08-01T12:52:46.181318Z",
     "iopub.status.idle": "2021-08-01T12:52:48.641246Z",
     "shell.execute_reply": "2021-08-01T12:52:48.640620Z",
     "shell.execute_reply.started": "2021-07-27T03:57:05.15991Z"
    },
    "papermill": {
     "duration": 2.494765,
     "end_time": "2021-08-01T12:52:48.641388",
     "exception": false,
     "start_time": "2021-08-01T12:52:46.146623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "refined-mauritius",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:48.730938Z",
     "iopub.status.busy": "2021-08-01T12:52:48.730311Z",
     "iopub.status.idle": "2021-08-01T12:52:48.733643Z",
     "shell.execute_reply": "2021-08-01T12:52:48.732927Z",
     "shell.execute_reply.started": "2021-07-27T03:57:08.968218Z"
    },
    "papermill": {
     "duration": 0.068469,
     "end_time": "2021-08-01T12:52:48.733757",
     "exception": false,
     "start_time": "2021-08-01T12:52:48.665288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"/kaggle/input/roberta-base\"\n",
    "TOKENIZER_PATH = \"/kaggle/input/roberta-base\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hydraulic-lobby",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:48.785924Z",
     "iopub.status.busy": "2021-08-01T12:52:48.785326Z",
     "iopub.status.idle": "2021-08-01T12:52:48.800806Z",
     "shell.execute_reply": "2021-08-01T12:52:48.800393Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.06681Z"
    },
    "papermill": {
     "duration": 0.0434,
     "end_time": "2021-08-01T12:52:48.800911",
     "exception": false,
     "start_time": "2021-08-01T12:52:48.757511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interesting-tourism",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:48.851453Z",
     "iopub.status.busy": "2021-08-01T12:52:48.850903Z",
     "iopub.status.idle": "2021-08-01T12:52:49.099291Z",
     "shell.execute_reply": "2021-08-01T12:52:49.100222Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.096558Z"
    },
    "papermill": {
     "duration": 0.276021,
     "end_time": "2021-08-01T12:52:49.100432",
     "exception": false,
     "start_time": "2021-08-01T12:52:48.824411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-thing",
   "metadata": {
    "papermill": {
     "duration": 0.041046,
     "end_time": "2021-08-01T12:52:49.180938",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.139892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "burning-opportunity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:49.271810Z",
     "iopub.status.busy": "2021-08-01T12:52:49.271285Z",
     "iopub.status.idle": "2021-08-01T12:52:49.275877Z",
     "shell.execute_reply": "2021-08-01T12:52:49.275143Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.331903Z"
    },
    "papermill": {
     "duration": 0.054887,
     "end_time": "2021-08-01T12:52:49.276042",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.221155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-annotation",
   "metadata": {
    "papermill": {
     "duration": 0.03844,
     "end_time": "2021-08-01T12:52:49.353250",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.314810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organic-proportion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:49.442354Z",
     "iopub.status.busy": "2021-08-01T12:52:49.441140Z",
     "iopub.status.idle": "2021-08-01T12:52:49.446062Z",
     "shell.execute_reply": "2021-08-01T12:52:49.447073Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.345174Z"
    },
    "papermill": {
     "duration": 0.055238,
     "end_time": "2021-08-01T12:52:49.447255",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.392017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(768, 512),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(                        \n",
    "            nn.Linear(768, 1)                        \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "revolutionary-suggestion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:49.530765Z",
     "iopub.status.busy": "2021-08-01T12:52:49.529481Z",
     "iopub.status.idle": "2021-08-01T12:52:49.532202Z",
     "shell.execute_reply": "2021-08-01T12:52:49.531779Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.363429Z"
    },
    "papermill": {
     "duration": 0.044015,
     "end_time": "2021-08-01T12:52:49.532307",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.488292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-england",
   "metadata": {
    "papermill": {
     "duration": 0.023703,
     "end_time": "2021-08-01T12:52:49.579934",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.556231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "behavioral-extra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:49.635448Z",
     "iopub.status.busy": "2021-08-01T12:52:49.634690Z",
     "iopub.status.idle": "2021-08-01T12:52:49.644837Z",
     "shell.execute_reply": "2021-08-01T12:52:49.644444Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.382672Z"
    },
    "papermill": {
     "duration": 0.041182,
     "end_time": "2021-08-01T12:52:49.644940",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.603758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = LitDataset(test_df, inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "massive-lotus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:52:49.701781Z",
     "iopub.status.busy": "2021-08-01T12:52:49.701051Z",
     "iopub.status.idle": "2021-08-01T12:53:37.769948Z",
     "shell.execute_reply": "2021-08-01T12:53:37.769432Z",
     "shell.execute_reply.started": "2021-07-27T03:57:09.412822Z"
    },
    "papermill": {
     "duration": 48.101038,
     "end_time": "2021-08-01T12:53:37.770083",
     "exception": false,
     "start_time": "2021-08-01T12:52:49.669045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/commonlit-roberta-0467/model_1.pth\n",
      "\n",
      "Using ../input/commonlit-roberta-0467/model_2.pth\n",
      "\n",
      "Using ../input/commonlit-roberta-0467/model_3.pth\n",
      "\n",
      "Using ../input/commonlit-roberta-0467/model_4.pth\n",
      "\n",
      "Using ../input/commonlit-roberta-0467/model_5.pth\n"
     ]
    }
   ],
   "source": [
    "NUM_MODELS = 5\n",
    "\n",
    "all_predictions = np.zeros((NUM_MODELS, len(test_df)))\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "for model_index in range(NUM_MODELS):            \n",
    "    model_path = f\"../input/commonlit-roberta-0467/model_{model_index + 1}.pth\"\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))    \n",
    "    model.to(DEVICE)\n",
    "        \n",
    "    all_predictions[model_index] = predict(model, test_loader)\n",
    "            \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "authentic-dress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:53:37.851862Z",
     "iopub.status.busy": "2021-08-01T12:53:37.851129Z",
     "iopub.status.idle": "2021-08-01T12:53:37.854792Z",
     "shell.execute_reply": "2021-08-01T12:53:37.854321Z",
     "shell.execute_reply.started": "2021-07-27T03:58:10.410343Z"
    },
    "papermill": {
     "duration": 0.058464,
     "end_time": "2021-08-01T12:53:37.854919",
     "exception": false,
     "start_time": "2021-08-01T12:53:37.796455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_predictions = all_predictions.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-glossary",
   "metadata": {
    "papermill": {
     "duration": 0.026289,
     "end_time": "2021-08-01T12:53:37.906746",
     "exception": false,
     "start_time": "2021-08-01T12:53:37.880457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2\n",
    "Imported from [https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3](https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coated-person",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:53:37.993195Z",
     "iopub.status.busy": "2021-08-01T12:53:37.976554Z",
     "iopub.status.idle": "2021-08-01T12:58:06.167575Z",
     "shell.execute_reply": "2021-08-01T12:58:06.168156Z",
     "shell.execute_reply.started": "2021-07-27T03:58:10.41995Z"
    },
    "papermill": {
     "duration": 268.234809,
     "end_time": "2021-08-01T12:58:06.168391",
     "exception": false,
     "start_time": "2021-08-01T12:53:37.933582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:01<04:07, 61.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:51<02:44, 54.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:39<01:42, 51.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:34<00:53, 53.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:23<00:00, 52.70s/it]\n"
     ]
    }
   ],
   "source": [
    "test = test_df\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import RobertaConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
    ")\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }\n",
    "\n",
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "def make_model(model_name, num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds\n",
    "\n",
    "def config(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )\n",
    "\n",
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Evaluator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds\n",
    "\n",
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "pred_df3 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dutch-burden",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:06.243134Z",
     "iopub.status.busy": "2021-08-01T12:58:06.241775Z",
     "iopub.status.idle": "2021-08-01T12:58:06.244455Z",
     "shell.execute_reply": "2021-08-01T12:58:06.244837Z",
     "shell.execute_reply.started": "2021-07-27T04:03:14.652866Z"
    },
    "papermill": {
     "duration": 0.043351,
     "end_time": "2021-08-01T12:58:06.244966",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.201615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df1 = np.array(pred_df1)\n",
    "pred_df2 = np.array(pred_df2)\n",
    "pred_df3 = np.array(pred_df3)\n",
    "model2_predictions = (pred_df2.mean(axis=1)*0.5) + (pred_df1.mean(axis=1)*0.3) + (pred_df3.mean(axis=1) * 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-replica",
   "metadata": {
    "papermill": {
     "duration": 0.032939,
     "end_time": "2021-08-01T12:58:06.310814",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.277875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "enclosed-midwest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:06.381682Z",
     "iopub.status.busy": "2021-08-01T12:58:06.381044Z",
     "iopub.status.idle": "2021-08-01T12:58:06.384540Z",
     "shell.execute_reply": "2021-08-01T12:58:06.384000Z",
     "shell.execute_reply.started": "2021-07-27T04:03:14.664934Z"
    },
    "papermill": {
     "duration": 0.040883,
     "end_time": "2021-08-01T12:58:06.384651",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.343768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 6#5\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 300#248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/pytorch_model.bin\"#\"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "TOKENIZER_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/\"\n",
    "CONFIG_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/config.json\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "premier-visibility",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:06.457141Z",
     "iopub.status.busy": "2021-08-01T12:58:06.455809Z",
     "iopub.status.idle": "2021-08-01T12:58:06.458420Z",
     "shell.execute_reply": "2021-08-01T12:58:06.458855Z",
     "shell.execute_reply.started": "2021-07-27T04:03:14.695479Z"
    },
    "papermill": {
     "duration": 0.04132,
     "end_time": "2021-08-01T12:58:06.458978",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.417658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "integral-glenn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:06.538533Z",
     "iopub.status.busy": "2021-08-01T12:58:06.537870Z",
     "iopub.status.idle": "2021-08-01T12:58:06.671103Z",
     "shell.execute_reply": "2021-08-01T12:58:06.670674Z",
     "shell.execute_reply.started": "2021-07-27T04:03:14.706094Z"
    },
    "papermill": {
     "duration": 0.179528,
     "end_time": "2021-08-01T12:58:06.671252",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.491724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\n",
    "\n",
    "# Remove incomplete entries if any.\n",
    "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
    "              inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unlimited-finger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:06.741713Z",
     "iopub.status.busy": "2021-08-01T12:58:06.741069Z",
     "iopub.status.idle": "2021-08-01T12:58:06.847938Z",
     "shell.execute_reply": "2021-08-01T12:58:06.847460Z",
     "shell.execute_reply.started": "2021-07-27T04:03:14.86297Z"
    },
    "papermill": {
     "duration": 0.143338,
     "end_time": "2021-08-01T12:58:06.848082",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.704744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-treaty",
   "metadata": {
    "papermill": {
     "duration": 0.031506,
     "end_time": "2021-08-01T12:58:06.911752",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.880246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "minor-roller",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.001573Z",
     "iopub.status.busy": "2021-08-01T12:58:07.000235Z",
     "iopub.status.idle": "2021-08-01T12:58:07.003066Z",
     "shell.execute_reply": "2021-08-01T12:58:07.002673Z",
     "shell.execute_reply.started": "2021-07-27T04:03:15.002939Z"
    },
    "papermill": {
     "duration": 0.046338,
     "end_time": "2021-08-01T12:58:07.003189",
     "exception": false,
     "start_time": "2021-08-01T12:58:06.956851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-arthur",
   "metadata": {
    "papermill": {
     "duration": 0.030792,
     "end_time": "2021-08-01T12:58:07.064632",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.033840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "functioning-things",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.131113Z",
     "iopub.status.busy": "2021-08-01T12:58:07.130607Z",
     "iopub.status.idle": "2021-08-01T12:58:07.134315Z",
     "shell.execute_reply": "2021-08-01T12:58:07.133896Z",
     "shell.execute_reply.started": "2021-07-27T04:03:15.015989Z"
    },
    "papermill": {
     "duration": 0.038333,
     "end_time": "2021-08-01T12:58:07.134437",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.096104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LitModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "#         config.update({\"output_hidden_states\":True, \n",
    "#                        \"hidden_dropout_prob\": 0.0,\n",
    "#                        \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "#         self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "#         self.attention = nn.Sequential(            \n",
    "#             nn.Linear(768, 512),            \n",
    "#             nn.Tanh(),                       \n",
    "#             nn.Linear(512, 1),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )        \n",
    "\n",
    "#         self.regressor = nn.Sequential(                        \n",
    "#             nn.Linear(768, 1)                        \n",
    "#         )\n",
    "        \n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         roberta_output = self.roberta(input_ids=input_ids,\n",
    "#                                       attention_mask=attention_mask)        \n",
    "\n",
    "#         # There are a total of 13 layers of hidden states.\n",
    "#         # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "#         # We take the hidden states from the last Roberta layer.\n",
    "#         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "#         # The number of cells is MAX_LEN.\n",
    "#         # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "#         # In order to condense hidden states of all cells to a context vector,\n",
    "#         # we compute a weighted average of the hidden states of all cells.\n",
    "#         # We compute the weight of each cell, using the attention neural network.\n",
    "#         weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "#         # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "#         # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "#         # Now we compute context_vector as the weighted average.\n",
    "#         # context_vector.shape is BATCH_SIZE x 768\n",
    "#         context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "#         # Now we reduce the context vector to the prediction score.\n",
    "#         return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vulnerable-sacrifice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.206849Z",
     "iopub.status.busy": "2021-08-01T12:58:07.206227Z",
     "iopub.status.idle": "2021-08-01T12:58:07.209435Z",
     "shell.execute_reply": "2021-08-01T12:58:07.209012Z"
    },
    "papermill": {
     "duration": 0.043556,
     "end_time": "2021-08-01T12:58:07.209537",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.165981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2103.04083v1.pdf\n",
    "class LitModel(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "#                        \"attention_probs_dropout_prob\":0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "#         self.cnn1 = nn.Conv1d(768, MAX_LEN, kernel_size=1)\n",
    "#         self.cnn2 = nn.Conv1d(MAX_LEN, 1, kernel_size=1)\n",
    "        self.cnn1 = nn.Conv1d(768, 512, kernel_size=1)\n",
    "        self.cnn2 = nn.Conv1d(512, MAX_LEN, kernel_size=1)\n",
    "         \n",
    "#         self.layernorm = nn.LayerNorm(MAX_LEN,MAX_LEN)    \n",
    "        self.layernorm = nn.LayerNorm(MAX_LEN)\n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(MAX_LEN, MAX_LEN),            \n",
    "            nn.Tanh(),  \n",
    "            nn.Linear(MAX_LEN, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(      \n",
    "#             nn.LayerNorm(768),\n",
    "            nn.Linear(MAX_LEN, 1),          \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)   \n",
    "        last_hidden_state = roberta_output.hidden_states[-1]\n",
    "#         print(last_hidden_state.shape)\n",
    "        last_hidden_state = last_hidden_state.permute(0, 2, 1)#16*768*MAX_LEN\n",
    "#         print(last_hidden_state.shape)\n",
    "        cnn_embeddings = F.relu(self.cnn1(last_hidden_state))#16*512*MAX_LEN\n",
    "#         print(cnn_embeddings.shape)\n",
    "        cnn_embeddings = self.cnn2(cnn_embeddings)#16*MAX_LEN(embedding)*MAX_LEN(tokens)\n",
    "#         print(cnn_embeddings.shape)\n",
    "        cnn_embeddings = cnn_embeddings.permute(0, 2, 1)\n",
    "#         cnn_embeddings = self.layernorm(cnn_embeddings)\n",
    "#         print(cnn_embeddings.shape)\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "#         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "        \n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "#         print(cnn_embeddings.shape)\n",
    "        weights = self.attention(cnn_embeddings)#16*MAX_LEN*1\n",
    "#         print('weights.shape',weights.shape)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * cnn_embeddings, dim=1)#16*MAX_LEN   \n",
    "#         print('context_vector',context_vector.shape)\n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)#16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "animal-acceptance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.277761Z",
     "iopub.status.busy": "2021-08-01T12:58:07.276544Z",
     "iopub.status.idle": "2021-08-01T12:58:07.278964Z",
     "shell.execute_reply": "2021-08-01T12:58:07.279428Z",
     "shell.execute_reply.started": "2021-07-27T04:03:15.034879Z"
    },
    "papermill": {
     "duration": 0.03907,
     "end_time": "2021-08-01T12:58:07.279543",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.240473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dying-avatar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.347803Z",
     "iopub.status.busy": "2021-08-01T12:58:07.346582Z",
     "iopub.status.idle": "2021-08-01T12:58:07.349418Z",
     "shell.execute_reply": "2021-08-01T12:58:07.348988Z",
     "shell.execute_reply.started": "2021-07-27T04:03:15.047887Z"
    },
    "papermill": {
     "duration": 0.039005,
     "end_time": "2021-08-01T12:58:07.349518",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.310513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-guinea",
   "metadata": {
    "papermill": {
     "duration": 0.031017,
     "end_time": "2021-08-01T12:58:07.411437",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.380420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "employed-formula",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.483245Z",
     "iopub.status.busy": "2021-08-01T12:58:07.482326Z",
     "iopub.status.idle": "2021-08-01T12:58:07.486149Z",
     "shell.execute_reply": "2021-08-01T12:58:07.486656Z",
     "shell.execute_reply.started": "2021-07-27T04:03:15.065901Z"
    },
    "papermill": {
     "duration": 0.044169,
     "end_time": "2021-08-01T12:58:07.486780",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.442611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = LitDataset(test_df, inference_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "protective-courage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:07.559160Z",
     "iopub.status.busy": "2021-08-01T12:58:07.557938Z",
     "iopub.status.idle": "2021-08-01T12:58:44.363788Z",
     "shell.execute_reply": "2021-08-01T12:58:44.364300Z",
     "shell.execute_reply.started": "2021-07-27T04:03:15.088116Z"
    },
    "papermill": {
     "duration": 36.846478,
     "end_time": "2021-08-01T12:58:44.364502",
     "exception": false,
     "start_time": "2021-08-01T12:58:07.518024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_2.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_3.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_4.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_5.pth\n"
     ]
    }
   ],
   "source": [
    "all_predictions = np.zeros((5, len(test_df)))\n",
    "\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "for index in range(5):            \n",
    "    model_path = f\"../input/pre-trained-roberta-solution-in-pytorch-train/model_{index + 1}.pth\" #../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_predictions[index] = predict(model, test_loader)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mature-smile",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:44.435364Z",
     "iopub.status.busy": "2021-08-01T12:58:44.434683Z",
     "iopub.status.idle": "2021-08-01T12:58:44.438321Z",
     "shell.execute_reply": "2021-08-01T12:58:44.438744Z",
     "shell.execute_reply.started": "2021-07-27T04:03:58.77674Z"
    },
    "papermill": {
     "duration": 0.040567,
     "end_time": "2021-08-01T12:58:44.438900",
     "exception": false,
     "start_time": "2021-08-01T12:58:44.398333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3_predictions = all_predictions.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "agreed-violation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:44.512695Z",
     "iopub.status.busy": "2021-08-01T12:58:44.512165Z",
     "iopub.status.idle": "2021-08-01T12:58:44.515851Z",
     "shell.execute_reply": "2021-08-01T12:58:44.515465Z",
     "shell.execute_reply.started": "2021-07-27T04:03:58.786107Z"
    },
    "papermill": {
     "duration": 0.039776,
     "end_time": "2021-08-01T12:58:44.515962",
     "exception": false,
     "start_time": "2021-08-01T12:58:44.476186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model1_predictions * 1/3 + model2_predictions * 1/3 + model3_predictions * 1/3\n",
    "\n",
    "# predictions = model1_predictions * 0.5 + model3_predictions * 0.5 -> 0.66\n",
    "# predictions = model1_predictions * 0.5 + model2_predictions * 0.5\n",
    "# predictions = model1_predictions * 0.55 + model2_predictions * 0.45\n",
    "# predictions = model1_predictions * 0.6 + model2_predictions * 0.4\n",
    "# predictions = model1_predictions * 0.7 + model2_predictions * 0.3\n",
    "# predictions = model1_predictions * 0.4 + model2_predictions * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "prospective-yacht",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:44.597970Z",
     "iopub.status.busy": "2021-08-01T12:58:44.597492Z",
     "iopub.status.idle": "2021-08-01T12:58:44.608887Z",
     "shell.execute_reply": "2021-08-01T12:58:44.608008Z",
     "shell.execute_reply.started": "2021-07-27T04:03:58.797514Z"
    },
    "papermill": {
     "duration": 0.059105,
     "end_time": "2021-08-01T12:58:44.609003",
     "exception": false,
     "start_time": "2021-08-01T12:58:44.549898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.437155</td>\n",
       "      <td>-0.424239</td>\n",
       "      <td>-0.534057</td>\n",
       "      <td>-0.465150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.656492</td>\n",
       "      <td>-0.552417</td>\n",
       "      <td>-0.536830</td>\n",
       "      <td>-0.581913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.354968</td>\n",
       "      <td>-0.480693</td>\n",
       "      <td>-0.471099</td>\n",
       "      <td>-0.435587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.515151</td>\n",
       "      <td>-2.409766</td>\n",
       "      <td>-2.565871</td>\n",
       "      <td>-2.496929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.678813</td>\n",
       "      <td>-1.869201</td>\n",
       "      <td>-1.846540</td>\n",
       "      <td>-1.798185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.427003</td>\n",
       "      <td>-1.139890</td>\n",
       "      <td>-1.400859</td>\n",
       "      <td>-1.322584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050763</td>\n",
       "      <td>0.154946</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>0.166027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model1    model2    model3  ensemble\n",
       "0 -0.437155 -0.424239 -0.534057 -0.465150\n",
       "1 -0.656492 -0.552417 -0.536830 -0.581913\n",
       "2 -0.354968 -0.480693 -0.471099 -0.435587\n",
       "3 -2.515151 -2.409766 -2.565871 -2.496929\n",
       "4 -1.678813 -1.869201 -1.846540 -1.798185\n",
       "5 -1.427003 -1.139890 -1.400859 -1.322584\n",
       "6  0.050763  0.154946  0.292373  0.166027"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(np.vstack((model1_predictions, model2_predictions, model3_predictions, predictions)).transpose(), \n",
    "                       columns=['model1','model2','model3','ensemble'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "extended-handbook",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T12:58:44.687659Z",
     "iopub.status.busy": "2021-08-01T12:58:44.686828Z",
     "iopub.status.idle": "2021-08-01T12:58:45.408320Z",
     "shell.execute_reply": "2021-08-01T12:58:45.407765Z",
     "shell.execute_reply.started": "2021-07-27T04:03:58.82948Z"
    },
    "papermill": {
     "duration": 0.765368,
     "end_time": "2021-08-01T12:58:45.408466",
     "exception": false,
     "start_time": "2021-08-01T12:58:44.643098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.465150\n",
      "1  f0953f0a5 -0.581913\n",
      "2  0df072751 -0.435587\n",
      "3  04caf4e0c -2.496929\n",
      "4  0e63f8bea -1.798185\n",
      "5  12537fe78 -1.322584\n",
      "6  965e592c0  0.166027\n"
     ]
    }
   ],
   "source": [
    "submission_df.target = predictions\n",
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-horizon",
   "metadata": {
    "papermill": {
     "duration": 0.033608,
     "end_time": "2021-08-01T12:58:45.478681",
     "exception": false,
     "start_time": "2021-08-01T12:58:45.445073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 368.759036,
   "end_time": "2021-08-01T12:58:48.153016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-01T12:52:39.393980",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
