{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceramic-developer",
   "metadata": {
    "papermill": {
     "duration": 0.016208,
     "end_time": "2021-06-03T04:34:19.571600",
     "exception": false,
     "start_time": "2021-06-03T04:34:19.555392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Please Upvote, Before Fork. \n",
    "\n",
    "### This Notebook\n",
    "\n",
    "Ensemble of 3 RoBERTa's,   \n",
    " - [CommonLit Readability Prize - RoBERTa Torch|Infer](https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer)  \n",
    " - [CommonLit Readability Prize-RoBERTa Torch|Infer 2](https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-2)  \n",
    " - RoBERTa-Large Trained using Dynamic Padding + Uniform Length Batching.  \n",
    " \n",
    "For more details about this technique and many more performance optimizations check below link, \n",
    "\n",
    "### What's New?\n",
    "I've created [**Speeding up Transformer w/ Optimization Strategies**](https://www.kaggle.com/rhtsingh/speeding-up-transformer-w-optimization-strategies/edit/run/64606344) notebook goes through in-depth analysis and code explanations of various promising performance improvement strategies in Transformers that can be used for training faster and better models,\n",
    " - Dyanmic Padding and Uniform Length Batching  \n",
    " - Gradient Accumulation  \n",
    " - Freeze Embedding  \n",
    " - Numeric Precision Reduction \n",
    " - Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-general",
   "metadata": {
    "papermill": {
     "duration": 0.015115,
     "end_time": "2021-06-03T04:34:19.602179",
     "exception": false,
     "start_time": "2021-06-03T04:34:19.587064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "molecular-oregon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:19.644595Z",
     "iopub.status.busy": "2021-06-03T04:34:19.644083Z",
     "iopub.status.idle": "2021-06-03T04:34:19.738863Z",
     "shell.execute_reply": "2021-06-03T04:34:19.738280Z",
     "shell.execute_reply.started": "2021-05-28T12:57:35.709083Z"
    },
    "papermill": {
     "duration": 0.121495,
     "end_time": "2021-06-03T04:34:19.739015",
     "exception": false,
     "start_time": "2021-06-03T04:34:19.617520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-hunger",
   "metadata": {
    "papermill": {
     "duration": 0.015397,
     "end_time": "2021-06-03T04:34:19.770068",
     "exception": false,
     "start_time": "2021-06-03T04:34:19.754671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "injured-portrait",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:19.808692Z",
     "iopub.status.busy": "2021-06-03T04:34:19.807363Z",
     "iopub.status.idle": "2021-06-03T04:34:19.810143Z",
     "shell.execute_reply": "2021-06-03T04:34:19.809731Z",
     "shell.execute_reply.started": "2021-05-28T12:57:35.838265Z"
    },
    "papermill": {
     "duration": 0.024711,
     "end_time": "2021-06-03T04:34:19.810262",
     "exception": false,
     "start_time": "2021-06-03T04:34:19.785551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungry-consolidation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:19.846134Z",
     "iopub.status.busy": "2021-06-03T04:34:19.845426Z",
     "iopub.status.idle": "2021-06-03T04:34:26.568542Z",
     "shell.execute_reply": "2021-06-03T04:34:26.568067Z",
     "shell.execute_reply.started": "2021-05-28T12:57:35.847953Z"
    },
    "papermill": {
     "duration": 6.743228,
     "end_time": "2021-06-03T04:34:26.568687",
     "exception": false,
     "start_time": "2021-06-03T04:34:19.825459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import RobertaConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
    ")\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-thickness",
   "metadata": {
    "papermill": {
     "duration": 0.014749,
     "end_time": "2021-06-03T04:34:26.598582",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.583833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert Examples `(Excerpt)` to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numeric-apollo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:26.634967Z",
     "iopub.status.busy": "2021-06-03T04:34:26.634225Z",
     "iopub.status.idle": "2021-06-03T04:34:26.636960Z",
     "shell.execute_reply": "2021-06-03T04:34:26.636532Z",
     "shell.execute_reply.started": "2021-05-28T12:57:43.159271Z"
    },
    "papermill": {
     "duration": 0.023612,
     "end_time": "2021-06-03T04:34:26.637069",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.613457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-territory",
   "metadata": {
    "papermill": {
     "duration": 0.014878,
     "end_time": "2021-06-03T04:34:26.666697",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.651819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identified-forty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:26.706447Z",
     "iopub.status.busy": "2021-06-03T04:34:26.705624Z",
     "iopub.status.idle": "2021-06-03T04:34:26.708296Z",
     "shell.execute_reply": "2021-06-03T04:34:26.707890Z",
     "shell.execute_reply.started": "2021-05-28T12:57:43.167729Z"
    },
    "papermill": {
     "duration": 0.026921,
     "end_time": "2021-06-03T04:34:26.708414",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.681493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-circulation",
   "metadata": {
    "papermill": {
     "duration": 0.01455,
     "end_time": "2021-06-03T04:34:26.737998",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.723448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decent-disco",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:26.781928Z",
     "iopub.status.busy": "2021-06-03T04:34:26.781164Z",
     "iopub.status.idle": "2021-06-03T04:34:26.783557Z",
     "shell.execute_reply": "2021-06-03T04:34:26.783941Z",
     "shell.execute_reply.started": "2021-05-28T12:57:43.182037Z"
    },
    "papermill": {
     "duration": 0.031095,
     "end_time": "2021-06-03T04:34:26.784070",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.752975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-working",
   "metadata": {
    "papermill": {
     "duration": 0.014975,
     "end_time": "2021-06-03T04:34:26.814373",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.799398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "small-green",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:26.851018Z",
     "iopub.status.busy": "2021-06-03T04:34:26.850247Z",
     "iopub.status.idle": "2021-06-03T04:34:26.852933Z",
     "shell.execute_reply": "2021-06-03T04:34:26.852485Z",
     "shell.execute_reply.started": "2021-05-28T12:57:43.200304Z"
    },
    "papermill": {
     "duration": 0.023781,
     "end_time": "2021-06-03T04:34:26.853050",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.829269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(model_name, num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-voltage",
   "metadata": {
    "papermill": {
     "duration": 0.014572,
     "end_time": "2021-06-03T04:34:26.882631",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.868059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aggressive-front",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:26.920839Z",
     "iopub.status.busy": "2021-06-03T04:34:26.920139Z",
     "iopub.status.idle": "2021-06-03T04:34:26.922899Z",
     "shell.execute_reply": "2021-06-03T04:34:26.922489Z",
     "shell.execute_reply.started": "2021-05-28T12:57:52.206134Z"
    },
    "papermill": {
     "duration": 0.024789,
     "end_time": "2021-06-03T04:34:26.923009",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.898220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-privilege",
   "metadata": {
    "papermill": {
     "duration": 0.01476,
     "end_time": "2021-06-03T04:34:26.953098",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.938338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chinese-decrease",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:26.989933Z",
     "iopub.status.busy": "2021-06-03T04:34:26.989160Z",
     "iopub.status.idle": "2021-06-03T04:34:26.992073Z",
     "shell.execute_reply": "2021-06-03T04:34:26.991598Z",
     "shell.execute_reply.started": "2021-05-28T12:57:53.97421Z"
    },
    "papermill": {
     "duration": 0.024091,
     "end_time": "2021-06-03T04:34:26.992180",
     "exception": false,
     "start_time": "2021-06-03T04:34:26.968089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def config(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-aberdeen",
   "metadata": {
    "papermill": {
     "duration": 0.014884,
     "end_time": "2021-06-03T04:34:27.021686",
     "exception": false,
     "start_time": "2021-06-03T04:34:27.006802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separated-lebanon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:27.057163Z",
     "iopub.status.busy": "2021-06-03T04:34:27.056377Z",
     "iopub.status.idle": "2021-06-03T04:34:27.058851Z",
     "shell.execute_reply": "2021-06-03T04:34:27.059245Z",
     "shell.execute_reply.started": "2021-05-28T12:57:57.1208Z"
    },
    "papermill": {
     "duration": 0.023003,
     "end_time": "2021-06-03T04:34:27.059363",
     "exception": false,
     "start_time": "2021-06-03T04:34:27.036360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Evaluator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "going-campbell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:34:27.094853Z",
     "iopub.status.busy": "2021-06-03T04:34:27.094326Z",
     "iopub.status.idle": "2021-06-03T04:39:20.081000Z",
     "shell.execute_reply": "2021-06-03T04:39:20.080555Z",
     "shell.execute_reply.started": "2021-05-28T12:59:26.446753Z"
    },
    "papermill": {
     "duration": 293.00698,
     "end_time": "2021-06-03T04:39:20.081128",
     "exception": false,
     "start_time": "2021-06-03T04:34:27.074148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:19<05:18, 79.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:12<03:12, 64.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:06<01:58, 59.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:59<00:57, 57.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:52<00:00, 58.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 16.6 s, total: 1min 47s\n",
      "Wall time: 4min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "pred_df3 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-revelation",
   "metadata": {
    "papermill": {
     "duration": 0.020792,
     "end_time": "2021-06-03T04:39:20.122689",
     "exception": false,
     "start_time": "2021-06-03T04:39:20.101897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "employed-stone",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:39:20.172936Z",
     "iopub.status.busy": "2021-06-03T04:39:20.172419Z",
     "iopub.status.idle": "2021-06-03T04:39:20.583599Z",
     "shell.execute_reply": "2021-06-03T04:39:20.583046Z",
     "shell.execute_reply.started": "2021-05-28T13:23:05.546803Z"
    },
    "papermill": {
     "duration": 0.440558,
     "end_time": "2021-06-03T04:39:20.583767",
     "exception": false,
     "start_time": "2021-06-03T04:39:20.143209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "# sub['target'] = ((pred_df1.mean(axis=1) + pred_df2.mean(axis=1) + pred_df3.mean(axis=1))/3).values.tolist()\n",
    "sub['target'] = (pred_df2.mean(axis=1)*0.5) + (pred_df1.mean(axis=1)*0.3) + (pred_df3.mean(axis=1) * 0.2).values.tolist()\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "homeless-stroke",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:39:20.628610Z",
     "iopub.status.busy": "2021-06-03T04:39:20.628118Z",
     "iopub.status.idle": "2021-06-03T04:39:20.631824Z",
     "shell.execute_reply": "2021-06-03T04:39:20.631408Z",
     "shell.execute_reply.started": "2021-05-25T13:05:44.493247Z"
    },
    "papermill": {
     "duration": 0.027236,
     "end_time": "2021-06-03T04:39:20.631929",
     "exception": false,
     "start_time": "2021-06-03T04:39:20.604693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "# sub['target'] = pred_df.mean(axis=1).values.tolist()\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "filled-domestic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T04:39:20.685541Z",
     "iopub.status.busy": "2021-06-03T04:39:20.684920Z",
     "iopub.status.idle": "2021-06-03T04:39:20.692870Z",
     "shell.execute_reply": "2021-06-03T04:39:20.693265Z",
     "shell.execute_reply.started": "2021-05-28T13:23:09.40502Z"
    },
    "papermill": {
     "duration": 0.040675,
     "end_time": "2021-06-03T04:39:20.693406",
     "exception": false,
     "start_time": "2021-06-03T04:39:20.652731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.424239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.552417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.480693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.409766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.869201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.139890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.154946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.424239\n",
       "1  f0953f0a5 -0.552417\n",
       "2  0df072751 -0.480693\n",
       "3  04caf4e0c -2.409766\n",
       "4  0e63f8bea -1.869201\n",
       "5  12537fe78 -1.139890\n",
       "6  965e592c0  0.154946"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-organic",
   "metadata": {
    "papermill": {
     "duration": 0.020725,
     "end_time": "2021-06-03T04:39:20.735596",
     "exception": false,
     "start_time": "2021-06-03T04:39:20.714871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 310.663262,
   "end_time": "2021-06-03T04:39:23.627076",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T04:34:12.963814",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
