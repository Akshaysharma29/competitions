{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "searching-patrol",
   "metadata": {
    "_cell_guid": "74de39a7-6183-4838-b0ba-3cfff13fa27f",
    "_uuid": "963d308e-189e-491c-a090-b5fc68f4f0a2",
    "papermill": {
     "duration": 0.016506,
     "end_time": "2021-07-27T09:50:39.765720",
     "exception": false,
     "start_time": "2021-07-27T09:50:39.749214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Notebooks sequence;)**\n",
    "* Train-val split notebook [here](https://www.kaggle.com/chamecall/train-val-split).<br>\n",
    "* Pretrain roberta-base on mlm with the competition data notebook [here](https://www.kaggle.com/chamecall/clrp-pretrain).<br>\n",
    "* Finetune pretrained roberta-base on readability task notebook [here](https://www.kaggle.com/chamecall/clrp-finetune).<br>\n",
    "* Inference model notebook [*CURRENT ONE*].<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greater-spouse",
   "metadata": {
    "_cell_guid": "58aa9358-0979-4bb5-a6ce-4292869a720c",
    "_uuid": "ef575956-b04d-49d6-a5ec-c4ede72227f6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-07-27T09:50:39.806439Z",
     "iopub.status.busy": "2021-07-27T09:50:39.805930Z",
     "iopub.status.idle": "2021-07-27T09:50:39.809217Z",
     "shell.execute_reply": "2021-07-27T09:50:39.809620Z",
     "shell.execute_reply.started": "2021-07-27T09:29:31.941665Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028529,
     "end_time": "2021-07-27T09:50:39.809828",
     "exception": false,
     "start_time": "2021-07-27T09:50:39.781299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "in_folder_path = Path('../input/clrp-finetune')#Path('../input/clrp-finetune')\n",
    "scripts_dir = Path(in_folder_path / 'scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "human-estimate",
   "metadata": {
    "_cell_guid": "729f8813-aaf6-49f9-a4c8-abefb0f32c31",
    "_uuid": "fdc9f439-b48a-4525-810b-718f44f61fcf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-07-27T09:50:39.844325Z",
     "iopub.status.busy": "2021-07-27T09:50:39.843831Z",
     "iopub.status.idle": "2021-07-27T09:50:47.048714Z",
     "shell.execute_reply": "2021-07-27T09:50:47.048199Z",
     "shell.execute_reply.started": "2021-07-27T09:29:32.480166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.223823,
     "end_time": "2021-07-27T09:50:47.048853",
     "exception": false,
     "start_time": "2021-07-27T09:50:39.825030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(scripts_dir)\n",
    "exec(Path(\"imports.py\").read_text())\n",
    "exec(Path(\"config.py\").read_text())\n",
    "exec(Path(\"dataset.py\").read_text())\n",
    "exec(Path(\"model.py\").read_text())\n",
    "os.chdir('/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satisfactory-speed",
   "metadata": {
    "_cell_guid": "0960a7a6-aae2-466b-8d31-0918a65eb559",
    "_uuid": "3bcc8398-d3ba-4caa-a24b-cadc4eeadf94",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-07-27T09:50:47.089075Z",
     "iopub.status.busy": "2021-07-27T09:50:47.088499Z",
     "iopub.status.idle": "2021-07-27T09:51:04.382072Z",
     "shell.execute_reply": "2021-07-27T09:51:04.381617Z",
     "shell.execute_reply.started": "2021-07-27T09:29:39.833332Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 17.317396,
     "end_time": "2021-07-27T09:51:04.382199",
     "exception": false,
     "start_time": "2021-07-27T09:50:47.064803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference#1/[0, 2]\n",
      "Inference#3/[0, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "\n",
    "tokenizer = torch.load('../input/tokenizers/roberta-tokenizer.pt')\n",
    "models_folder_path = Path(in_folder_path / 'models')\n",
    "models_preds = []\n",
    "# n_models = 5\n",
    "n_models = [0,2]\n",
    "\n",
    "# for model_num in range(n_models):\n",
    "for model_num in n_models:\n",
    "    print(f'Inference#{model_num+1}/{n_models}')\n",
    "    test_ds = CLRPDataset(data=test_df, tokenizer=tokenizer, max_len=Config.max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_ds)\n",
    "    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=Config.batch_size)\n",
    "    model = torch.load(models_folder_path / f'best_model_{model_num}.pt').to(Config.device)\n",
    "\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "\n",
    "    for step,batch in enumerate(test_dataloader):\n",
    "        sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            all_preds += preds.flatten().cpu().tolist()\n",
    "    \n",
    "    models_preds.append(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greater-swaziland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.418617Z",
     "iopub.status.busy": "2021-07-27T09:51:04.418002Z",
     "iopub.status.idle": "2021-07-27T09:51:04.421636Z",
     "shell.execute_reply": "2021-07-27T09:51:04.421210Z",
     "shell.execute_reply.started": "2021-07-27T09:29:55.52765Z"
    },
    "papermill": {
     "duration": 0.022331,
     "end_time": "2021-07-27T09:51:04.421742",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.399411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models_preds = np.array(models_preds)\n",
    "# print(models_preds.shape)\n",
    "# # print(models_preds)\n",
    "# model1_predictions = models_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-kingston",
   "metadata": {
    "papermill": {
     "duration": 0.015777,
     "end_time": "2021-07-27T09:51:04.453313",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.437536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statistical-thickness",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.489887Z",
     "iopub.status.busy": "2021-07-27T09:51:04.489324Z",
     "iopub.status.idle": "2021-07-27T09:51:04.492745Z",
     "shell.execute_reply": "2021-07-27T09:51:04.493105Z",
     "shell.execute_reply.started": "2021-07-27T09:30:35.255105Z"
    },
    "papermill": {
     "duration": 0.024084,
     "end_time": "2021-07-27T09:51:04.493225",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.469141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 300#248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/pytorch_model.bin\"#\"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "TOKENIZER_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/\"\n",
    "CONFIG_PATH = \"../input/pre-trained-roberta-solution-in-pytorch-train/roberta-base/config.json\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "powerful-sector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.532517Z",
     "iopub.status.busy": "2021-07-27T09:51:04.531302Z",
     "iopub.status.idle": "2021-07-27T09:51:04.533944Z",
     "shell.execute_reply": "2021-07-27T09:51:04.533554Z",
     "shell.execute_reply.started": "2021-07-27T09:30:36.25983Z"
    },
    "papermill": {
     "duration": 0.022801,
     "end_time": "2021-07-27T09:51:04.534047",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.511246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removed-onion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.572200Z",
     "iopub.status.busy": "2021-07-27T09:51:04.571701Z",
     "iopub.status.idle": "2021-07-27T09:51:04.648812Z",
     "shell.execute_reply": "2021-07-27T09:51:04.648334Z",
     "shell.execute_reply.started": "2021-07-27T09:30:37.141871Z"
    },
    "papermill": {
     "duration": 0.099093,
     "end_time": "2021-07-27T09:51:04.648939",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.549846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\n",
    "\n",
    "# Remove incomplete entries if any.\n",
    "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
    "              inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "turned-wrong",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.684279Z",
     "iopub.status.busy": "2021-07-27T09:51:04.683795Z",
     "iopub.status.idle": "2021-07-27T09:51:04.793027Z",
     "shell.execute_reply": "2021-07-27T09:51:04.792503Z",
     "shell.execute_reply.started": "2021-07-27T09:30:37.713914Z"
    },
    "papermill": {
     "duration": 0.128028,
     "end_time": "2021-07-27T09:51:04.793154",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.665126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-liability",
   "metadata": {
    "papermill": {
     "duration": 0.015764,
     "end_time": "2021-07-27T09:51:04.825386",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.809622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "perfect-soldier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.866110Z",
     "iopub.status.busy": "2021-07-27T09:51:04.865469Z",
     "iopub.status.idle": "2021-07-27T09:51:04.868267Z",
     "shell.execute_reply": "2021-07-27T09:51:04.868651Z",
     "shell.execute_reply.started": "2021-07-27T09:30:39.095042Z"
    },
    "papermill": {
     "duration": 0.027509,
     "end_time": "2021-07-27T09:51:04.868776",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.841267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-belfast",
   "metadata": {
    "papermill": {
     "duration": 0.015722,
     "end_time": "2021-07-27T09:51:04.901054",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.885332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "israeli-floor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.940586Z",
     "iopub.status.busy": "2021-07-27T09:51:04.939983Z",
     "iopub.status.idle": "2021-07-27T09:51:04.943246Z",
     "shell.execute_reply": "2021-07-27T09:51:04.943645Z",
     "shell.execute_reply.started": "2021-07-27T09:30:41.38057Z"
    },
    "papermill": {
     "duration": 0.026796,
     "end_time": "2021-07-27T09:51:04.943776",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.916980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(768, 512),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(                        \n",
    "            nn.Linear(768, 1)                        \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "timely-sample",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:04.981367Z",
     "iopub.status.busy": "2021-07-27T09:51:04.980871Z",
     "iopub.status.idle": "2021-07-27T09:51:04.983983Z",
     "shell.execute_reply": "2021-07-27T09:51:04.984350Z",
     "shell.execute_reply.started": "2021-07-27T09:30:42.089547Z"
    },
    "papermill": {
     "duration": 0.024871,
     "end_time": "2021-07-27T09:51:04.984494",
     "exception": false,
     "start_time": "2021-07-27T09:51:04.959623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ultimate-medline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:05.022115Z",
     "iopub.status.busy": "2021-07-27T09:51:05.021534Z",
     "iopub.status.idle": "2021-07-27T09:51:05.024553Z",
     "shell.execute_reply": "2021-07-27T09:51:05.024148Z",
     "shell.execute_reply.started": "2021-07-27T09:30:42.887468Z"
    },
    "papermill": {
     "duration": 0.023997,
     "end_time": "2021-07-27T09:51:05.024658",
     "exception": false,
     "start_time": "2021-07-27T09:51:05.000661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-island",
   "metadata": {
    "papermill": {
     "duration": 0.015779,
     "end_time": "2021-07-27T09:51:05.056351",
     "exception": false,
     "start_time": "2021-07-27T09:51:05.040572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "administrative-bailey",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:05.094419Z",
     "iopub.status.busy": "2021-07-27T09:51:05.093666Z",
     "iopub.status.idle": "2021-07-27T09:51:36.346810Z",
     "shell.execute_reply": "2021-07-27T09:51:36.346210Z",
     "shell.execute_reply.started": "2021-07-27T09:30:45.051231Z"
    },
    "papermill": {
     "duration": 31.274719,
     "end_time": "2021-07-27T09:51:36.346955",
     "exception": false,
     "start_time": "2021-07-27T09:51:05.072236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_2.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_4.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_5.pth\n"
     ]
    }
   ],
   "source": [
    "model_num= [1,3,4]\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "# all_predictions = np.zeros((len(model_num), len(test_df)))\n",
    "\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "# for index in range(5):\n",
    "for index,val in enumerate(model_num):            \n",
    "    model_path = f\"../input/pre-trained-roberta-solution-in-pytorch-train/model_{val + 1}.pth\" #../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    models_preds.append(predict(model, test_loader))\n",
    "    \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attended-morgan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:36.388917Z",
     "iopub.status.busy": "2021-07-27T09:51:36.388351Z",
     "iopub.status.idle": "2021-07-27T09:51:36.391725Z",
     "shell.execute_reply": "2021-07-27T09:51:36.392130Z",
     "shell.execute_reply.started": "2021-07-27T09:31:11.229439Z"
    },
    "papermill": {
     "duration": 0.026233,
     "end_time": "2021-07-27T09:51:36.392252",
     "exception": false,
     "start_time": "2021-07-27T09:51:36.366019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model2_predictions = all_predictions.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "right-paris",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:36.433222Z",
     "iopub.status.busy": "2021-07-27T09:51:36.432628Z",
     "iopub.status.idle": "2021-07-27T09:51:36.438013Z",
     "shell.execute_reply": "2021-07-27T09:51:36.437544Z",
     "shell.execute_reply.started": "2021-07-27T09:31:21.869192Z"
    },
    "papermill": {
     "duration": 0.028708,
     "end_time": "2021-07-27T09:51:36.438137",
     "exception": false,
     "start_time": "2021-07-27T09:51:36.409429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7)\n"
     ]
    }
   ],
   "source": [
    "# predictions = model1_predictions * 0.5 + model2_predictions * 0.5\n",
    "models_preds = np.array(models_preds)\n",
    "print(models_preds.shape)\n",
    "# print(models_preds)\n",
    "predictions = models_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "material-encoding",
   "metadata": {
    "_cell_guid": "ebdd4e76-65d4-45d0-aa8f-0c7705198e57",
    "_uuid": "e496e1ec-baf8-4e23-a7bf-63fc4e7c5d1a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:36.477934Z",
     "iopub.status.busy": "2021-07-27T09:51:36.477434Z",
     "iopub.status.idle": "2021-07-27T09:51:36.481155Z",
     "shell.execute_reply": "2021-07-27T09:51:36.480762Z",
     "shell.execute_reply.started": "2021-07-27T09:32:13.463503Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023449,
     "end_time": "2021-07-27T09:51:36.481283",
     "exception": false,
     "start_time": "2021-07-27T09:51:36.457834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # results = pd.DataFrame(np.vstack((model1_predictions, model2_predictions, model3_predictions, predictions)).transpose(), \n",
    "# #                        columns=['model1','model2','model3','ensemble'])\n",
    "# results = pd.DataFrame(np.vstack((model1_predictions, model2_predictions, predictions)).transpose(), \n",
    "#                        columns=['model1','model2','ensemble'])\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "significant-opinion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:36.518662Z",
     "iopub.status.busy": "2021-07-27T09:51:36.518127Z",
     "iopub.status.idle": "2021-07-27T09:51:36.522014Z",
     "shell.execute_reply": "2021-07-27T09:51:36.521622Z",
     "shell.execute_reply.started": "2021-07-27T09:35:03.168447Z"
    },
    "papermill": {
     "duration": 0.023394,
     "end_time": "2021-07-27T09:51:36.522117",
     "exception": false,
     "start_time": "2021-07-27T09:51:36.498723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission_df.target = predictions\n",
    "# print(submission_df)\n",
    "# submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "received-cabin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:51:36.571813Z",
     "iopub.status.busy": "2021-07-27T09:51:36.571245Z",
     "iopub.status.idle": "2021-07-27T09:51:36.703712Z",
     "shell.execute_reply": "2021-07-27T09:51:36.703127Z",
     "shell.execute_reply.started": "2021-07-27T09:34:47.753237Z"
    },
    "papermill": {
     "duration": 0.162402,
     "end_time": "2021-07-27T09:51:36.703837",
     "exception": false,
     "start_time": "2021-07-27T09:51:36.541435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.445603\n",
      "1  f0953f0a5 -0.582775\n",
      "2  0df072751 -0.430027\n",
      "3  04caf4e0c -2.531679\n",
      "4  0e63f8bea -1.707110\n",
      "5  12537fe78 -1.540228\n",
      "6  965e592c0  0.108431\n"
     ]
    }
   ],
   "source": [
    "test_df['target']=predictions\n",
    "# submission_df.target = predictions\n",
    "cols_to_keep=['id','target']\n",
    "print(test_df[cols_to_keep])\n",
    "test_df.loc[:, cols_to_keep].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-stranger",
   "metadata": {
    "papermill": {
     "duration": 0.018298,
     "end_time": "2021-07-27T09:51:36.739564",
     "exception": false,
     "start_time": "2021-07-27T09:51:36.721266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.728246,
   "end_time": "2021-07-27T09:51:38.887862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-27T09:50:33.159616",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
