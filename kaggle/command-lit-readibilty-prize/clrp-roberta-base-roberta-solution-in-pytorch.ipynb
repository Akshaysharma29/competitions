{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binary-stations",
   "metadata": {
    "papermill": {
     "duration": 0.019037,
     "end_time": "2021-08-02T11:17:58.946117",
     "exception": false,
     "start_time": "2021-08-02T11:17:58.927080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "This is kernel is almost the same as [Lightweight Roberta solution in PyTorch](https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch), but instead of \"roberta-base\", it starts from [Maunish's pre-trained model](https://www.kaggle.com/maunish/clrp-roberta-base).\n",
    "\n",
    "Acknowledgments: some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "different-glory",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T11:17:58.990883Z",
     "iopub.status.busy": "2021-08-02T11:17:58.990214Z",
     "iopub.status.idle": "2021-08-02T11:18:06.469123Z",
     "shell.execute_reply": "2021-08-02T11:18:06.468522Z",
     "shell.execute_reply.started": "2021-08-02T11:15:28.706105Z"
    },
    "papermill": {
     "duration": 7.505792,
     "end_time": "2021-08-02T11:18:06.469265",
     "exception": false,
     "start_time": "2021-08-02T11:17:58.963473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "criminal-clause",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:06.547001Z",
     "iopub.status.busy": "2021-08-02T11:18:06.545986Z",
     "iopub.status.idle": "2021-08-02T11:18:06.548410Z",
     "shell.execute_reply": "2021-08-02T11:18:06.548891Z",
     "shell.execute_reply.started": "2021-08-02T11:15:38.391017Z"
    },
    "papermill": {
     "duration": 0.063113,
     "end_time": "2021-08-02T11:18:06.549051",
     "exception": false,
     "start_time": "2021-08-02T11:18:06.485938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5#5\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 300#248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"../input/clrp-roberta-base-pre-trained-in-pytorch-train/roberta-base/pytorch_model.bin\"#\"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "TOKENIZER_PATH = \"../input/clrp-roberta-base-pre-trained-in-pytorch-train/roberta-base/\"\n",
    "CONFIG_PATH = \"../input/clrp-roberta-base-pre-trained-in-pytorch-train/roberta-base/config.json\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "streaming-assault",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:06.589809Z",
     "iopub.status.busy": "2021-08-02T11:18:06.589042Z",
     "iopub.status.idle": "2021-08-02T11:18:06.592871Z",
     "shell.execute_reply": "2021-08-02T11:18:06.592259Z",
     "shell.execute_reply.started": "2021-08-02T11:15:38.449021Z"
    },
    "papermill": {
     "duration": 0.026233,
     "end_time": "2021-08-02T11:18:06.592999",
     "exception": false,
     "start_time": "2021-08-02T11:18:06.566766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secure-syracuse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:06.629584Z",
     "iopub.status.busy": "2021-08-02T11:18:06.629073Z",
     "iopub.status.idle": "2021-08-02T11:18:06.726982Z",
     "shell.execute_reply": "2021-08-02T11:18:06.725999Z",
     "shell.execute_reply.started": "2021-08-02T11:15:38.464473Z"
    },
    "papermill": {
     "duration": 0.11873,
     "end_time": "2021-08-02T11:18:06.727125",
     "exception": false,
     "start_time": "2021-08-02T11:18:06.608395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\n",
    "\n",
    "# Remove incomplete entries if any.\n",
    "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
    "              inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outer-spouse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:06.762473Z",
     "iopub.status.busy": "2021-08-02T11:18:06.761925Z",
     "iopub.status.idle": "2021-08-02T11:18:06.919040Z",
     "shell.execute_reply": "2021-08-02T11:18:06.918505Z",
     "shell.execute_reply.started": "2021-08-02T11:15:38.588701Z"
    },
    "papermill": {
     "duration": 0.175271,
     "end_time": "2021-08-02T11:18:06.919160",
     "exception": false,
     "start_time": "2021-08-02T11:18:06.743889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-emergency",
   "metadata": {
    "papermill": {
     "duration": 0.01473,
     "end_time": "2021-08-02T11:18:06.949901",
     "exception": false,
     "start_time": "2021-08-02T11:18:06.935171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "generous-making",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:06.991950Z",
     "iopub.status.busy": "2021-08-02T11:18:06.991166Z",
     "iopub.status.idle": "2021-08-02T11:18:06.995078Z",
     "shell.execute_reply": "2021-08-02T11:18:06.994477Z",
     "shell.execute_reply.started": "2021-08-02T11:16:23.784450Z"
    },
    "papermill": {
     "duration": 0.029401,
     "end_time": "2021-08-02T11:18:06.995205",
     "exception": false,
     "start_time": "2021-08-02T11:18:06.965804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-valuable",
   "metadata": {
    "papermill": {
     "duration": 0.017571,
     "end_time": "2021-08-02T11:18:07.030523",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.012952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adjusted-silence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.066783Z",
     "iopub.status.busy": "2021-08-02T11:18:07.065834Z",
     "iopub.status.idle": "2021-08-02T11:18:07.068511Z",
     "shell.execute_reply": "2021-08-02T11:18:07.068054Z",
     "shell.execute_reply.started": "2021-08-02T11:16:24.695351Z"
    },
    "papermill": {
     "duration": 0.02212,
     "end_time": "2021-08-02T11:18:07.068620",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.046500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LitModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "#         config.update({\"output_hidden_states\":True, \n",
    "#                        \"hidden_dropout_prob\": 0.0,\n",
    "#                        \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "#         self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "#         self.attention = nn.Sequential(            \n",
    "#             nn.Linear(768, 512),            \n",
    "#             nn.Tanh(),                       \n",
    "#             nn.Linear(512, 1),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )        \n",
    "\n",
    "#         self.regressor = nn.Sequential(                        \n",
    "#             nn.Linear(768, 1)                        \n",
    "#         )\n",
    "        \n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         roberta_output = self.roberta(input_ids=input_ids,\n",
    "#                                       attention_mask=attention_mask)        \n",
    "\n",
    "#         # There are a total of 13 layers of hidden states.\n",
    "#         # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "#         # We take the hidden states from the last Roberta layer.\n",
    "#         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "#         # The number of cells is MAX_LEN.\n",
    "#         # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "#         # In order to condense hidden states of all cells to a context vector,\n",
    "#         # we compute a weighted average of the hidden states of all cells.\n",
    "#         # We compute the weight of each cell, using the attention neural network.\n",
    "#         weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "#         # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "#         # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "#         # Now we compute context_vector as the weighted average.\n",
    "#         # context_vector.shape is BATCH_SIZE x 768\n",
    "#         context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "#         # Now we reduce the context vector to the prediction score.\n",
    "#         return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "light-provision",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.109718Z",
     "iopub.status.busy": "2021-08-02T11:18:07.108923Z",
     "iopub.status.idle": "2021-08-02T11:18:07.111786Z",
     "shell.execute_reply": "2021-08-02T11:18:07.111380Z",
     "shell.execute_reply.started": "2021-08-02T11:16:24.927994Z"
    },
    "papermill": {
     "duration": 0.028158,
     "end_time": "2021-08-02T11:18:07.111897",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.083739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2103.04083v1.pdf\n",
    "class LitModel(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "#                        \"attention_probs_dropout_prob\":0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "#         self.cnn1 = nn.Conv1d(768, MAX_LEN, kernel_size=1)\n",
    "#         self.cnn2 = nn.Conv1d(MAX_LEN, 1, kernel_size=1)\n",
    "        self.cnn1 = nn.Conv1d(768, 512, kernel_size=1)\n",
    "        self.cnn2 = nn.Conv1d(512, MAX_LEN, kernel_size=1)\n",
    "         \n",
    "#         self.layernorm = nn.LayerNorm(MAX_LEN,MAX_LEN)    \n",
    "        self.layernorm = nn.LayerNorm(MAX_LEN)\n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(MAX_LEN, MAX_LEN),            \n",
    "            nn.Tanh(),  \n",
    "            nn.Linear(MAX_LEN, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(      \n",
    "#             nn.LayerNorm(768),\n",
    "            nn.Linear(MAX_LEN, 1),          \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)   \n",
    "        last_hidden_state = roberta_output.hidden_states[-1]\n",
    "#         print(last_hidden_state.shape)\n",
    "        last_hidden_state = last_hidden_state.permute(0, 2, 1)#16*768*MAX_LEN\n",
    "#         print(last_hidden_state.shape)\n",
    "        cnn_embeddings = F.relu(self.cnn1(last_hidden_state))#16*512*MAX_LEN\n",
    "#         print(cnn_embeddings.shape)\n",
    "        cnn_embeddings = self.cnn2(cnn_embeddings)#16*MAX_LEN(embedding)*MAX_LEN(tokens)\n",
    "#         print(cnn_embeddings.shape)\n",
    "        cnn_embeddings = cnn_embeddings.permute(0, 2, 1)\n",
    "#         cnn_embeddings = self.layernorm(cnn_embeddings)\n",
    "#         print(cnn_embeddings.shape)\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "#         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "        \n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "#         print(cnn_embeddings.shape)\n",
    "        weights = self.attention(cnn_embeddings)#16*MAX_LEN*1\n",
    "#         print('weights.shape',weights.shape)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * cnn_embeddings, dim=1)#16*MAX_LEN   \n",
    "#         print('context_vector',context_vector.shape)\n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)#16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "macro-binding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.153831Z",
     "iopub.status.busy": "2021-08-02T11:18:07.152827Z",
     "iopub.status.idle": "2021-08-02T11:18:07.155793Z",
     "shell.execute_reply": "2021-08-02T11:18:07.155262Z",
     "shell.execute_reply.started": "2021-08-02T11:16:25.031220Z"
    },
    "papermill": {
     "duration": 0.027574,
     "end_time": "2021-08-02T11:18:07.155920",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.128346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "worthy-security",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.196409Z",
     "iopub.status.busy": "2021-08-02T11:18:07.195638Z",
     "iopub.status.idle": "2021-08-02T11:18:07.198289Z",
     "shell.execute_reply": "2021-08-02T11:18:07.197758Z",
     "shell.execute_reply.started": "2021-08-02T11:16:25.191050Z"
    },
    "papermill": {
     "duration": 0.024927,
     "end_time": "2021-08-02T11:18:07.198414",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.173487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "urban-poverty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.239440Z",
     "iopub.status.busy": "2021-08-02T11:18:07.238660Z",
     "iopub.status.idle": "2021-08-02T11:18:07.241434Z",
     "shell.execute_reply": "2021-08-02T11:18:07.240888Z",
     "shell.execute_reply.started": "2021-08-02T11:16:25.376149Z"
    },
    "papermill": {
     "duration": 0.028135,
     "end_time": "2021-08-02T11:18:07.241542",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.213407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, model_path, train_loader, val_loader,\n",
    "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
    "    best_val_rmse = None\n",
    "    best_epoch = 0\n",
    "    step = 0\n",
    "    last_eval_step = 0\n",
    "    eval_period = EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):                           \n",
    "        val_rmse = None         \n",
    "\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)            \n",
    "            target = target.to(DEVICE)                        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            pred = model(input_ids, attention_mask)\n",
    "                                                        \n",
    "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
    "                        \n",
    "            mse.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            if step >= last_eval_step + eval_period:\n",
    "                # Evaluate the model on val_loader.\n",
    "                elapsed_seconds = time.time() - start\n",
    "                num_steps = step - last_eval_step\n",
    "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                last_eval_step = step\n",
    "                \n",
    "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
    "\n",
    "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
    "                      f\"val_rmse: {val_rmse:0.4}\")\n",
    "\n",
    "                for rmse, period in EVAL_SCHEDULE:\n",
    "                    if val_rmse >= rmse:\n",
    "                        eval_period = period\n",
    "                        break                               \n",
    "                \n",
    "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
    "                    best_val_rmse = val_rmse\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "                else:       \n",
    "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "                          f\"(from epoch {best_epoch})\")                                    \n",
    "                    \n",
    "                start = time.time()\n",
    "                                            \n",
    "            step += 1\n",
    "                        \n",
    "    \n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "angry-dispute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.282158Z",
     "iopub.status.busy": "2021-08-02T11:18:07.281168Z",
     "iopub.status.idle": "2021-08-02T11:18:07.284284Z",
     "shell.execute_reply": "2021-08-02T11:18:07.283697Z",
     "shell.execute_reply.started": "2021-08-02T11:16:25.485833Z"
    },
    "papermill": {
     "duration": 0.027481,
     "end_time": "2021-08-02T11:18:07.284425",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.256944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    named_parameters = list(model.named_parameters())    \n",
    "    \n",
    "    roberta_parameters = named_parameters[:197]    \n",
    "    attention_parameters = named_parameters[199:203]\n",
    "    regressor_parameters = named_parameters[203:]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "\n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group})\n",
    "    parameters.append({\"params\": regressor_group})\n",
    "\n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
    "\n",
    "        lr = 2e-5\n",
    "\n",
    "        if layer_num >= 69:        \n",
    "            lr = 5e-5\n",
    "\n",
    "        if layer_num >= 133:\n",
    "            lr = 1e-4\n",
    "\n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "\n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dynamic-spanish",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.325041Z",
     "iopub.status.busy": "2021-08-02T11:18:07.324102Z",
     "iopub.status.idle": "2021-08-02T11:18:07.326910Z",
     "shell.execute_reply": "2021-08-02T11:18:07.326500Z",
     "shell.execute_reply.started": "2021-08-02T11:16:25.651192Z"
    },
    "papermill": {
     "duration": 0.025028,
     "end_time": "2021-08-02T11:18:07.327034",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.302006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gc.collect()\n",
    "\n",
    "# SEED = 1000\n",
    "# list_val_rmse = []\n",
    "\n",
    "# kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "# for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
    "#     print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
    "#     model_path = f\"model_{fold + 1}.pth\"\n",
    "        \n",
    "#     set_random_seed(SEED + fold)\n",
    "    \n",
    "#     train_dataset = LitDataset(train_df.loc[train_indices])    \n",
    "#     val_dataset = LitDataset(train_df.loc[val_indices])    \n",
    "        \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "#                               drop_last=True, shuffle=True, num_workers=2)    \n",
    "#     val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "#                             drop_last=False, shuffle=False, num_workers=2)    \n",
    "        \n",
    "#     set_random_seed(SEED + fold)    \n",
    "    \n",
    "#     model = LitModel().to(DEVICE)\n",
    "    \n",
    "#     optimizer = create_optimizer(model)                        \n",
    "#     scheduler = get_cosine_schedule_with_warmup(\n",
    "#         optimizer,\n",
    "#         num_training_steps=NUM_EPOCHS * len(train_loader),\n",
    "#         num_warmup_steps=50)    \n",
    "    \n",
    "#     list_val_rmse.append(train(model, model_path, train_loader,\n",
    "#                                val_loader, optimizer, scheduler=scheduler))\n",
    "\n",
    "#     del model\n",
    "#     gc.collect()\n",
    "    \n",
    "#     print(\"\\nPerformance estimates:\")\n",
    "#     print(list_val_rmse)\n",
    "#     print(\"Mean:\", np.array(list_val_rmse).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-prompt",
   "metadata": {
    "papermill": {
     "duration": 0.014936,
     "end_time": "2021-08-02T11:18:07.357243",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.342307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "existing-queue",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.392473Z",
     "iopub.status.busy": "2021-08-02T11:18:07.391899Z",
     "iopub.status.idle": "2021-08-02T11:18:07.407637Z",
     "shell.execute_reply": "2021-08-02T11:18:07.407192Z",
     "shell.execute_reply.started": "2021-08-02T11:16:26.457182Z"
    },
    "papermill": {
     "duration": 0.03491,
     "end_time": "2021-08-02T11:18:07.407747",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.372837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = LitDataset(test_df, inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "french-nutrition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:18:07.450405Z",
     "iopub.status.busy": "2021-08-02T11:18:07.449452Z",
     "iopub.status.idle": "2021-08-02T11:19:10.574055Z",
     "shell.execute_reply": "2021-08-02T11:19:10.573577Z"
    },
    "papermill": {
     "duration": 63.14946,
     "end_time": "2021-08-02T11:19:10.574190",
     "exception": false,
     "start_time": "2021-08-02T11:18:07.424730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_2.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_3.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_4.pth\n",
      "\n",
      "Using ../input/pre-trained-roberta-solution-in-pytorch-train/model_5.pth\n"
     ]
    }
   ],
   "source": [
    "all_predictions = np.zeros((NUM_FOLDS, len(test_df)))\n",
    "\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "for index in range(NUM_FOLDS):            \n",
    "    model_path = f\"../input/pre-trained-roberta-solution-in-pytorch-train/model_{index + 1}.pth\" #../input/pre-trained-roberta-solution-in-pytorch-train/model_1.pth\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_predictions[index] = predict(model, test_loader)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "divided-hospital",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:19:10.614517Z",
     "iopub.status.busy": "2021-08-02T11:19:10.612716Z",
     "iopub.status.idle": "2021-08-02T11:19:10.615875Z",
     "shell.execute_reply": "2021-08-02T11:19:10.615284Z"
    },
    "papermill": {
     "duration": 0.024886,
     "end_time": "2021-08-02T11:19:10.615996",
     "exception": false,
     "start_time": "2021-08-02T11:19:10.591110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = all_predictions.mean(axis=0)\n",
    "# submission_df.target = predictions\n",
    "# print(submission_df)\n",
    "# submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "obvious-oliver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T11:19:10.663909Z",
     "iopub.status.busy": "2021-08-02T11:19:10.663183Z",
     "iopub.status.idle": "2021-08-02T11:19:10.794136Z",
     "shell.execute_reply": "2021-08-02T11:19:10.794835Z"
    },
    "papermill": {
     "duration": 0.15974,
     "end_time": "2021-08-02T11:19:10.794990",
     "exception": false,
     "start_time": "2021-08-02T11:19:10.635250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.534057\n",
      "1  f0953f0a5 -0.536830\n",
      "2  0df072751 -0.471099\n",
      "3  04caf4e0c -2.565871\n",
      "4  0e63f8bea -1.846540\n",
      "5  12537fe78 -1.400859\n",
      "6  965e592c0  0.292373\n"
     ]
    }
   ],
   "source": [
    "test_df['target']=predictions\n",
    "# submission_df.target = predictions\n",
    "cols_to_keep=['id','target']\n",
    "print(test_df[cols_to_keep])\n",
    "test_df.loc[:, cols_to_keep].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-validation",
   "metadata": {
    "papermill": {
     "duration": 0.018158,
     "end_time": "2021-08-02T11:19:10.830065",
     "exception": false,
     "start_time": "2021-08-02T11:19:10.811907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-harris",
   "metadata": {
    "papermill": {
     "duration": 0.01824,
     "end_time": "2021-08-02T11:19:10.868439",
     "exception": false,
     "start_time": "2021-08-02T11:19:10.850199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 81.826297,
   "end_time": "2021-08-02T11:19:13.887009",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-02T11:17:52.060712",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
