{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c200a467",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:01.498742Z",
     "iopub.status.busy": "2021-09-10T11:08:01.497379Z",
     "iopub.status.idle": "2021-09-10T11:08:01.500983Z",
     "shell.execute_reply": "2021-09-10T11:08:01.501406Z",
     "shell.execute_reply.started": "2021-09-10T09:32:22.537783Z"
    },
    "papermill": {
     "duration": 0.039202,
     "end_time": "2021-09-10T11:08:01.501633",
     "exception": false,
     "start_time": "2021-09-10T11:08:01.462431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324d688a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:01.657089Z",
     "iopub.status.busy": "2021-09-10T11:08:01.647845Z",
     "iopub.status.idle": "2021-09-10T11:08:11.316636Z",
     "shell.execute_reply": "2021-09-10T11:08:11.316020Z",
     "shell.execute_reply.started": "2021-09-10T09:32:22.819053Z"
    },
    "papermill": {
     "duration": 9.784958,
     "end_time": "2021-09-10T11:08:11.316790",
     "exception": false,
     "start_time": "2021-09-10T11:08:01.531832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-cloud 0.1.13 requires tensorflow<3.0,>=1.15.0, which is not installed.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda112, which is not installed.\r\n",
      "cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda110, which is not installed.\r\n",
      "s3fs 2021.6.1 requires fsspec==2021.06.1, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "pytorch-lightning 1.3.8 requires fsspec[http]!=2021.06.0,>=2021.05.0, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires dask<=2021.5.1,>=2021.4.0, but you have dask 2021.6.2 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires distributed<=2021.5.1,>=2.22.0, but you have distributed 2021.6.2 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# ! pip install datasets transformers\n",
    "!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32290ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:11.391743Z",
     "iopub.status.busy": "2021-09-10T11:08:11.386127Z",
     "iopub.status.idle": "2021-09-10T11:08:11.818703Z",
     "shell.execute_reply": "2021-09-10T11:08:11.818185Z",
     "shell.execute_reply.started": "2021-09-10T09:32:31.887688Z"
    },
    "papermill": {
     "duration": 0.467638,
     "end_time": "2021-09-10T11:08:11.818839",
     "exception": false,
     "start_time": "2021-09-10T11:08:11.351201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4884f",
   "metadata": {
    "papermill": {
     "duration": 0.030065,
     "end_time": "2021-09-10T11:08:11.879204",
     "exception": false,
     "start_time": "2021-09-10T11:08:11.849139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db811eaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:11.944721Z",
     "iopub.status.busy": "2021-09-10T11:08:11.944003Z",
     "iopub.status.idle": "2021-09-10T11:08:18.994996Z",
     "shell.execute_reply": "2021-09-10T11:08:18.994141Z",
     "shell.execute_reply.started": "2021-09-10T09:32:32.577857Z"
    },
    "papermill": {
     "duration": 7.085149,
     "end_time": "2021-09-10T11:08:18.995128",
     "exception": false,
     "start_time": "2021-09-10T11:08:11.909979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_checkpoint = \"distilbert-base-uncased\"\n",
    "# model_checkpoint = \"deepset/xlm-roberta-large-squad2\"\n",
    "# model_checkpoint = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-base-squad2\"\n",
    "model_checkpoint = \"../input/pipeline-for-qa-train-with-5-folds/chaii-trained-model-0\"\n",
    "\n",
    "from transformers import XLMTokenizer,AutoTokenizer\n",
    "# tokenizer = XLMTokenizer.from_pretrained('xlm-mlm-en-2048')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e9085c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.063027Z",
     "iopub.status.busy": "2021-09-10T11:08:19.061500Z",
     "iopub.status.idle": "2021-09-10T11:08:19.063842Z",
     "shell.execute_reply": "2021-09-10T11:08:19.064265Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.478402Z"
    },
    "papermill": {
     "duration": 0.038312,
     "end_time": "2021-09-10T11:08:19.064463",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.026151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b51fc",
   "metadata": {
    "papermill": {
     "duration": 0.030069,
     "end_time": "2021-09-10T11:08:19.124906",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.094837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Doc_stride is used to handle large text: tokens>512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc307dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.190492Z",
     "iopub.status.busy": "2021-09-10T11:08:19.189565Z",
     "iopub.status.idle": "2021-09-10T11:08:19.192202Z",
     "shell.execute_reply": "2021-09-10T11:08:19.191774Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.486636Z"
    },
    "papermill": {
     "duration": 0.036835,
     "end_time": "2021-09-10T11:08:19.192322",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.155487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 384 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945b71f",
   "metadata": {
    "papermill": {
     "duration": 0.030077,
     "end_time": "2021-09-10T11:08:19.252341",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.222264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e19483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.317992Z",
     "iopub.status.busy": "2021-09-10T11:08:19.317440Z",
     "iopub.status.idle": "2021-09-10T11:08:19.356197Z",
     "shell.execute_reply": "2021-09-10T11:08:19.355671Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.495957Z"
    },
    "papermill": {
     "duration": 0.073753,
     "end_time": "2021-09-10T11:08:19.356328",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.282575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
    "test_dataset = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e308586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.421226Z",
     "iopub.status.busy": "2021-09-10T11:08:19.420350Z",
     "iopub.status.idle": "2021-09-10T11:08:19.423041Z",
     "shell.execute_reply": "2021-09-10T11:08:19.422641Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.542462Z"
    },
    "papermill": {
     "duration": 0.036049,
     "end_time": "2021-09-10T11:08:19.423153",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.387104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4630117",
   "metadata": {
    "papermill": {
     "duration": 0.029893,
     "end_time": "2021-09-10T11:08:19.483336",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.453443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83db45ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.553022Z",
     "iopub.status.busy": "2021-09-10T11:08:19.552150Z",
     "iopub.status.idle": "2021-09-10T11:08:19.554339Z",
     "shell.execute_reply": "2021-09-10T11:08:19.554701Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.550854Z"
    },
    "papermill": {
     "duration": 0.04093,
     "end_time": "2021-09-10T11:08:19.554833",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.513903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In some padding required on left side\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "def prepare_validation_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397ea403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.619064Z",
     "iopub.status.busy": "2021-09-10T11:08:19.618266Z",
     "iopub.status.idle": "2021-09-10T11:08:19.620939Z",
     "shell.execute_reply": "2021-09-10T11:08:19.620531Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.562778Z"
    },
    "papermill": {
     "duration": 0.036235,
     "end_time": "2021-09-10T11:08:19.621049",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.584814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features = prepare_validation_features(test_dataset[:5])\n",
    "# print(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7828d76d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:19.714741Z",
     "iopub.status.busy": "2021-09-10T11:08:19.713905Z",
     "iopub.status.idle": "2021-09-10T11:08:20.108676Z",
     "shell.execute_reply": "2021-09-10T11:08:20.108239Z",
     "shell.execute_reply.started": "2021-09-10T09:32:39.574872Z"
    },
    "papermill": {
     "duration": 0.457565,
     "end_time": "2021-09-10T11:08:20.108819",
     "exception": false,
     "start_time": "2021-09-10T11:08:19.651254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4ef456012d4ad5a62e7a9f9ff20a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " validation_features = test_dataset.map(\n",
    "        prepare_validation_features,\n",
    "        batched=True,\n",
    "        remove_columns=test_dataset.column_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc95686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:20.176924Z",
     "iopub.status.busy": "2021-09-10T11:08:20.176349Z",
     "iopub.status.idle": "2021-09-10T11:08:20.180050Z",
     "shell.execute_reply": "2021-09-10T11:08:20.180445Z",
     "shell.execute_reply.started": "2021-09-10T09:32:40.021553Z"
    },
    "papermill": {
     "duration": 0.040153,
     "end_time": "2021-09-10T11:08:20.180595",
     "exception": false,
     "start_time": "2021-09-10T11:08:20.140442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import collections\n",
    "\n",
    "\n",
    "# def postprocess_qa_predictions(examples, features, start_logits_cons, end_logits_cons, n_best_size = 20, \n",
    "#                                max_answer_length = 30):\n",
    "#     all_start_logits = start_logits_cons\n",
    "#     all_end_logits = end_logits_cons\n",
    "# #     all_start_logits, all_end_logits = raw_predictions\n",
    "#     # Build a map example to its corresponding features.\n",
    "#     example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "#     features_per_example = collections.defaultdict(list)\n",
    "#     for i, feature in enumerate(features):\n",
    "#         features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "#     # The dictionaries we have to fill.\n",
    "#     predictions = collections.OrderedDict()\n",
    "\n",
    "#     # Logging.\n",
    "#     print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "#     # Let's loop over all the examples!\n",
    "#     for example_index, example in enumerate(tqdm(examples)):\n",
    "#         # Those are the indices of the features associated to the current example.\n",
    "#         feature_indices = features_per_example[example_index]\n",
    "\n",
    "#         min_null_score = None # Only used if squad_v2 is True.\n",
    "#         valid_answers = []\n",
    "        \n",
    "#         context = example[\"context\"]\n",
    "#         # Looping through all the features associated to the current example.\n",
    "#         for feature_index in feature_indices:\n",
    "#             # We grab the predictions of the model for this feature.\n",
    "#             start_logits = all_start_logits[feature_index]\n",
    "#             end_logits = all_end_logits[feature_index]\n",
    "#             # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "#             # context.\n",
    "#             offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "#             # Update minimum null prediction.\n",
    "#             cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "#             feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "#             if min_null_score is None or min_null_score < feature_null_score:\n",
    "#                 min_null_score = feature_null_score\n",
    "\n",
    "#             # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "#             start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "#             end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "#             for start_index in start_indexes:\n",
    "#                 for end_index in end_indexes:\n",
    "#                     # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "#                     # to part of the input_ids that are not in the context.\n",
    "#                     if (\n",
    "#                         start_index >= len(offset_mapping)\n",
    "#                         or end_index >= len(offset_mapping)\n",
    "#                         or offset_mapping[start_index] is None\n",
    "#                         or offset_mapping[end_index] is None\n",
    "#                     ):\n",
    "#                         continue\n",
    "#                     # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "#                     if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "#                         continue\n",
    "\n",
    "#                     start_char = offset_mapping[start_index][0]\n",
    "#                     end_char = offset_mapping[end_index][1]\n",
    "#                     valid_answers.append(\n",
    "#                         {\n",
    "#                             \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "#                             \"text\": context[start_char: end_char]\n",
    "#                         }\n",
    "#                     )\n",
    "        \n",
    "#         if len(valid_answers) > 0:\n",
    "#             best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "#         else:\n",
    "#             # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "#             # failure.\n",
    "#             best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "#         # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "# #         if not squad_v2:\n",
    "#         predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "# #         else:\n",
    "# #             answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "# #             predictions[example[\"id\"]] = answer\n",
    "\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4cf23",
   "metadata": {
    "papermill": {
     "duration": 0.03111,
     "end_time": "2021-09-10T11:08:20.242615",
     "exception": false,
     "start_time": "2021-09-10T11:08:20.211505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3584afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:20.310455Z",
     "iopub.status.busy": "2021-09-10T11:08:20.309688Z",
     "iopub.status.idle": "2021-09-10T11:08:21.147424Z",
     "shell.execute_reply": "2021-09-10T11:08:21.146939Z",
     "shell.execute_reply.started": "2021-09-10T09:32:40.029541Z"
    },
    "papermill": {
     "duration": 0.873498,
     "end_time": "2021-09-10T11:08:21.147555",
     "exception": false,
     "start_time": "2021-09-10T11:08:20.274057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "gc.collect()\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244fbf8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:08:21.215488Z",
     "iopub.status.busy": "2021-09-10T11:08:21.214569Z",
     "iopub.status.idle": "2021-09-10T11:11:08.939437Z",
     "shell.execute_reply": "2021-09-10T11:11:08.940502Z",
     "shell.execute_reply.started": "2021-09-10T09:32:40.865661Z"
    },
    "papermill": {
     "duration": 167.76214,
     "end_time": "2021-09-10T11:11:08.940738",
     "exception": false,
     "start_time": "2021-09-10T11:08:21.178598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting using model 0 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 0 complete\n",
      "-----------------------------------\n",
      "predicting using model 1 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 1 complete\n",
      "-----------------------------------\n",
      "predicting using model 2 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 2 complete\n",
      "-----------------------------------\n",
      "predicting using model 3 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 3 complete\n",
      "-----------------------------------\n",
      "predicting using model 4 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 4 complete\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = []\n",
    "for i in range(folds):\n",
    "    print(f'predicting using model {i} start')\n",
    "    model_checkpoint = f\"../input/pipeline-for-qa-train-with-5-folds/chaii-trained-model-{i}\"\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "    trainer = Trainer(model)\n",
    "    raw_predictions.append(trainer.predict(validation_features))\n",
    "    print(f'prediction of model {i} complete')\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7c3628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:09.061068Z",
     "iopub.status.busy": "2021-09-10T11:11:09.060083Z",
     "iopub.status.idle": "2021-09-10T11:11:09.062443Z",
     "shell.execute_reply": "2021-09-10T11:11:09.061786Z",
     "shell.execute_reply.started": "2021-09-10T09:35:19.980903Z"
    },
    "papermill": {
     "duration": 0.065435,
     "end_time": "2021-09-10T11:11:09.062608",
     "exception": false,
     "start_time": "2021-09-10T11:11:08.997173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c54905f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:09.187408Z",
     "iopub.status.busy": "2021-09-10T11:11:09.186506Z",
     "iopub.status.idle": "2021-09-10T11:11:09.192068Z",
     "shell.execute_reply": "2021-09-10T11:11:09.192851Z",
     "shell.execute_reply.started": "2021-09-10T09:35:19.990042Z"
    },
    "papermill": {
     "duration": 0.069,
     "end_time": "2021-09-10T11:11:09.193104",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.124104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4768ef",
   "metadata": {
    "papermill": {
     "duration": 0.056574,
     "end_time": "2021-09-10T11:11:09.306544",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.249970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f03e29a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:09.428498Z",
     "iopub.status.busy": "2021-09-10T11:11:09.427718Z",
     "iopub.status.idle": "2021-09-10T11:11:09.434348Z",
     "shell.execute_reply": "2021-09-10T11:11:09.435121Z",
     "shell.execute_reply.started": "2021-09-10T09:35:20.006998Z"
    },
    "papermill": {
     "duration": 0.071508,
     "end_time": "2021-09-10T11:11:09.435330",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.363822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "start_logits_cons = 0\n",
    "end_logits_cons = 0\n",
    "for raw_prediction in raw_predictions:\n",
    "    sc, ec = raw_prediction.predictions\n",
    "    sc = sc/folds\n",
    "    ec = ec/folds\n",
    "    start_logits_cons += sc\n",
    "    end_logits_cons += ec\n",
    "print(len(start_logits_cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a16bbc12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:09.557324Z",
     "iopub.status.busy": "2021-09-10T11:11:09.556462Z",
     "iopub.status.idle": "2021-09-10T11:11:09.558650Z",
     "shell.execute_reply": "2021-09-10T11:11:09.558002Z",
     "shell.execute_reply.started": "2021-09-10T09:35:20.02482Z"
    },
    "papermill": {
     "duration": 0.066376,
     "end_time": "2021-09-10T11:11:09.558801",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.492425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_logits_cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c237332",
   "metadata": {
    "papermill": {
     "duration": 0.05665,
     "end_time": "2021-09-10T11:11:09.671955",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.615305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67092ae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:09.798691Z",
     "iopub.status.busy": "2021-09-10T11:11:09.797883Z",
     "iopub.status.idle": "2021-09-10T11:11:09.839325Z",
     "shell.execute_reply": "2021-09-10T11:11:09.838867Z",
     "shell.execute_reply.started": "2021-09-10T09:35:20.037441Z"
    },
    "papermill": {
     "duration": 0.109914,
     "end_time": "2021-09-10T11:11:09.839449",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.729535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex AMP Installed :: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn import model_selection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader,\n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "    APEX_INSTALLED = True\n",
    "except ImportError:\n",
    "    APEX_INSTALLED = False\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    logging,\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    ")\n",
    "logging.set_verbosity_warning()\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def optimal_num_of_loader_workers():\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    optimal_value = min(num_cpus, num_gpus*4) if num_gpus else num_cpus - 1\n",
    "    return optimal_value\n",
    "\n",
    "print(f\"Apex AMP Installed :: {APEX_INSTALLED}\")\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5198e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:09.921284Z",
     "iopub.status.busy": "2021-09-10T11:11:09.920614Z",
     "iopub.status.idle": "2021-09-10T11:11:09.923356Z",
     "shell.execute_reply": "2021-09-10T11:11:09.923733Z",
     "shell.execute_reply.started": "2021-09-10T09:39:25.211774Z"
    },
    "papermill": {
     "duration": 0.04969,
     "end_time": "2021-09-10T11:11:09.923876",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.874186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # model\n",
    "    model_type = 'xlm_roberta'\n",
    "    model_name_or_path = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2/\"\n",
    "    config_name = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2/\"\n",
    "    fp16 = True if APEX_INSTALLED else False\n",
    "    fp16_opt_level = \"O1\"\n",
    "    gradient_accumulation_steps = 2\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer_name = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2/\"\n",
    "    max_seq_length = 384\n",
    "    doc_stride = 128\n",
    "\n",
    "    # train\n",
    "    epochs = 1\n",
    "    train_batch_size = 4\n",
    "    eval_batch_size = 32#8\n",
    "\n",
    "    # optimizer\n",
    "    optimizer_type = 'AdamW'\n",
    "    learning_rate = 1.5e-5\n",
    "    weight_decay = 1e-2\n",
    "    epsilon = 1e-8\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    # scheduler\n",
    "    decay_name = 'linear-warmup'\n",
    "    warmup_ratio = 0.1\n",
    "\n",
    "    # logging\n",
    "    logging_steps = 10\n",
    "\n",
    "    # evaluate\n",
    "    output_dir = 'output'\n",
    "    seed = 2021\n",
    "    \n",
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, features, mode='train'):\n",
    "        super(DatasetRetriever, self).__init__()\n",
    "        self.features = features\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, item):   \n",
    "        feature = self.features[item]\n",
    "        if self.mode == 'train':\n",
    "            return {\n",
    "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
    "                'offset_mapping':torch.tensor(feature['offset_mapping'], dtype=torch.long),\n",
    "                'start_position':torch.tensor(feature['start_position'], dtype=torch.long),\n",
    "                'end_position':torch.tensor(feature['end_position'], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
    "                'offset_mapping':feature['offset_mapping'],\n",
    "                'sequence_ids':feature['sequence_ids'],\n",
    "                'id':feature['example_id'],\n",
    "                'context': feature['context'],\n",
    "                'question': feature['question']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d7d7728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:10.002820Z",
     "iopub.status.busy": "2021-09-10T11:11:10.002105Z",
     "iopub.status.idle": "2021-09-10T11:11:10.005519Z",
     "shell.execute_reply": "2021-09-10T11:11:10.005094Z",
     "shell.execute_reply.started": "2021-09-10T09:39:25.71828Z"
    },
    "papermill": {
     "duration": 0.046932,
     "end_time": "2021-09-10T11:11:10.005636",
     "exception": false,
     "start_time": "2021-09-10T11:11:09.958704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, modelname_or_path, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.xlm_roberta = AutoModel.from_pretrained(modelname_or_path, config=config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, 2)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self._init_weights(self.qa_outputs)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids, \n",
    "        attention_mask=None, \n",
    "    ):\n",
    "        outputs = self.xlm_roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]\n",
    "        \n",
    "        # sequence_output = self.dropout(sequence_output)\n",
    "        qa_logits = self.qa_outputs(sequence_output)\n",
    "        \n",
    "        start_logits, end_logits = qa_logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "    \n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1061b26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:10.080352Z",
     "iopub.status.busy": "2021-09-10T11:11:10.079721Z",
     "iopub.status.idle": "2021-09-10T11:11:10.083642Z",
     "shell.execute_reply": "2021-09-10T11:11:10.083206Z",
     "shell.execute_reply.started": "2021-09-10T09:39:26.068036Z"
    },
    "papermill": {
     "duration": 0.043305,
     "end_time": "2021-09-10T11:11:10.083755",
     "exception": false,
     "start_time": "2021-09-10T11:11:10.040450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(args):\n",
    "    config = AutoConfig.from_pretrained(args.config_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
    "    model = Model(args.model_name_or_path, config=config)\n",
    "    return config, tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c46c7358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:10.167067Z",
     "iopub.status.busy": "2021-09-10T11:11:10.166099Z",
     "iopub.status.idle": "2021-09-10T11:11:10.170401Z",
     "shell.execute_reply": "2021-09-10T11:11:10.169867Z",
     "shell.execute_reply.started": "2021-09-10T09:39:26.411773Z"
    },
    "papermill": {
     "duration": 0.048077,
     "end_time": "2021-09-10T11:11:10.170525",
     "exception": false,
     "start_time": "2021-09-10T11:11:10.122448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_test_features(args, example, tokenizer):\n",
    "    example[\"question\"] = example[\"question\"].lstrip()\n",
    "    \n",
    "    tokenized_example = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=args.max_seq_length,\n",
    "        stride=args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(tokenized_example[\"input_ids\"])):\n",
    "        feature = {}\n",
    "        feature[\"example_id\"] = example['id']\n",
    "        feature['context'] = example['context']\n",
    "        feature['question'] = example['question']\n",
    "        feature['input_ids'] = tokenized_example['input_ids'][i]\n",
    "        feature['attention_mask'] = tokenized_example['attention_mask'][i]\n",
    "        feature['offset_mapping'] = tokenized_example['offset_mapping'][i]\n",
    "        feature['sequence_ids'] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe51e448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:10.248477Z",
     "iopub.status.busy": "2021-09-10T11:11:10.247914Z",
     "iopub.status.idle": "2021-09-10T11:11:11.790369Z",
     "shell.execute_reply": "2021-09-10T11:11:11.789460Z",
     "shell.execute_reply.started": "2021-09-10T09:39:26.842655Z"
    },
    "papermill": {
     "duration": 1.583633,
     "end_time": "2021-09-10T11:11:11.790515",
     "exception": false,
     "start_time": "2021-09-10T11:11:10.206882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
    "base_model_path = '../input/chaii-xlmroberta-large-v6/output/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config().tokenizer_name)\n",
    "\n",
    "test_features = []\n",
    "for i, row in test.iterrows():\n",
    "    test_features += prepare_test_features(Config(), row, tokenizer)\n",
    "\n",
    "args = Config()\n",
    "test_dataset = DatasetRetriever(test_features, mode='test')\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.eval_batch_size, \n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    num_workers=optimal_num_of_loader_workers(),\n",
    "    pin_memory=True, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b6a31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:11.869964Z",
     "iopub.status.busy": "2021-09-10T11:11:11.869360Z",
     "iopub.status.idle": "2021-09-10T11:11:11.872641Z",
     "shell.execute_reply": "2021-09-10T11:11:11.872179Z",
     "shell.execute_reply.started": "2021-09-10T09:39:27.882272Z"
    },
    "papermill": {
     "duration": 0.046527,
     "end_time": "2021-09-10T11:11:11.872754",
     "exception": false,
     "start_time": "2021-09-10T11:11:11.826227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(checkpoint_path):\n",
    "    config, tokenizer, model = make_model(Config())\n",
    "    print(f'model loading: {checkpoint_path}')\n",
    "    model.cuda();\n",
    "    model.load_state_dict(\n",
    "        torch.load(base_model_path + checkpoint_path)\n",
    "    );\n",
    "    \n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs_start, outputs_end = model(batch['input_ids'].cuda(), batch['attention_mask'].cuda())\n",
    "            start_logits.append(outputs_start.cpu().numpy().tolist())\n",
    "            end_logits.append(outputs_end.cpu().numpy().tolist())\n",
    "            del outputs_start, outputs_end\n",
    "    del model, tokenizer, config\n",
    "    gc.collect()\n",
    "    return np.vstack(start_logits), np.vstack(end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b345a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:11:11.948068Z",
     "iopub.status.busy": "2021-09-10T11:11:11.947508Z",
     "iopub.status.idle": "2021-09-10T11:14:33.456342Z",
     "shell.execute_reply": "2021-09-10T11:14:33.455543Z"
    },
    "papermill": {
     "duration": 201.548664,
     "end_time": "2021-09-10T11:14:33.456479",
     "exception": false,
     "start_time": "2021-09-10T11:11:11.907815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading: checkpoint-fold-0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading: checkpoint-fold-1/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading: checkpoint-fold-2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading: checkpoint-fold-3/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading: checkpoint-fold-4/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "start_logits1, end_logits1 = get_predictions('checkpoint-fold-0/pytorch_model.bin')\n",
    "start_logits2, end_logits2 = get_predictions('checkpoint-fold-1/pytorch_model.bin')\n",
    "start_logits3, end_logits3 = get_predictions('checkpoint-fold-2/pytorch_model.bin')\n",
    "start_logits4, end_logits4 = get_predictions('checkpoint-fold-3/pytorch_model.bin')\n",
    "start_logits5, end_logits5 = get_predictions('checkpoint-fold-4/pytorch_model.bin')\n",
    "\n",
    "start_logits = (start_logits1 + start_logits2 + start_logits3 + start_logits4 + start_logits5) / 5\n",
    "end_logits = (end_logits1 + end_logits2 + end_logits3 + end_logits4 + end_logits5) / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7853232",
   "metadata": {
    "papermill": {
     "duration": 0.043651,
     "end_time": "2021-09-10T11:14:33.544308",
     "exception": false,
     "start_time": "2021-09-10T11:14:33.500657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensembled logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8249da8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:33.637905Z",
     "iopub.status.busy": "2021-09-10T11:14:33.637218Z",
     "iopub.status.idle": "2021-09-10T11:14:33.648555Z",
     "shell.execute_reply": "2021-09-10T11:14:33.648069Z",
     "shell.execute_reply.started": "2021-09-10T09:30:49.472175Z"
    },
    "papermill": {
     "duration": 0.060416,
     "end_time": "2021-09-10T11:14:33.648694",
     "exception": false,
     "start_time": "2021-09-10T11:14:33.588278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "normalizer = torch.nn.Softmax(dim=1)\n",
    "\n",
    "start_logits = normalizer(torch.from_numpy(start_logits))\n",
    "end_logits = normalizer(torch.from_numpy(end_logits))\n",
    "\n",
    "start_logits = start_logits.numpy()\n",
    "end_logits = end_logits.numpy()\n",
    "\n",
    "\n",
    "start_logits_cons = normalizer(torch.from_numpy(start_logits_cons))\n",
    "end_logits_cons = normalizer(torch.from_numpy(end_logits_cons))\n",
    "\n",
    "start_logits_cons = start_logits_cons.numpy()\n",
    "end_logits_cons = end_logits_cons.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acb41b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:33.740920Z",
     "iopub.status.busy": "2021-09-10T11:14:33.740395Z",
     "iopub.status.idle": "2021-09-10T11:14:33.744877Z",
     "shell.execute_reply": "2021-09-10T11:14:33.744449Z",
     "shell.execute_reply.started": "2021-09-10T09:30:49.668041Z"
    },
    "papermill": {
     "duration": 0.052359,
     "end_time": "2021-09-10T11:14:33.744991",
     "exception": false,
     "start_time": "2021-09-10T11:14:33.692632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = 0.4#0.5\n",
    "model2 = 0.6#0.5\n",
    "\n",
    "final_start_logits = model1*start_logits_cons + model2*start_logits\n",
    "final_end_logits = model1*end_logits_cons + model2*end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a91ee1",
   "metadata": {
    "papermill": {
     "duration": 0.043694,
     "end_time": "2021-09-10T11:14:33.832919",
     "exception": false,
     "start_time": "2021-09-10T11:14:33.789225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a342d707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:33.937098Z",
     "iopub.status.busy": "2021-09-10T11:14:33.936510Z",
     "iopub.status.idle": "2021-09-10T11:14:33.940477Z",
     "shell.execute_reply": "2021-09-10T11:14:33.940045Z",
     "shell.execute_reply.started": "2021-09-10T09:30:50.351989Z"
    },
    "papermill": {
     "duration": 0.063488,
     "end_time": "2021-09-10T11:14:33.940609",
     "exception": false,
     "start_time": "2021-09-10T11:14:33.877121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    \n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in examples.iterrows():\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "\n",
    "            sequence_ids = features[feature_index][\"sequence_ids\"]\n",
    "            context_index = 1\n",
    "\n",
    "            features[feature_index][\"offset_mapping\"] = [\n",
    "                (o if sequence_ids[k] == context_index else None)\n",
    "                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n",
    "            ]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        \n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a48b12b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:34.036969Z",
     "iopub.status.busy": "2021-09-10T11:14:34.036150Z",
     "iopub.status.idle": "2021-09-10T11:14:34.068660Z",
     "shell.execute_reply": "2021-09-10T11:14:34.068157Z",
     "shell.execute_reply.started": "2021-09-10T09:30:21.429875Z"
    },
    "papermill": {
     "duration": 0.083504,
     "end_time": "2021-09-10T11:14:34.068782",
     "exception": false,
     "start_time": "2021-09-10T11:14:33.985278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 67 features.\n"
     ]
    }
   ],
   "source": [
    "# final_predictions = postprocess_qa_predictions(test_dataset, validation_features, final_start_logits, final_end_logits)\n",
    "# final_predictions = postprocess_qa_predictions(test_dataset, validation_features, start_logits_cons, end_logits_cons)\n",
    "predictions = postprocess_qa_predictions(test, test_features, (final_start_logits, final_end_logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1d265c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:34.174402Z",
     "iopub.status.busy": "2021-09-10T11:14:34.172328Z",
     "iopub.status.idle": "2021-09-10T11:14:34.176988Z",
     "shell.execute_reply": "2021-09-10T11:14:34.176585Z",
     "shell.execute_reply.started": "2021-09-10T09:30:21.475586Z"
    },
    "papermill": {
     "duration": 0.063804,
     "end_time": "2021-09-10T11:14:34.177118",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.113314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['PredictionString'] = test['id'].map(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7a971e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:34.271092Z",
     "iopub.status.busy": "2021-09-10T11:14:34.270555Z",
     "iopub.status.idle": "2021-09-10T11:14:34.287874Z",
     "shell.execute_reply": "2021-09-10T11:14:34.288368Z",
     "shell.execute_reply.started": "2021-09-10T09:30:21.49375Z"
    },
    "papermill": {
     "duration": 0.066889,
     "end_time": "2021-09-10T11:14:34.288517",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.221628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       20 अप्रैल 2010  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cfa716",
   "metadata": {
    "papermill": {
     "duration": 0.04474,
     "end_time": "2021-09-10T11:14:34.378074",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.333334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f83bd4f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:34.487837Z",
     "iopub.status.busy": "2021-09-10T11:14:34.486922Z",
     "iopub.status.idle": "2021-09-10T11:14:34.489666Z",
     "shell.execute_reply": "2021-09-10T11:14:34.489239Z",
     "shell.execute_reply.started": "2021-09-10T09:30:21.520782Z"
    },
    "papermill": {
     "duration": 0.065894,
     "end_time": "2021-09-10T11:14:34.489789",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.423895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
    "bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
    "\n",
    "tamil_ad = \"கி.பி\"\n",
    "tamil_bc = \"கி.மு\"\n",
    "tamil_km = \"கி.மீ\"\n",
    "hindi_ad = \"ई\"\n",
    "hindi_bc = \"ई.पू\"\n",
    "\n",
    "\n",
    "cleaned_preds = []\n",
    "for pred, context in test[[\"PredictionString\", \"context\"]].to_numpy():\n",
    "    if pred == \"\":\n",
    "        cleaned_preds.append(pred)\n",
    "        continue\n",
    "    while any([pred.startswith(y) for y in bad_starts]):\n",
    "        pred = pred[1:]\n",
    "    while any([pred.endswith(y) for y in bad_endings]):\n",
    "        if pred.endswith(\"...\"):\n",
    "            pred = pred[:-3]\n",
    "        else:\n",
    "            pred = pred[:-1]\n",
    "    \n",
    "    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
    "        pred = pred+\".\"\n",
    "\n",
    "    cleaned_preds.append(pred)\n",
    "\n",
    "test[\"PredictionString\"] = cleaned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ac7d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:34.590624Z",
     "iopub.status.busy": "2021-09-10T11:14:34.589781Z",
     "iopub.status.idle": "2021-09-10T11:14:34.593141Z",
     "shell.execute_reply": "2021-09-10T11:14:34.593572Z",
     "shell.execute_reply.started": "2021-09-10T09:30:21.539432Z"
    },
    "papermill": {
     "duration": 0.059341,
     "end_time": "2021-09-10T11:14:34.593715",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.534374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       20 अप्रैल 2010  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd071f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T11:14:34.689317Z",
     "iopub.status.busy": "2021-09-10T11:14:34.688672Z",
     "iopub.status.idle": "2021-09-10T11:14:34.695468Z",
     "shell.execute_reply": "2021-09-10T11:14:34.694899Z",
     "shell.execute_reply.started": "2021-09-10T09:30:21.560683Z"
    },
    "papermill": {
     "duration": 0.056755,
     "end_time": "2021-09-10T11:14:34.695588",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.638833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[['id','PredictionString']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b2ffb",
   "metadata": {
    "papermill": {
     "duration": 0.045152,
     "end_time": "2021-09-10T11:14:34.786333",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.741181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712303c",
   "metadata": {
    "papermill": {
     "duration": 0.044992,
     "end_time": "2021-09-10T11:14:34.876651",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.831659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27842944",
   "metadata": {
    "papermill": {
     "duration": 0.044635,
     "end_time": "2021-09-10T11:14:34.966447",
     "exception": false,
     "start_time": "2021-09-10T11:14:34.921812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 403.744123,
   "end_time": "2021-09-10T11:14:38.419930",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-10T11:07:54.675807",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1efb71cf147740f9ad52f6ceb069724d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53146e65f94844b88a91c10075ec6063": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6973856e7d0b4b4e90e0f3fa0c45c8d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6e4ef456012d4ad5a62e7a9f9ff20a28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b971940ae968475ba9ef980277a2c7e0",
        "IPY_MODEL_dc0611d6525a4bdcb953b2af8a809836"
       ],
       "layout": "IPY_MODEL_9958639e7cd449bcb2034c786e85a8f6"
      }
     },
     "9958639e7cd449bcb2034c786e85a8f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b971940ae968475ba9ef980277a2c7e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f30fddaa1e484bed8802cd457aef1894",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6973856e7d0b4b4e90e0f3fa0c45c8d0",
       "value": 1.0
      }
     },
     "dc0611d6525a4bdcb953b2af8a809836": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1efb71cf147740f9ad52f6ceb069724d",
       "placeholder": "​",
       "style": "IPY_MODEL_53146e65f94844b88a91c10075ec6063",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fa95d28e250&gt;"
      }
     },
     "f30fddaa1e484bed8802cd457aef1894": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
