{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1dbb99",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:22.803925Z",
     "iopub.status.busy": "2021-11-03T04:19:22.793718Z",
     "iopub.status.idle": "2021-11-03T04:19:30.830870Z",
     "shell.execute_reply": "2021-11-03T04:19:30.829959Z",
     "shell.execute_reply.started": "2021-11-02T13:01:50.877828Z"
    },
    "papermill": {
     "duration": 8.076933,
     "end_time": "2021-11-03T04:19:30.831031",
     "exception": false,
     "start_time": "2021-11-03T04:19:22.754098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-cloud 0.1.13 requires tensorflow<3.0,>=1.15.0, which is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822941a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:30.892355Z",
     "iopub.status.busy": "2021-11-03T04:19:30.891597Z",
     "iopub.status.idle": "2021-11-03T04:19:33.529040Z",
     "shell.execute_reply": "2021-11-03T04:19:33.528540Z",
     "shell.execute_reply.started": "2021-11-02T13:01:58.747971Z"
    },
    "papermill": {
     "duration": 2.669802,
     "end_time": "2021-11-03T04:19:33.529198",
     "exception": false,
     "start_time": "2021-11-03T04:19:30.859396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "import collections\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tez\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a520765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:33.593252Z",
     "iopub.status.busy": "2021-11-03T04:19:33.592002Z",
     "iopub.status.idle": "2021-11-03T04:19:33.594349Z",
     "shell.execute_reply": "2021-11-03T04:19:33.594765Z",
     "shell.execute_reply.started": "2021-11-02T13:02:01.819691Z"
    },
    "papermill": {
     "duration": 0.038236,
     "end_time": "2021-11-03T04:19:33.594884",
     "exception": false,
     "start_time": "2021-11-03T04:19:33.556648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiModel(tez.Model):\n",
    "    def __init__(self, model_name, num_train_steps, steps_per_epoch, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.model_name = model_name\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "\n",
    "        hidden_dropout_prob: float = 0.0\n",
    "        layer_norm_eps: float = 1e-7\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(model_name)\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name, config=config)\n",
    "        self.output = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids=None, start_positions=None, end_positions=None):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out[0]\n",
    "        logits = self.output(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        return (start_logits, end_logits), 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0832c449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:33.653686Z",
     "iopub.status.busy": "2021-11-03T04:19:33.653056Z",
     "iopub.status.idle": "2021-11-03T04:19:33.656164Z",
     "shell.execute_reply": "2021-11-03T04:19:33.655739Z",
     "shell.execute_reply.started": "2021-11-02T13:02:01.833239Z"
    },
    "papermill": {
     "duration": 0.034786,
     "end_time": "2021-11-03T04:19:33.656274",
     "exception": false,
     "start_time": "2021-11-03T04:19:33.621488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"ids\": torch.tensor(self.data[item][\"input_ids\"], dtype=torch.long),\n",
    "            \"mask\": torch.tensor(self.data[item][\"attention_mask\"], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182ef498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:33.726667Z",
     "iopub.status.busy": "2021-11-03T04:19:33.725925Z",
     "iopub.status.idle": "2021-11-03T04:19:33.728870Z",
     "shell.execute_reply": "2021-11-03T04:19:33.728455Z",
     "shell.execute_reply.started": "2021-11-02T13:02:01.845193Z"
    },
    "papermill": {
     "duration": 0.045269,
     "end_time": "2021-11-03T04:19:33.728976",
     "exception": false,
     "start_time": "2021-11-03T04:19:33.683707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af81987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:33.799157Z",
     "iopub.status.busy": "2021-11-03T04:19:33.798293Z",
     "iopub.status.idle": "2021-11-03T04:19:33.801091Z",
     "shell.execute_reply": "2021-11-03T04:19:33.800705Z",
     "shell.execute_reply.started": "2021-11-02T13:02:47.784867Z"
    },
    "papermill": {
     "duration": 0.043776,
     "end_time": "2021-11-03T04:19:33.801224",
     "exception": false,
     "start_time": "2021-11-03T04:19:33.757448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess_qa_predictions(\n",
    "    examples, tokenizer, features, raw_predictions, n_best_size=20, max_answer_length=30, squad_v2=False\n",
    "):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None  # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": (start_logits[start_index] + end_logits[end_index])/2,\n",
    "                            \"text\": context[start_char:end_char],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)\n",
    "#             print(answers)\n",
    "            best_answer = answers[0]\n",
    "#             best_answer = answers[:5]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        predictions[example[\"id\"]] = best_answer#[\"text\"]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a84c327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:33.860065Z",
     "iopub.status.busy": "2021-11-03T04:19:33.859445Z",
     "iopub.status.idle": "2021-11-03T04:19:39.924683Z",
     "shell.execute_reply": "2021-11-03T04:19:39.923986Z",
     "shell.execute_reply.started": "2021-11-02T13:02:48.485094Z"
    },
    "papermill": {
     "duration": 6.096025,
     "end_time": "2021-11-03T04:19:39.924823",
     "exception": false,
     "start_time": "2021-11-03T04:19:33.828798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"../input/xlmrob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1c728a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:19:39.990814Z",
     "iopub.status.busy": "2021-11-03T04:19:39.990288Z",
     "iopub.status.idle": "2021-11-03T04:25:20.358381Z",
     "shell.execute_reply": "2021-11-03T04:25:20.356954Z",
     "shell.execute_reply.started": "2021-11-02T13:02:54.496897Z"
    },
    "papermill": {
     "duration": 340.406486,
     "end_time": "2021-11-03T04:25:20.358511",
     "exception": false,
     "start_time": "2021-11-03T04:19:39.952025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cd71208d0e4899b27318b351ceb86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7d078170db4067b91a360f3cdfaa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 10%|█         | 1/10 [00:55<08:17, 55.28s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 20%|██        | 2/10 [01:35<06:09, 46.17s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 30%|███       | 3/10 [02:05<04:32, 38.98s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 40%|████      | 4/10 [02:36<03:34, 35.79s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 50%|█████     | 5/10 [03:06<02:49, 33.92s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 60%|██████    | 6/10 [03:37<02:10, 32.73s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 70%|███████   | 7/10 [04:08<01:36, 32.05s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 80%|████████  | 8/10 [04:38<01:03, 31.63s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 90%|█████████ | 9/10 [05:09<00:31, 31.30s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 10/10 [05:39<00:00, 33.97s/it]\n"
     ]
    }
   ],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "\n",
    "test_data = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "test_features = test_dataset.map(\n",
    "    partial(\n",
    "        prepare_validation_features, \n",
    "        tokenizer=tokenizer,\n",
    "        pad_on_right=pad_on_right, \n",
    "        max_length=max_length,\n",
    "        doc_stride=doc_stride\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")\n",
    "test_feats_small = test_features.map(\n",
    "    lambda example: example, remove_columns=['example_id', 'offset_mapping']\n",
    ")\n",
    "\n",
    "fin_start_logits = None\n",
    "fin_end_logits = None\n",
    "\n",
    "for fold_ in tqdm(range(10)):\n",
    "    model = ChaiiModel(model_name=\"../input/xlmrob\", num_train_steps=0, steps_per_epoch=0, learning_rate=0)\n",
    "    model.load(f\"../input/deepsetsquad2-v2/pytorch_model_f{fold_}.bin\", weights_only=True)\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        ChaiiDataset(test_feats_small), \n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "\n",
    "    for b_idx, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(\"cuda\")\n",
    "            output, _, _ = model(**data)\n",
    "            start = output[0].detach().cpu().numpy()\n",
    "            end = output[1].detach().cpu().numpy()\n",
    "            start_logits.append(start)\n",
    "            end_logits.append(end)\n",
    "\n",
    "    start_logits = np.vstack(start_logits)\n",
    "    end_logits = np.vstack(end_logits)\n",
    "    \n",
    "    if fin_start_logits is None:\n",
    "        fin_start_logits = start_logits\n",
    "        fin_end_logits = end_logits\n",
    "    else:\n",
    "        fin_start_logits += start_logits\n",
    "        fin_end_logits += end_logits\n",
    "        \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e668ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:20.438463Z",
     "iopub.status.busy": "2021-11-03T04:25:20.437658Z",
     "iopub.status.idle": "2021-11-03T04:25:20.441004Z",
     "shell.execute_reply": "2021-11-03T04:25:20.441399Z",
     "shell.execute_reply.started": "2021-11-02T13:09:01.503449Z"
    },
    "papermill": {
     "duration": 0.048783,
     "end_time": "2021-11-03T04:25:20.441535",
     "exception": false,
     "start_time": "2021-11-03T04:25:20.392752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fin_start_logits /= 10\n",
    "fin_end_logits /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18040d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:20.514146Z",
     "iopub.status.busy": "2021-11-03T04:25:20.513557Z",
     "iopub.status.idle": "2021-11-03T04:25:20.523868Z",
     "shell.execute_reply": "2021-11-03T04:25:20.523470Z",
     "shell.execute_reply.started": "2021-11-02T13:09:01.515384Z"
    },
    "papermill": {
     "duration": 0.048163,
     "end_time": "2021-11-03T04:25:20.523977",
     "exception": false,
     "start_time": "2021-11-03T04:25:20.475814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "normalizer = torch.nn.Softmax(dim=1)\n",
    "\n",
    "fin_start_logits = normalizer(torch.from_numpy(fin_start_logits))\n",
    "fin_end_logits = normalizer(torch.from_numpy(fin_end_logits))\n",
    "\n",
    "fin_start_logits = fin_start_logits.numpy()\n",
    "fin_end_logits = fin_end_logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b1a7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:20.598185Z",
     "iopub.status.busy": "2021-11-03T04:25:20.597637Z",
     "iopub.status.idle": "2021-11-03T04:25:21.066756Z",
     "shell.execute_reply": "2021-11-03T04:25:21.067206Z",
     "shell.execute_reply.started": "2021-11-02T13:09:01.537706Z"
    },
    "papermill": {
     "duration": 0.509684,
     "end_time": "2021-11-03T04:25:21.067358",
     "exception": false,
     "start_time": "2021-11-03T04:25:20.557674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 67 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.22it/s]\n"
     ]
    }
   ],
   "source": [
    "fin_preds = postprocess_qa_predictions(test_dataset, tokenizer, test_features, (fin_start_logits, fin_end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1a2e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.145510Z",
     "iopub.status.busy": "2021-11-03T04:25:21.144771Z",
     "iopub.status.idle": "2021-11-03T04:25:21.148034Z",
     "shell.execute_reply": "2021-11-03T04:25:21.148430Z",
     "shell.execute_reply.started": "2021-11-02T13:09:02.593962Z"
    },
    "papermill": {
     "duration": 0.045598,
     "end_time": "2021-11-03T04:25:21.148568",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.102970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6914839744567871, 'text': ' येलन'},\n",
       " {'score': 0.21004313230514526, 'text': ' 28 नवम्बर 2007'},\n",
       " {'score': 0.9119396805763245, 'text': '१२ मार्च १८२४'},\n",
       " {'score': 0.975170910358429, 'text': ' 13'},\n",
       " {'score': 0.639376163482666, 'text': 'சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list = list(fin_preds.values())\n",
    "final_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e2a1a",
   "metadata": {
    "papermill": {
     "duration": 0.035685,
     "end_time": "2021-11-03T04:25:21.220170",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.184485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ccbe28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.304205Z",
     "iopub.status.busy": "2021-11-03T04:25:21.303646Z",
     "iopub.status.idle": "2021-11-03T04:25:21.410037Z",
     "shell.execute_reply": "2021-11-03T04:25:21.409565Z",
     "shell.execute_reply.started": "2021-11-03T02:46:59.699278Z"
    },
    "papermill": {
     "duration": 0.154027,
     "end_time": "2021-11-03T04:25:21.410179",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.256152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex AMP Installed :: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import gc\n",
    "gc.enable()\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn import model_selection\n",
    "from string import punctuation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader,\n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "    APEX_INSTALLED = True\n",
    "except ImportError:\n",
    "    APEX_INSTALLED = False\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    logging,\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    ")\n",
    "logging.set_verbosity_warning()\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def optimal_num_of_loader_workers():\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    optimal_value = min(num_cpus, num_gpus*4) if num_gpus else num_cpus - 1\n",
    "    return optimal_value\n",
    "\n",
    "print(f\"Apex AMP Installed :: {APEX_INSTALLED}\")\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec2bb036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.488890Z",
     "iopub.status.busy": "2021-11-03T04:25:21.488309Z",
     "iopub.status.idle": "2021-11-03T04:25:21.492248Z",
     "shell.execute_reply": "2021-11-03T04:25:21.491793Z",
     "shell.execute_reply.started": "2021-11-03T02:47:06.979474Z"
    },
    "papermill": {
     "duration": 0.045582,
     "end_time": "2021-11-03T04:25:21.492360",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.446778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # model\n",
    "    model_type = 'xlm_roberta'\n",
    "    model_name_or_path = \"../input/5foldsroberta/output/checkpoint-fold-0\"#\"../input/xlm-roberta-large-squad-v2\"\n",
    "    config_name = \"../input/5foldsroberta/output/checkpoint-fold-0\"#\"../input/xlm-roberta-large-squad-v2\"\n",
    "    fp16 = True if APEX_INSTALLED else False\n",
    "    fp16_opt_level = \"O1\"\n",
    "    gradient_accumulation_steps = 2\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer_name = \"../input/5foldsroberta/output/checkpoint-fold-0\"#\"../input/xlm-roberta-large-squad-v2\"\n",
    "    max_seq_length = 400\n",
    "    doc_stride = 135\n",
    "\n",
    "    # train\n",
    "    epochs = 1\n",
    "    train_batch_size = 4\n",
    "    eval_batch_size = 128\n",
    "\n",
    "    # optimzer\n",
    "    optimizer_type = 'AdamW'\n",
    "    learning_rate = 1e-5\n",
    "    weight_decay = 1e-2\n",
    "    epsilon = 1e-8\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    # scheduler\n",
    "    decay_name = 'linear-warmup'\n",
    "    warmup_ratio = 0.1\n",
    "\n",
    "    # logging\n",
    "    logging_steps = 10\n",
    "\n",
    "    # evaluate\n",
    "    output_dir = 'output'\n",
    "    seed = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eafdc49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.573646Z",
     "iopub.status.busy": "2021-11-03T04:25:21.572403Z",
     "iopub.status.idle": "2021-11-03T04:25:21.574571Z",
     "shell.execute_reply": "2021-11-03T04:25:21.575409Z",
     "shell.execute_reply.started": "2021-11-03T02:47:06.988953Z"
    },
    "papermill": {
     "duration": 0.047132,
     "end_time": "2021-11-03T04:25:21.575534",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.528402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, features, mode='train'):\n",
    "        super(DatasetRetriever, self).__init__()\n",
    "        self.features = features\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, item):   \n",
    "        feature = self.features[item]\n",
    "        if self.mode == 'train':\n",
    "            return {\n",
    "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
    "                'offset_mapping':torch.tensor(feature['offset_mapping'], dtype=torch.long),\n",
    "                'start_position':torch.tensor(feature['start_position'], dtype=torch.long),\n",
    "                'end_position':torch.tensor(feature['end_position'], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
    "                'offset_mapping':feature['offset_mapping'],\n",
    "                'sequence_ids':feature['sequence_ids'],\n",
    "                'id':feature['example_id'],\n",
    "                'context': feature['context'],\n",
    "                'question': feature['question']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff9637b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.657693Z",
     "iopub.status.busy": "2021-11-03T04:25:21.656928Z",
     "iopub.status.idle": "2021-11-03T04:25:21.659811Z",
     "shell.execute_reply": "2021-11-03T04:25:21.659392Z",
     "shell.execute_reply.started": "2021-11-03T02:47:07.002847Z"
    },
    "papermill": {
     "duration": 0.048162,
     "end_time": "2021-11-03T04:25:21.659920",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.611758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, modelname_or_path, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.xlm_roberta = AutoModel.from_pretrained(modelname_or_path, config=config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, 2)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self._init_weights(self.qa_outputs)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids, \n",
    "        attention_mask=None, \n",
    "    ):\n",
    "        outputs = self.xlm_roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]\n",
    "        \n",
    "        # sequence_output = self.dropout(sequence_output)\n",
    "        qa_logits = self.qa_outputs(sequence_output)\n",
    "        \n",
    "        start_logits, end_logits = qa_logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "    \n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce316ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.737526Z",
     "iopub.status.busy": "2021-11-03T04:25:21.736271Z",
     "iopub.status.idle": "2021-11-03T04:25:21.738630Z",
     "shell.execute_reply": "2021-11-03T04:25:21.739025Z",
     "shell.execute_reply.started": "2021-11-03T02:47:07.014695Z"
    },
    "papermill": {
     "duration": 0.042972,
     "end_time": "2021-11-03T04:25:21.739173",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.696201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(args):\n",
    "    config = AutoConfig.from_pretrained(args.config_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
    "    model = Model(args.model_name_or_path, config=config)\n",
    "    return config, tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87b09456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.819390Z",
     "iopub.status.busy": "2021-11-03T04:25:21.818712Z",
     "iopub.status.idle": "2021-11-03T04:25:21.821582Z",
     "shell.execute_reply": "2021-11-03T04:25:21.821137Z",
     "shell.execute_reply.started": "2021-11-03T02:47:07.024497Z"
    },
    "papermill": {
     "duration": 0.046187,
     "end_time": "2021-11-03T04:25:21.821686",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.775499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_test_features(args, example, tokenizer):\n",
    "    example[\"question\"] = example[\"question\"].lstrip()\n",
    "    \n",
    "    tokenized_example = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=args.max_seq_length,\n",
    "        stride=args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(tokenized_example[\"input_ids\"])):\n",
    "        feature = {}\n",
    "        feature[\"example_id\"] = example['id']\n",
    "        feature['context'] = example['context']\n",
    "        feature['question'] = example['question']\n",
    "        feature['input_ids'] = tokenized_example['input_ids'][i]\n",
    "        feature['attention_mask'] = tokenized_example['attention_mask'][i]\n",
    "        feature['offset_mapping'] = tokenized_example['offset_mapping'][i]\n",
    "        feature['sequence_ids'] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a647ed66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:21.900653Z",
     "iopub.status.busy": "2021-11-03T04:25:21.900136Z",
     "iopub.status.idle": "2021-11-03T04:25:23.404506Z",
     "shell.execute_reply": "2021-11-03T04:25:23.403901Z",
     "shell.execute_reply.started": "2021-11-03T02:47:07.0353Z"
    },
    "papermill": {
     "duration": 1.547137,
     "end_time": "2021-11-03T04:25:23.404642",
     "exception": false,
     "start_time": "2021-11-03T04:25:21.857505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
    "\n",
    "test['context'] = test['context'].apply(lambda x: ' '.join(x.split()))\n",
    "test['question'] = test['question'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "#base_model_path = '../input/chaii-qa-5-fold-xlmroberta-torch-fit'\n",
    "# test=test[:10]\n",
    "#test=test[:10]\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config().tokenizer_name)\n",
    "\n",
    "test_features = []\n",
    "for i, row in test.iterrows():\n",
    "    test_features += prepare_test_features(Config(), row, tokenizer)\n",
    "\n",
    "args = Config()\n",
    "test_dataset = DatasetRetriever(test_features, mode='test')\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.eval_batch_size, \n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    num_workers=optimal_num_of_loader_workers(),\n",
    "    pin_memory=True, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "880d2b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:23.481980Z",
     "iopub.status.busy": "2021-11-03T04:25:23.481459Z",
     "iopub.status.idle": "2021-11-03T04:25:23.485320Z",
     "shell.execute_reply": "2021-11-03T04:25:23.484886Z",
     "shell.execute_reply.started": "2021-11-03T02:47:08.234299Z"
    },
    "papermill": {
     "duration": 0.043449,
     "end_time": "2021-11-03T04:25:23.485447",
     "exception": false,
     "start_time": "2021-11-03T04:25:23.441998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = '../input/5foldsroberta/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4a2eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:23.564420Z",
     "iopub.status.busy": "2021-11-03T04:25:23.563728Z",
     "iopub.status.idle": "2021-11-03T04:25:23.566570Z",
     "shell.execute_reply": "2021-11-03T04:25:23.566153Z",
     "shell.execute_reply.started": "2021-11-03T02:47:08.240448Z"
    },
    "papermill": {
     "duration": 0.045142,
     "end_time": "2021-11-03T04:25:23.566682",
     "exception": false,
     "start_time": "2021-11-03T04:25:23.521540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(checkpoint_path):\n",
    "    config, tokenizer, model = make_model(Config())\n",
    "    model.cuda();\n",
    "    model.load_state_dict(\n",
    "        torch.load(base_model + checkpoint_path)\n",
    "    );\n",
    "    \n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs_start, outputs_end = model(batch['input_ids'].cuda(), batch['attention_mask'].cuda())\n",
    "            start_logits.append(outputs_start.cpu().numpy().tolist())\n",
    "            end_logits.append(outputs_end.cpu().numpy().tolist())\n",
    "            del outputs_start, outputs_end\n",
    "    del model, tokenizer, config\n",
    "    gc.collect()\n",
    "    return np.vstack(start_logits), np.vstack(end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0d94a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:25:23.643249Z",
     "iopub.status.busy": "2021-11-03T04:25:23.642674Z",
     "iopub.status.idle": "2021-11-03T04:28:28.252077Z",
     "shell.execute_reply": "2021-11-03T04:28:28.251425Z",
     "shell.execute_reply.started": "2021-11-03T02:47:08.250472Z"
    },
    "papermill": {
     "duration": 184.649667,
     "end_time": "2021-11-03T04:28:28.252265",
     "exception": false,
     "start_time": "2021-11-03T04:25:23.602598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_logits1, end_logits1 = get_predictions('checkpoint-fold-0/pytorch_model.bin')\n",
    "start_logits2, end_logits2 = get_predictions('checkpoint-fold-1/pytorch_model.bin')\n",
    "start_logits3, end_logits3 = get_predictions('checkpoint-fold-2/pytorch_model.bin')\n",
    "start_logits4, end_logits4 = get_predictions('checkpoint-fold-3/pytorch_model.bin')\n",
    "start_logits5, end_logits5 = get_predictions('checkpoint-fold-4/pytorch_model.bin')\n",
    "\n",
    "\n",
    "\n",
    "start_logits = (start_logits1 + start_logits2 + start_logits3 + start_logits4+ start_logits5)/5\n",
    "end_logits = (end_logits1 + end_logits2 + end_logits3 + end_logits4 + end_logits5 )/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb1cf96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.333198Z",
     "iopub.status.busy": "2021-11-03T04:28:28.332438Z",
     "iopub.status.idle": "2021-11-03T04:28:28.336498Z",
     "shell.execute_reply": "2021-11-03T04:28:28.336893Z",
     "shell.execute_reply.started": "2021-11-03T02:50:12.819807Z"
    },
    "papermill": {
     "duration": 0.047397,
     "end_time": "2021-11-03T04:28:28.337027",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.289630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "normalizer = torch.nn.Softmax(dim=1)\n",
    "\n",
    "start_logits = normalizer(torch.from_numpy(start_logits))\n",
    "end_logits = normalizer(torch.from_numpy(end_logits))\n",
    "\n",
    "start_logits = start_logits.numpy()\n",
    "end_logits = end_logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7853f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.424864Z",
     "iopub.status.busy": "2021-11-03T04:28:28.423602Z",
     "iopub.status.idle": "2021-11-03T04:28:28.425755Z",
     "shell.execute_reply": "2021-11-03T04:28:28.426585Z",
     "shell.execute_reply.started": "2021-11-03T02:55:50.617919Z"
    },
    "papermill": {
     "duration": 0.053271,
     "end_time": "2021-11-03T04:28:28.426728",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.373457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    \n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in examples.iterrows():\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "\n",
    "            sequence_ids = features[feature_index][\"sequence_ids\"]\n",
    "            context_index = 1\n",
    "\n",
    "            features[feature_index][\"offset_mapping\"] = [\n",
    "                (o if sequence_ids[k] == context_index else None)\n",
    "                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n",
    "            ]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": (start_logits[start_index] + end_logits[end_index])/2,\n",
    "                            \"text\": context[start_char: end_char],\n",
    "#                             \"example\": example\n",
    "#                             \"feature_index\":feature_index,\n",
    "#                             \"features\":features[feature_index],\n",
    "#                             \"start_index\":start_index,\n",
    "#                             \"end_index\":end_index,\n",
    "#                             \"offset_mapping\":offset_mapping,\n",
    "#                             \"context\":context\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)\n",
    "#             print(answers)\n",
    "            best_answer = answers[0]\n",
    "#             best_answer = answers[:5]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        predictions[example[\"id\"]] = best_answer#[\"text\"]\n",
    "        \n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "512ddb55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.507355Z",
     "iopub.status.busy": "2021-11-03T04:28:28.506465Z",
     "iopub.status.idle": "2021-11-03T04:28:28.538444Z",
     "shell.execute_reply": "2021-11-03T04:28:28.537986Z",
     "shell.execute_reply.started": "2021-11-03T02:55:51.496629Z"
    },
    "papermill": {
     "duration": 0.075167,
     "end_time": "2021-11-03T04:28:28.538549",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.463382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 63 features.\n"
     ]
    }
   ],
   "source": [
    "final_predictions_model2 = postprocess_qa_predictions(test, test_features, (start_logits, end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f59780f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.616629Z",
     "iopub.status.busy": "2021-11-03T04:28:28.615652Z",
     "iopub.status.idle": "2021-11-03T04:28:28.619268Z",
     "shell.execute_reply": "2021-11-03T04:28:28.618747Z",
     "shell.execute_reply.started": "2021-11-03T02:56:10.188099Z"
    },
    "papermill": {
     "duration": 0.04452,
     "end_time": "2021-11-03T04:28:28.619426",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.574906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6738852538461213, 'text': ' येलन'},\n",
       " {'score': 0.2364240767299597, 'text': ' 20 अप्रैल 2010'},\n",
       " {'score': 0.8744408926944801, 'text': '१२ मार्च १८२४'},\n",
       " {'score': 0.9539678124400571, 'text': ' 13'},\n",
       " {'score': 0.6116797119144188, 'text': 'சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list_model2 = list(final_predictions_model2.values())\n",
    "final_list_model2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b557ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.696510Z",
     "iopub.status.busy": "2021-11-03T04:28:28.695805Z",
     "iopub.status.idle": "2021-11-03T04:28:28.698509Z",
     "shell.execute_reply": "2021-11-03T04:28:28.698087Z",
     "shell.execute_reply.started": "2021-11-03T03:04:42.95246Z"
    },
    "papermill": {
     "duration": 0.04221,
     "end_time": "2021-11-03T04:28:28.698612",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.656402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_list_model2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc85302f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.778254Z",
     "iopub.status.busy": "2021-11-03T04:28:28.777343Z",
     "iopub.status.idle": "2021-11-03T04:28:28.780606Z",
     "shell.execute_reply": "2021-11-03T04:28:28.780961Z",
     "shell.execute_reply.started": "2021-11-02T13:17:52.376Z"
    },
    "papermill": {
     "duration": 0.045009,
     "end_time": "2021-11-03T04:28:28.781075",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.736066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6914839744567871, 'text': ' येलन'},\n",
       " {'score': 0.21004313230514526, 'text': ' 28 नवम्बर 2007'},\n",
       " {'score': 0.9119396805763245, 'text': '१२ मार्च १८२४'},\n",
       " {'score': 0.975170910358429, 'text': ' 13'},\n",
       " {'score': 0.639376163482666, 'text': 'சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a284af",
   "metadata": {
    "papermill": {
     "duration": 0.037294,
     "end_time": "2021-11-03T04:28:28.855523",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.818229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d728f49e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:28.936561Z",
     "iopub.status.busy": "2021-11-03T04:28:28.934712Z",
     "iopub.status.idle": "2021-11-03T04:28:28.937320Z",
     "shell.execute_reply": "2021-11-03T04:28:28.937732Z"
    },
    "papermill": {
     "duration": 0.04503,
     "end_time": "2021-11-03T04:28:28.937845",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.892815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "total_ans = len(final_list) \n",
    "threshold = 0.20#0.10#0.50#0.05#0.15#0.25#0.80#0.65\n",
    "for i in range(total_ans):\n",
    "    if final_list_model2[i]['score']>=threshold:\n",
    "        final_predictions.append(final_list_model2[i]['text'])\n",
    "    elif final_list[i]['score']>final_list_model2[i]['score']:\n",
    "        final_predictions.append(final_list[i]['text'])\n",
    "    else:\n",
    "        final_predictions.append(final_list_model2[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcf24298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.018089Z",
     "iopub.status.busy": "2021-11-03T04:28:29.017284Z",
     "iopub.status.idle": "2021-11-03T04:28:29.020645Z",
     "shell.execute_reply": "2021-11-03T04:28:29.021017Z"
    },
    "papermill": {
     "duration": 0.045731,
     "end_time": "2021-11-03T04:28:29.021162",
     "exception": false,
     "start_time": "2021-11-03T04:28:28.975431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' येलन',\n",
       " ' 20 अप्रैल 2010',\n",
       " '१२ मार्च १८२४',\n",
       " ' 13',\n",
       " 'சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "269897ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.100748Z",
     "iopub.status.busy": "2021-11-03T04:28:29.100038Z",
     "iopub.status.idle": "2021-11-03T04:28:29.102739Z",
     "shell.execute_reply": "2021-11-03T04:28:29.102340Z"
    },
    "papermill": {
     "duration": 0.043811,
     "end_time": "2021-11-03T04:28:29.102842",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.059031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "for p2 in final_predictions:\n",
    "    p2 = \" \".join(p2.split())\n",
    "    p2 = p2.strip(punctuation)\n",
    "#     submission.append((p1, p2))\n",
    "    submission.append(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff885d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.181864Z",
     "iopub.status.busy": "2021-11-03T04:28:29.181219Z",
     "iopub.status.idle": "2021-11-03T04:28:29.183900Z",
     "shell.execute_reply": "2021-11-03T04:28:29.183492Z"
    },
    "papermill": {
     "duration": 0.042944,
     "end_time": "2021-11-03T04:28:29.183996",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.141052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample = pd.DataFrame(submission, columns=[\"id\", \"PredictionString\"])\n",
    "# sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac463d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.267971Z",
     "iopub.status.busy": "2021-11-03T04:28:29.267364Z",
     "iopub.status.idle": "2021-11-03T04:28:29.290535Z",
     "shell.execute_reply": "2021-11-03T04:28:29.290046Z"
    },
    "papermill": {
     "duration": 0.068977,
     "end_time": "2021-11-03T04:28:29.290636",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.221659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து நாட்டில் ம...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து நாட்டில் ம...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       20 अप्रैल 2010  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"PredictionString\"] = submission\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41f54b16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.370898Z",
     "iopub.status.busy": "2021-11-03T04:28:29.370165Z",
     "iopub.status.idle": "2021-11-03T04:28:29.372830Z",
     "shell.execute_reply": "2021-11-03T04:28:29.372418Z"
    },
    "papermill": {
     "duration": 0.043858,
     "end_time": "2021-11-03T04:28:29.372940",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.329082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data['PredictionString'] = sample['PredictionString']\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "649eba0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.462561Z",
     "iopub.status.busy": "2021-11-03T04:28:29.462013Z",
     "iopub.status.idle": "2021-11-03T04:28:29.466999Z",
     "shell.execute_reply": "2021-11-03T04:28:29.466621Z"
    },
    "papermill": {
     "duration": 0.056184,
     "end_time": "2021-11-03T04:28:29.467118",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.410934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
    "bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
    "\n",
    "tamil_ad = \"கி.பி\"\n",
    "tamil_bc = \"கி.மு\"\n",
    "tamil_km = \"கி.மீ\"\n",
    "hindi_ad = \"ई\"\n",
    "hindi_bc = \"ई.पू\"\n",
    "\n",
    "cleaned_preds = []\n",
    "for pred, context in test[[\"PredictionString\", \"context\"]].to_numpy():\n",
    "    if pred == \"\":\n",
    "        cleaned_preds.append(pred)\n",
    "        continue\n",
    "    while any([pred.startswith(y) for y in bad_starts]):\n",
    "        pred = pred[1:]\n",
    "    while any([pred.endswith(y) for y in bad_endings]):\n",
    "        if pred.endswith(\"...\"):\n",
    "            pred = pred[:-3]\n",
    "        else:\n",
    "            pred = pred[:-1]\n",
    "    \n",
    "    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
    "        pred = pred+\".\"\n",
    "\n",
    "    cleaned_preds.append(pred)\n",
    "\n",
    "test[\"PredictionString\"] = cleaned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3927e9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.556392Z",
     "iopub.status.busy": "2021-11-03T04:28:29.555587Z",
     "iopub.status.idle": "2021-11-03T04:28:29.558986Z",
     "shell.execute_reply": "2021-11-03T04:28:29.559430Z"
    },
    "papermill": {
     "duration": 0.052056,
     "end_time": "2021-11-03T04:28:29.559550",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.507494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து நாட்டில் ம...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து நாட்டில் ம...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       20 अप्रैल 2010  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "563ae28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T04:28:29.644518Z",
     "iopub.status.busy": "2021-11-03T04:28:29.643876Z",
     "iopub.status.idle": "2021-11-03T04:28:29.651609Z",
     "shell.execute_reply": "2021-11-03T04:28:29.651188Z"
    },
    "papermill": {
     "duration": 0.051789,
     "end_time": "2021-11-03T04:28:29.651706",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.599917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[['id','PredictionString']].to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d08114",
   "metadata": {
    "papermill": {
     "duration": 0.039444,
     "end_time": "2021-11-03T04:28:29.730097",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.690653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb7300",
   "metadata": {
    "papermill": {
     "duration": 0.039046,
     "end_time": "2021-11-03T04:28:29.808583",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.769537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf850b",
   "metadata": {
    "papermill": {
     "duration": 0.039071,
     "end_time": "2021-11-03T04:28:29.887527",
     "exception": false,
     "start_time": "2021-11-03T04:28:29.848456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 556.895424,
   "end_time": "2021-11-03T04:28:33.014536",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-03T04:19:16.119112",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1599753473894c9694eb13d443a91e6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1599ab72965948c69433cfa9b7000952": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "23bc5059d692402d90c5132406627cf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "304401d48cc74a318af17f003b90953c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35fc8d2d1b3c452b9f90aa31054a5c86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5763d649d54c43baac0fe4f37e32d388": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35fc8d2d1b3c452b9f90aa31054a5c86",
       "max": 67.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_814970d67d484145924ec8034f1f5975",
       "value": 67.0
      }
     },
     "684d81bb26984bb2bb97c4116901c786": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8874f5565d4e48a7bab9be313348029e",
       "placeholder": "​",
       "style": "IPY_MODEL_1599ab72965948c69433cfa9b7000952",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fe522c2e4d0&gt;"
      }
     },
     "72cd71208d0e4899b27318b351ceb86e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_deb247d5c30344b6a31c100ae63c0deb",
        "IPY_MODEL_684d81bb26984bb2bb97c4116901c786"
       ],
       "layout": "IPY_MODEL_aa0200349a2a4dac8aaea0b6d874977b"
      }
     },
     "760beaa5abce4f7ca467257571c5c605": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "814970d67d484145924ec8034f1f5975": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "8874f5565d4e48a7bab9be313348029e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d7d078170db4067b91a360f3cdfaa57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5763d649d54c43baac0fe4f37e32d388",
        "IPY_MODEL_c7a38e50d0144034b8fcf0087dbc66f6"
       ],
       "layout": "IPY_MODEL_760beaa5abce4f7ca467257571c5c605"
      }
     },
     "9bef386b7bf9477a83c296eda48795a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "aa0200349a2a4dac8aaea0b6d874977b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7a38e50d0144034b8fcf0087dbc66f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1599753473894c9694eb13d443a91e6b",
       "placeholder": "​",
       "style": "IPY_MODEL_23bc5059d692402d90c5132406627cf3",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fe521c38e90&gt;"
      }
     },
     "deb247d5c30344b6a31c100ae63c0deb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_304401d48cc74a318af17f003b90953c",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9bef386b7bf9477a83c296eda48795a2",
       "value": 1.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
