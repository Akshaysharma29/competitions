{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ee8f63",
   "metadata": {
    "papermill": {
     "duration": 0.028567,
     "end_time": "2021-11-13T14:54:22.321389",
     "exception": false,
     "start_time": "2021-11-13T14:54:22.292822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Postprocess added in data preparation(in this version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68aac1ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:54:22.381550Z",
     "iopub.status.busy": "2021-11-13T14:54:22.380057Z",
     "iopub.status.idle": "2021-11-13T14:55:55.200851Z",
     "shell.execute_reply": "2021-11-13T14:55:55.199796Z",
     "shell.execute_reply.started": "2021-11-13T14:51:54.268405Z"
    },
    "papermill": {
     "duration": 92.851974,
     "end_time": "2021-11-13T14:55:55.201037",
     "exception": false,
     "start_time": "2021-11-13T14:54:22.349063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /kaggle/working/.git/\r\n",
      "Detected operating system as Ubuntu/bionic.\r\n",
      "Checking for curl...\r\n",
      "Detected curl...\r\n",
      "Checking for gpg...\r\n",
      "Detected gpg...\r\n",
      "Running apt-get update... done.\r\n",
      "Installing apt-transport-https... done.\r\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\r\n",
      "Importing packagecloud gpg key... done.\r\n",
      "Running apt-get update... done.\r\n",
      "\r\n",
      "The repository is setup! You can now install packages.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  git-lfs\r\n",
      "0 upgraded, 1 newly installed, 0 to remove and 27 not upgraded.\r\n",
      "Need to get 6526 kB of archives.\r\n",
      "After this operation, 14.7 MB of additional disk space will be used.\r\n",
      "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 3.0.2 [6526 kB]\r\n",
      "Fetched 6526 kB in 1s (4610 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package git-lfs.\r\n",
      "(Reading database ... 111661 files and directories currently installed.)\r\n",
      "Preparing to unpack .../git-lfs_3.0.2_amd64.deb ...\r\n",
      "Unpacking git-lfs (3.0.2) ...\r\n",
      "Setting up git-lfs (3.0.2) ...\r\n",
      "Git LFS initialized.\r\n",
      "Updated git hooks.\r\n",
      "Git LFS initialized.\r\n",
      "Cloning into 'xlm-roberta-large'...\r\n",
      "remote: Enumerating objects: 24, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (24/24), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\r\n",
      "remote: Total 24 (delta 8), reused 0 (delta 0)\u001b[K\r\n",
      "Unpacking objects: 100% (24/24), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "!apt-get install git-lfs\n",
    "!git lfs install\n",
    "# !git clone https://huggingface.co/monsoon-nlp/tamillion\n",
    "# !git clone https://huggingface.co/ai4bharat/indic-bert\n",
    "# !git clone https://huggingface.co/xlm-roberta-base\n",
    "!git clone https://huggingface.co/xlm-roberta-large\n",
    "# !git clone https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1\n",
    "\n",
    "# !git clone https://huggingface.co/deepset/xlm-roberta-large-squad2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e4dd6",
   "metadata": {
    "papermill": {
     "duration": 0.040022,
     "end_time": "2021-11-13T14:55:55.282809",
     "exception": false,
     "start_time": "2021-11-13T14:55:55.242787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b74a53",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-13T14:55:55.371001Z",
     "iopub.status.busy": "2021-11-13T14:55:55.370480Z",
     "iopub.status.idle": "2021-11-13T14:55:55.546177Z",
     "shell.execute_reply": "2021-11-13T14:55:55.545692Z",
     "shell.execute_reply.started": "2021-11-13T14:52:43.726801Z"
    },
    "papermill": {
     "duration": 0.222367,
     "end_time": "2021-11-13T14:55:55.546333",
     "exception": false,
     "start_time": "2021-11-13T14:55:55.323966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>require_text</th>\n",
       "      <th>jac_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>208</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answer_text                              question  \\\n",
       "0         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "2         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "3         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "4         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "\n",
       "                                           pred_text  \\\n",
       "0                                                206   \n",
       "1   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "2                                                208   \n",
       "3   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "4   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "\n",
       "                                        require_text  jac_score  \n",
       "0  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   1.000000  \n",
       "1  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667  \n",
       "2  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.000000  \n",
       "3  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667  \n",
       "4  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.142857  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../input/5-folds-data-pre-combinedmodel-0-792-model2/training.csv')#[:512]\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3a5cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:55:55.635605Z",
     "iopub.status.busy": "2021-11-13T14:55:55.634748Z",
     "iopub.status.idle": "2021-11-13T14:55:55.637359Z",
     "shell.execute_reply": "2021-11-13T14:55:55.636886Z",
     "shell.execute_reply.started": "2021-11-13T14:52:43.888146Z"
    },
    "papermill": {
     "duration": 0.049863,
     "end_time": "2021-11-13T14:55:55.637468",
     "exception": false,
     "start_time": "2021-11-13T14:55:55.587605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_text(row):\n",
    "#     return '<q> '+row['question']+' <a> '+row['pred_text']+' <c> '+row['require_text']\n",
    "#     return row['question']+','+row['pred_text']+','+row['require_text']\n",
    "#     return \"<s>Question:\"+row['question']+\"</s></s>Answer:\"+row['pred_text']+\"</s></s>Context:\"+row['require_text']+\"</s>\"\n",
    "#     return \"<s>Question:\"+row['question']+\"</s></s>Context:\"+row['require_text']+\"</s></s>Answer:\"+row['pred_text']+\"</s>\"\n",
    "#     return \"<s>\"+row['question']+\"</s></s>\"+row['require_text']+\"</s></s>\"+row['pred_text']+\"</s>\"\n",
    "#     return \"<s>\"+row['question']+\"</s></s>\"+row['pred_text']+\"</s>\"\n",
    "#     return \"<s>\"+row['question']+\"</s></s>\"+row['require_text']+\" \"+row['pred_text']+\"</s>\"\n",
    "    return \"<s>\"+row['question']+\"</s></s>\"+row['require_text']+\"   \"+row['pred_text']+\"</s>\"\n",
    "#     return \"[CLS]\"+row['question']+\"[SEP]\"+row['require_text']+\" \"+row['pred_text']+\"[SEP]\"\n",
    "#     return \"[CLS]\"+row['question']+\"[SEP]\"+row['pred_text']+\"[SEP]\"\n",
    "\n",
    "def round_jac_score(row):\n",
    "    score = round(row['jac_score'],2)\n",
    "#     if score>=0.75:\n",
    "#         return 0.75\n",
    "#     elif score>=0.50:\n",
    "#         return 0.50\n",
    "#     elif score>=0.25:\n",
    "#         return 0.25\n",
    "#     else:\n",
    "#         return 0.0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93f14f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:55:55.763891Z",
     "iopub.status.busy": "2021-11-13T14:55:55.753674Z",
     "iopub.status.idle": "2021-11-13T14:55:55.938599Z",
     "shell.execute_reply": "2021-11-13T14:55:55.939008Z",
     "shell.execute_reply.started": "2021-11-13T14:52:47.613045Z"
    },
    "papermill": {
     "duration": 0.26168,
     "end_time": "2021-11-13T14:55:55.939159",
     "exception": false,
     "start_time": "2021-11-13T14:55:55.677479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>require_text</th>\n",
       "      <th>jac_score</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>208</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answer_text                              question  \\\n",
       "0         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "2         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "3         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "4         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "\n",
       "                                           pred_text  \\\n",
       "0                                                206   \n",
       "1   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "2                                                208   \n",
       "3   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "4   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "\n",
       "                                        require_text  jac_score  \\\n",
       "0  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   1.000000   \n",
       "1  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667   \n",
       "2  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.000000   \n",
       "3  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667   \n",
       "4  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.142857   \n",
       "\n",
       "                                             excerpt  target  \n",
       "0  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    1.00  \n",
       "1  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.17  \n",
       "2  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.00  \n",
       "3  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.17  \n",
       "4  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.14  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['excerpt'] = data.apply(combine_text,axis=1)\n",
    "# data['target'] = data['jac_score']\n",
    "data['target'] = data.apply(round_jac_score,axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c200eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:55:56.029230Z",
     "iopub.status.busy": "2021-11-13T14:55:56.028590Z",
     "iopub.status.idle": "2021-11-13T14:55:56.031158Z",
     "shell.execute_reply": "2021-11-13T14:55:56.031614Z",
     "shell.execute_reply.started": "2021-11-13T14:52:51.214435Z"
    },
    "papermill": {
     "duration": 0.05095,
     "end_time": "2021-11-13T14:55:56.031747",
     "exception": false,
     "start_time": "2021-11-13T14:55:55.980797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின்வரும் 206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட்டால் 208) எண்ணிக்கையான எலும்புகளைக் கொண்டிருக்கும். இந்த எண்ணிக்கை உடற்கூட்டியல் வேறு    206</s>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['excerpt'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe75f6b",
   "metadata": {
    "papermill": {
     "duration": 0.041801,
     "end_time": "2021-11-13T14:55:56.114493",
     "exception": false,
     "start_time": "2021-11-13T14:55:56.072692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Finetune notebook start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874f0194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:55:56.248337Z",
     "iopub.status.busy": "2021-11-13T14:55:56.247791Z",
     "iopub.status.idle": "2021-11-13T14:56:03.452719Z",
     "shell.execute_reply": "2021-11-13T14:56:03.451766Z",
     "shell.execute_reply.started": "2021-11-13T14:52:52.959842Z"
    },
    "papermill": {
     "duration": 7.297437,
     "end_time": "2021-11-13T14:56:03.452874",
     "exception": false,
     "start_time": "2021-11-13T14:55:56.155437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921bbd29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:17.137103Z",
     "iopub.status.busy": "2021-11-13T14:56:17.136146Z",
     "iopub.status.idle": "2021-11-13T14:56:17.137983Z",
     "shell.execute_reply": "2021-11-13T14:56:17.138695Z",
     "shell.execute_reply.started": "2021-11-13T14:53:02.170297Z"
    },
    "papermill": {
     "duration": 13.644567,
     "end_time": "2021-11-13T14:56:17.138853",
     "exception": false,
     "start_time": "2021-11-13T14:56:03.494286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 7#10#3\n",
    "BATCH_SIZE = 16#24#32#16#1\n",
    "MAX_LEN = 128#248\n",
    "EVAL_SCHEDULE = [(0.30, 16), (0.25, 8), (0.20, 4), (0.15, 2), (-1., 1)]#[(0.35, 16), (0.30, 8), (0.25, 4), (0.20, 2), (-1., 1)]#\n",
    "BASE_MODEL_PATH = \"./xlm-roberta-large\"#\"./xlm-roberta-base\"##./tamillion\"#\"./indic-bert\"\"#\n",
    "ROBERTA_PATH = BASE_MODEL_PATH+\"/pytorch_model.bin\"#\"./xlm-roberta-base/pytorch_model.bin\"\n",
    "TOKENIZER_PATH = BASE_MODEL_PATH#\"./xlm-roberta-base\"#\"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "CONFIG_PATH = BASE_MODEL_PATH+\"/config.json\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa7cdd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:17.226594Z",
     "iopub.status.busy": "2021-11-13T14:56:17.225905Z",
     "iopub.status.idle": "2021-11-13T14:56:17.228609Z",
     "shell.execute_reply": "2021-11-13T14:56:17.228141Z",
     "shell.execute_reply.started": "2021-11-13T14:53:02.228735Z"
    },
    "papermill": {
     "duration": 0.047986,
     "end_time": "2021-11-13T14:56:17.228720",
     "exception": false,
     "start_time": "2021-11-13T14:56:17.180734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a33107ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:17.315003Z",
     "iopub.status.busy": "2021-11-13T14:56:17.314241Z",
     "iopub.status.idle": "2021-11-13T14:56:17.316208Z",
     "shell.execute_reply": "2021-11-13T14:56:17.316645Z",
     "shell.execute_reply.started": "2021-11-13T14:53:03.863772Z"
    },
    "papermill": {
     "duration": 0.047013,
     "end_time": "2021-11-13T14:56:17.316768",
     "exception": false,
     "start_time": "2021-11-13T14:56:17.269755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76dbdfe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:17.401242Z",
     "iopub.status.busy": "2021-11-13T14:56:17.400764Z",
     "iopub.status.idle": "2021-11-13T14:56:18.057156Z",
     "shell.execute_reply": "2021-11-13T14:56:18.057651Z",
     "shell.execute_reply.started": "2021-11-13T14:53:03.874202Z"
    },
    "papermill": {
     "duration": 0.700458,
     "end_time": "2021-11-13T14:56:18.057835",
     "exception": false,
     "start_time": "2021-11-13T14:56:17.357377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d2a134",
   "metadata": {
    "papermill": {
     "duration": 0.040467,
     "end_time": "2021-11-13T14:56:18.139542",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.099075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb710b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.228514Z",
     "iopub.status.busy": "2021-11-13T14:56:18.227722Z",
     "iopub.status.idle": "2021-11-13T14:56:18.232284Z",
     "shell.execute_reply": "2021-11-13T14:56:18.231892Z",
     "shell.execute_reply.started": "2021-11-13T14:53:41.327821Z"
    },
    "papermill": {
     "duration": 0.052121,
     "end_time": "2021-11-13T14:56:18.232414",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.180293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        self.question = df.question.tolist()\n",
    "        self.pred_text = df.pred_text.tolist()\n",
    "        self.require_text = df.require_text.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "#         self.encoded = tokenizer.batch_encode_plus(\n",
    "#             self.text,\n",
    "#             padding = 'max_length',            \n",
    "#             max_length = MAX_LEN,\n",
    "#             truncation = True,\n",
    "#             return_attention_mask=True\n",
    "#         )  \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "#             self.question, self.pred_text, self.require_text,\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=False\n",
    "        )  \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e677ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.319042Z",
     "iopub.status.busy": "2021-11-13T14:56:18.318128Z",
     "iopub.status.idle": "2021-11-13T14:56:18.320966Z",
     "shell.execute_reply": "2021-11-13T14:56:18.320492Z",
     "shell.execute_reply.started": "2021-11-13T14:53:41.466519Z"
    },
    "papermill": {
     "duration": 0.048604,
     "end_time": "2021-11-13T14:56:18.321076",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.272472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # https://arxiv.org/pdf/2103.04083v1.pdf\n",
    "# class LitModel(nn.Module):  \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         config = AutoConfig.from_pretrained(CONFIG_PATH)\n",
    "#         config.update({\"output_hidden_states\":True, \n",
    "#                        \"hidden_dropout_prob\": 0.0,\n",
    "# #                        \"attention_probs_dropout_prob\":0.0,\n",
    "#                        \"layer_norm_eps\": 1e-7\n",
    "#                       })                       \n",
    "        \n",
    "#         self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "# #         self.cnn1 = nn.Conv1d(768, MAX_LEN, kernel_size=1)\n",
    "# #         self.cnn2 = nn.Conv1d(MAX_LEN, 1, kernel_size=1)\n",
    "#         self.cnn1 = nn.Conv1d(768, 512, kernel_size=1)\n",
    "#         self.cnn2 = nn.Conv1d(512, MAX_LEN, kernel_size=1)\n",
    "         \n",
    "# #         self.layernorm = nn.LayerNorm(MAX_LEN,MAX_LEN)    \n",
    "#         self.layernorm = nn.LayerNorm(MAX_LEN)\n",
    "            \n",
    "#         self.attention = nn.Sequential(            \n",
    "#             nn.Linear(MAX_LEN, MAX_LEN),            \n",
    "#             nn.Tanh(),  \n",
    "#             nn.Linear(MAX_LEN, 1),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )        \n",
    "\n",
    "#         self.regressor = nn.Sequential(      \n",
    "# #             nn.LayerNorm(768),\n",
    "#             nn.Linear(MAX_LEN, 1),      \n",
    "# #             nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         roberta_output = self.roberta(input_ids=input_ids,\n",
    "#                                       attention_mask=attention_mask)   \n",
    "#         last_hidden_state = roberta_output.hidden_states[-1]\n",
    "# #         print(last_hidden_state.shape)\n",
    "#         last_hidden_state = last_hidden_state.permute(0, 2, 1)#16*768*MAX_LEN\n",
    "# #         print(last_hidden_state.shape)\n",
    "#         cnn_embeddings = F.relu(self.cnn1(last_hidden_state))#16*512*MAX_LEN\n",
    "# #         print(cnn_embeddings.shape)\n",
    "#         cnn_embeddings = self.cnn2(cnn_embeddings)#16*MAX_LEN(embedding)*MAX_LEN(tokens)\n",
    "# #         print(cnn_embeddings.shape)\n",
    "#         cnn_embeddings = cnn_embeddings.permute(0, 2, 1)\n",
    "# #         cnn_embeddings = self.layernorm(cnn_embeddings)\n",
    "# #         print(cnn_embeddings.shape)\n",
    "#         # There are a total of 13 layers of hidden states.\n",
    "#         # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "#         # We take the hidden states from the last Roberta layer.\n",
    "# #         last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "        \n",
    "\n",
    "#         # The number of cells is MAX_LEN.\n",
    "#         # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "#         # In order to condense hidden states of all cells to a context vector,\n",
    "#         # we compute a weighted average of the hidden states of all cells.\n",
    "#         # We compute the weight of each cell, using the attention neural network.\n",
    "# #         print(cnn_embeddings.shape)\n",
    "#         weights = self.attention(cnn_embeddings)#16*MAX_LEN*1\n",
    "# #         print('weights.shape',weights.shape)\n",
    "                \n",
    "#         # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "#         # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "#         # Now we compute context_vector as the weighted average.\n",
    "#         # context_vector.shape is BATCH_SIZE x 768\n",
    "#         context_vector = torch.sum(weights * cnn_embeddings, dim=1)#16*MAX_LEN   \n",
    "# #         print('context_vector',context_vector.shape)\n",
    "        \n",
    "#         # Now we reduce the context vector to the prediction score.\n",
    "#         return self.regressor(context_vector)#16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bef0b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.409711Z",
     "iopub.status.busy": "2021-11-13T14:56:18.409016Z",
     "iopub.status.idle": "2021-11-13T14:56:18.411173Z",
     "shell.execute_reply": "2021-11-13T14:56:18.411589Z",
     "shell.execute_reply.started": "2021-11-13T14:53:41.647857Z"
    },
    "papermill": {
     "duration": 0.050157,
     "end_time": "2021-11-13T14:56:18.411710",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.361553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitModel(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(CONFIG_PATH)                     \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=self.config)  \n",
    "#         self.cnn1 = nn.Conv1d(768, MAX_LEN, kernel_size=1)\n",
    "#         self.cnn2 = nn.Conv1d(MAX_LEN, 1, kernel_size=1)\n",
    "        self.cnn1 = nn.Conv1d(768, 512, kernel_size=1)\n",
    "        self.cnn2 = nn.Conv1d(512, MAX_LEN, kernel_size=1)\n",
    "         \n",
    "#         self.layernorm = nn.LayerNorm(MAX_LEN,MAX_LEN)    \n",
    "        self.layernorm = nn.LayerNorm(MAX_LEN)\n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(MAX_LEN, MAX_LEN),            \n",
    "            nn.Tanh(),  \n",
    "            nn.Linear(MAX_LEN, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(      \n",
    "#             nn.LayerNorm(768),\n",
    "            nn.Linear(self.config.hidden_size, 1),      \n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)   \n",
    "        last_hidden_state = roberta_output[0]\n",
    "        cls_embeddings = last_hidden_state[:, 0]\n",
    "#         print(cls_embeddings.shape)\n",
    "        logits = self.regressor(cls_embeddings) # regression head\n",
    "#         print(logits.shape)\n",
    "        return logits#16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5df4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.499253Z",
     "iopub.status.busy": "2021-11-13T14:56:18.498542Z",
     "iopub.status.idle": "2021-11-13T14:56:18.500891Z",
     "shell.execute_reply": "2021-11-13T14:56:18.501324Z",
     "shell.execute_reply.started": "2021-11-13T14:53:41.811645Z"
    },
    "papermill": {
     "duration": 0.049049,
     "end_time": "2021-11-13T14:56:18.501479",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.452430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ffc7f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.588477Z",
     "iopub.status.busy": "2021-11-13T14:56:18.587792Z",
     "iopub.status.idle": "2021-11-13T14:56:18.590297Z",
     "shell.execute_reply": "2021-11-13T14:56:18.589912Z",
     "shell.execute_reply.started": "2021-11-13T14:53:41.981252Z"
    },
    "papermill": {
     "duration": 0.048177,
     "end_time": "2021-11-13T14:56:18.590426",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.542249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7af10de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.682324Z",
     "iopub.status.busy": "2021-11-13T14:56:18.678551Z",
     "iopub.status.idle": "2021-11-13T14:56:18.684745Z",
     "shell.execute_reply": "2021-11-13T14:56:18.684245Z",
     "shell.execute_reply.started": "2021-11-13T14:53:42.150796Z"
    },
    "papermill": {
     "duration": 0.053895,
     "end_time": "2021-11-13T14:56:18.684850",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.630955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, model_path, train_loader, val_loader,\n",
    "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
    "    best_val_rmse = None\n",
    "    best_epoch = 0\n",
    "    step = 0\n",
    "    last_eval_step = 0\n",
    "    eval_period = EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):                           \n",
    "        val_rmse = None         \n",
    "\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)            \n",
    "            target = target.to(DEVICE)                        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            pred = model(input_ids, attention_mask)\n",
    "#             print(pred.shape)\n",
    "                                                        \n",
    "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
    "#             print(mse)\n",
    "                        \n",
    "            mse.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            if step >= last_eval_step + eval_period:\n",
    "                # Evaluate the model on val_loader.\n",
    "                elapsed_seconds = time.time() - start\n",
    "                num_steps = step - last_eval_step\n",
    "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                last_eval_step = step\n",
    "                \n",
    "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
    "\n",
    "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
    "                      f\"val_rmse: {val_rmse:0.4}\")\n",
    "\n",
    "                for rmse, period in EVAL_SCHEDULE:\n",
    "                    if val_rmse >= rmse:\n",
    "                        eval_period = period\n",
    "                        break                               \n",
    "                \n",
    "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
    "                    best_val_rmse = val_rmse\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "                else:       \n",
    "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "                          f\"(from epoch {best_epoch})\")                                    \n",
    "                    \n",
    "                start = time.time()\n",
    "                                            \n",
    "            step += 1\n",
    "                        \n",
    "    \n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ca08b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.773891Z",
     "iopub.status.busy": "2021-11-13T14:56:18.773146Z",
     "iopub.status.idle": "2021-11-13T14:56:18.775526Z",
     "shell.execute_reply": "2021-11-13T14:56:18.775071Z",
     "shell.execute_reply.started": "2021-11-13T14:53:42.332110Z"
    },
    "papermill": {
     "duration": 0.050913,
     "end_time": "2021-11-13T14:56:18.775629",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.724716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    named_parameters = list(model.named_parameters())    \n",
    "    \n",
    "    roberta_parameters = named_parameters[:197]    \n",
    "    attention_parameters = named_parameters[199:203]\n",
    "    regressor_parameters = named_parameters[203:]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "\n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group,\n",
    "                       \"weight_decay\": 0.001,\n",
    "                      \"lr\": 1e-3})\n",
    "    parameters.append({\"params\": regressor_group,\n",
    "                       \"weight_decay\": 0.001,\n",
    "                      \"lr\": 1e-3})\n",
    "\n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
    "\n",
    "        lr = 2e-5\n",
    "\n",
    "        if layer_num >= 69:        \n",
    "            lr = 5e-5\n",
    "\n",
    "        if layer_num >= 133:\n",
    "            lr = 1e-4\n",
    "\n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "\n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59163eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.860070Z",
     "iopub.status.busy": "2021-11-13T14:56:18.859305Z",
     "iopub.status.idle": "2021-11-13T14:56:18.861769Z",
     "shell.execute_reply": "2021-11-13T14:56:18.861337Z",
     "shell.execute_reply.started": "2021-11-13T14:53:42.499369Z"
    },
    "papermill": {
     "duration": 0.046095,
     "end_time": "2021-11-13T14:56:18.861871",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.815776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKENIZERS_PARALLELISM=True #False\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"#\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd34b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:18.954859Z",
     "iopub.status.busy": "2021-11-13T14:56:18.954173Z",
     "iopub.status.idle": "2021-11-13T14:56:18.957226Z",
     "shell.execute_reply": "2021-11-13T14:56:18.957662Z",
     "shell.execute_reply.started": "2021-11-13T14:53:42.701334Z"
    },
    "papermill": {
     "duration": 0.055686,
     "end_time": "2021-11-13T14:56:18.957779",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.902093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>require_text</th>\n",
       "      <th>jac_score</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>208</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answer_text                              question  \\\n",
       "0         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "2         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "3         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "4         206  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "\n",
       "                                           pred_text  \\\n",
       "0                                                206   \n",
       "1   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "2                                                208   \n",
       "3   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "4   206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "\n",
       "                                        require_text  jac_score  \\\n",
       "0  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   1.000000   \n",
       "1  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667   \n",
       "2  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.000000   \n",
       "3  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667   \n",
       "4  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.142857   \n",
       "\n",
       "                                             excerpt  target  \n",
       "0  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    1.00  \n",
       "1  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.17  \n",
       "2  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.00  \n",
       "3  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.17  \n",
       "4  <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.14  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23ffd9d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:19.043065Z",
     "iopub.status.busy": "2021-11-13T14:56:19.042430Z",
     "iopub.status.idle": "2021-11-13T14:56:19.044560Z",
     "shell.execute_reply": "2021-11-13T14:56:19.044998Z",
     "shell.execute_reply.started": "2021-11-13T14:53:42.932822Z"
    },
    "papermill": {
     "duration": 0.04648,
     "end_time": "2021-11-13T14:56:19.045119",
     "exception": false,
     "start_time": "2021-11-13T14:56:18.998639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = LitModel()\n",
    "# list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d34e7bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T14:56:19.297169Z",
     "iopub.status.busy": "2021-11-13T14:56:19.296284Z",
     "iopub.status.idle": "2021-11-13T20:30:40.846307Z",
     "shell.execute_reply": "2021-11-13T20:30:40.846802Z"
    },
    "papermill": {
     "duration": 20061.761183,
     "end_time": "2021-11-13T20:30:40.846990",
     "exception": false,
     "start_time": "2021-11-13T14:56:19.085807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "\n",
      "16 steps took 13.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.6667\n",
      "New best_val_rmse: 0.6667\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.504\n",
      "New best_val_rmse: 0.504\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.4626\n",
      "New best_val_rmse: 0.4626\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.4318\n",
      "New best_val_rmse: 0.4318\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.4347\n",
      "Still best_val_rmse: 0.4318 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.376\n",
      "New best_val_rmse: 0.376\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.3724\n",
      "New best_val_rmse: 0.3724\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.4007\n",
      "Still best_val_rmse: 0.3724 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.3625\n",
      "New best_val_rmse: 0.3625\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 160 val_rmse: 0.4283\n",
      "Still best_val_rmse: 0.3625 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 176 val_rmse: 0.4482\n",
      "Still best_val_rmse: 0.3625 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 192 val_rmse: 0.3628\n",
      "Still best_val_rmse: 0.3625 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 208 val_rmse: 0.3617\n",
      "New best_val_rmse: 0.3617\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 224 val_rmse: 0.368\n",
      "Still best_val_rmse: 0.3617 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 240 val_rmse: 0.3576\n",
      "New best_val_rmse: 0.3576\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 256 val_rmse: 0.3579\n",
      "Still best_val_rmse: 0.3576 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 272 val_rmse: 0.355\n",
      "New best_val_rmse: 0.355\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 10 val_rmse: 0.3531\n",
      "New best_val_rmse: 0.3531\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 26 val_rmse: 0.3864\n",
      "Still best_val_rmse: 0.3531 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 42 val_rmse: 0.3527\n",
      "New best_val_rmse: 0.3527\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 58 val_rmse: 0.3536\n",
      "Still best_val_rmse: 0.3527 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 74 val_rmse: 0.35\n",
      "New best_val_rmse: 0.35\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 90 val_rmse: 0.3672\n",
      "Still best_val_rmse: 0.35 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 106 val_rmse: 0.3689\n",
      "Still best_val_rmse: 0.35 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 122 val_rmse: 0.3618\n",
      "Still best_val_rmse: 0.35 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 138 val_rmse: 0.3481\n",
      "New best_val_rmse: 0.3481\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 154 val_rmse: 0.3466\n",
      "New best_val_rmse: 0.3466\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 170 val_rmse: 0.3479\n",
      "Still best_val_rmse: 0.3466 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 186 val_rmse: 0.3462\n",
      "New best_val_rmse: 0.3462\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 202 val_rmse: 0.3441\n",
      "New best_val_rmse: 0.3441\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 218 val_rmse: 0.3451\n",
      "Still best_val_rmse: 0.3441 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 234 val_rmse: 0.3596\n",
      "Still best_val_rmse: 0.3441 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 250 val_rmse: 0.3403\n",
      "New best_val_rmse: 0.3403\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 266 val_rmse: 0.3461\n",
      "Still best_val_rmse: 0.3403 (from epoch 1)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.3507\n",
      "Still best_val_rmse: 0.3403 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.3501\n",
      "Still best_val_rmse: 0.3403 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.3842\n",
      "Still best_val_rmse: 0.3403 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.3441\n",
      "Still best_val_rmse: 0.3403 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.3451\n",
      "Still best_val_rmse: 0.3403 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.3381\n",
      "New best_val_rmse: 0.3381\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.3372\n",
      "New best_val_rmse: 0.3372\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.354\n",
      "Still best_val_rmse: 0.3372 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.3427\n",
      "Still best_val_rmse: 0.3372 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 148 val_rmse: 0.3388\n",
      "Still best_val_rmse: 0.3372 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 164 val_rmse: 0.3348\n",
      "New best_val_rmse: 0.3348\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 180 val_rmse: 0.3476\n",
      "Still best_val_rmse: 0.3348 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 196 val_rmse: 0.3375\n",
      "Still best_val_rmse: 0.3348 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 212 val_rmse: 0.3305\n",
      "New best_val_rmse: 0.3305\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 228 val_rmse: 0.3319\n",
      "Still best_val_rmse: 0.3305 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 244 val_rmse: 0.329\n",
      "New best_val_rmse: 0.329\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 260 val_rmse: 0.3262\n",
      "New best_val_rmse: 0.3262\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 276 val_rmse: 0.3263\n",
      "Still best_val_rmse: 0.3262 (from epoch 2)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.3267\n",
      "Still best_val_rmse: 0.3262 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.343\n",
      "Still best_val_rmse: 0.3262 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.3383\n",
      "Still best_val_rmse: 0.3262 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.359\n",
      "Still best_val_rmse: 0.3262 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.3306\n",
      "Still best_val_rmse: 0.3262 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 94 val_rmse: 0.3185\n",
      "New best_val_rmse: 0.3185\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 110 val_rmse: 0.3226\n",
      "Still best_val_rmse: 0.3185 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 126 val_rmse: 0.3213\n",
      "Still best_val_rmse: 0.3185 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 142 val_rmse: 0.3233\n",
      "Still best_val_rmse: 0.3185 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 158 val_rmse: 0.3369\n",
      "Still best_val_rmse: 0.3185 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 174 val_rmse: 0.323\n",
      "Still best_val_rmse: 0.3185 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 190 val_rmse: 0.3308\n",
      "Still best_val_rmse: 0.3185 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 206 val_rmse: 0.3169\n",
      "New best_val_rmse: 0.3169\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 222 val_rmse: 0.3256\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 238 val_rmse: 0.3199\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 254 val_rmse: 0.3218\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 270 val_rmse: 0.3211\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.3343\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.3241\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.3541\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.3269\n",
      "Still best_val_rmse: 0.3169 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.315\n",
      "New best_val_rmse: 0.315\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 88 val_rmse: 0.3188\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 104 val_rmse: 0.3339\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 120 val_rmse: 0.3176\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 136 val_rmse: 0.3162\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 152 val_rmse: 0.3231\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 168 val_rmse: 0.3182\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 184 val_rmse: 0.3196\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 200 val_rmse: 0.3298\n",
      "Still best_val_rmse: 0.315 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 216 val_rmse: 0.3106\n",
      "New best_val_rmse: 0.3106\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 232 val_rmse: 0.3165\n",
      "Still best_val_rmse: 0.3106 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 248 val_rmse: 0.3217\n",
      "Still best_val_rmse: 0.3106 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 264 val_rmse: 0.3198\n",
      "Still best_val_rmse: 0.3106 (from epoch 4)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 5 batch_num: 2 val_rmse: 0.3103\n",
      "New best_val_rmse: 0.3103\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 18 val_rmse: 0.3295\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 34 val_rmse: 0.3212\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 50 val_rmse: 0.3146\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 66 val_rmse: 0.3131\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 82 val_rmse: 0.3174\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 98 val_rmse: 0.321\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 114 val_rmse: 0.3263\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 130 val_rmse: 0.312\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 146 val_rmse: 0.3201\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 162 val_rmse: 0.3119\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 178 val_rmse: 0.319\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 194 val_rmse: 0.3316\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 210 val_rmse: 0.311\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 226 val_rmse: 0.3195\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 242 val_rmse: 0.3192\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 258 val_rmse: 0.3219\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 274 val_rmse: 0.3184\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 6 batch_num: 12 val_rmse: 0.3206\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 28 val_rmse: 0.3225\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 44 val_rmse: 0.3149\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 60 val_rmse: 0.3251\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 76 val_rmse: 0.3144\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 92 val_rmse: 0.316\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 108 val_rmse: 0.3169\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 124 val_rmse: 0.319\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 140 val_rmse: 0.3161\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 156 val_rmse: 0.3173\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 172 val_rmse: 0.3198\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 188 val_rmse: 0.3206\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 204 val_rmse: 0.3184\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 220 val_rmse: 0.3187\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 236 val_rmse: 0.3193\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 252 val_rmse: 0.3196\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 268 val_rmse: 0.3196\n",
      "Still best_val_rmse: 0.3103 (from epoch 5)\n",
      "\n",
      "Performance estimates:\n",
      "[0.31026969003605726]\n",
      "Mean: 0.31026969003605726\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.3796\n",
      "New best_val_rmse: 0.3796\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.4359\n",
      "Still best_val_rmse: 0.3796 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.3842\n",
      "Still best_val_rmse: 0.3796 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.4753\n",
      "Still best_val_rmse: 0.3796 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.3721\n",
      "New best_val_rmse: 0.3721\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.3799\n",
      "Still best_val_rmse: 0.3721 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.3903\n",
      "Still best_val_rmse: 0.3721 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.3983\n",
      "Still best_val_rmse: 0.3721 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.3715\n",
      "New best_val_rmse: 0.3715\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 160 val_rmse: 0.3612\n",
      "New best_val_rmse: 0.3612\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 176 val_rmse: 0.3799\n",
      "Still best_val_rmse: 0.3612 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 192 val_rmse: 0.3667\n",
      "Still best_val_rmse: 0.3612 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 208 val_rmse: 0.36\n",
      "New best_val_rmse: 0.36\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 224 val_rmse: 0.3786\n",
      "Still best_val_rmse: 0.36 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 240 val_rmse: 0.3574\n",
      "New best_val_rmse: 0.3574\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 256 val_rmse: 0.3781\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 272 val_rmse: 0.3743\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 10 val_rmse: 0.3685\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 26 val_rmse: 0.3641\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 42 val_rmse: 0.3708\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 58 val_rmse: 0.3582\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 74 val_rmse: 0.3706\n",
      "Still best_val_rmse: 0.3574 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 90 val_rmse: 0.3547\n",
      "New best_val_rmse: 0.3547\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 106 val_rmse: 0.3733\n",
      "Still best_val_rmse: 0.3547 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 122 val_rmse: 0.3522\n",
      "New best_val_rmse: 0.3522\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 138 val_rmse: 0.3676\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 154 val_rmse: 0.3664\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 170 val_rmse: 0.3618\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 186 val_rmse: 0.3662\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 202 val_rmse: 0.3558\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 218 val_rmse: 0.3572\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 234 val_rmse: 0.3545\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 250 val_rmse: 0.3628\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 266 val_rmse: 0.357\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.4028\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.3566\n",
      "Still best_val_rmse: 0.3522 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.346\n",
      "New best_val_rmse: 0.346\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.3555\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.3478\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.349\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.3483\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.3505\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.3472\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 148 val_rmse: 0.3641\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 164 val_rmse: 0.3545\n",
      "Still best_val_rmse: 0.346 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 180 val_rmse: 0.3417\n",
      "New best_val_rmse: 0.3417\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 196 val_rmse: 0.3463\n",
      "Still best_val_rmse: 0.3417 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 212 val_rmse: 0.3394\n",
      "New best_val_rmse: 0.3394\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 228 val_rmse: 0.3428\n",
      "Still best_val_rmse: 0.3394 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 244 val_rmse: 0.3409\n",
      "Still best_val_rmse: 0.3394 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 260 val_rmse: 0.3511\n",
      "Still best_val_rmse: 0.3394 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 276 val_rmse: 0.3379\n",
      "New best_val_rmse: 0.3379\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.3495\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.3451\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.3403\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.3405\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.3474\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 94 val_rmse: 0.3415\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 110 val_rmse: 0.3473\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 126 val_rmse: 0.3418\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 142 val_rmse: 0.3432\n",
      "Still best_val_rmse: 0.3379 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 158 val_rmse: 0.3379\n",
      "New best_val_rmse: 0.3379\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 174 val_rmse: 0.336\n",
      "New best_val_rmse: 0.336\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 190 val_rmse: 0.3315\n",
      "New best_val_rmse: 0.3315\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 206 val_rmse: 0.3278\n",
      "New best_val_rmse: 0.3278\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 222 val_rmse: 0.3282\n",
      "Still best_val_rmse: 0.3278 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 238 val_rmse: 0.3465\n",
      "Still best_val_rmse: 0.3278 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 254 val_rmse: 0.3278\n",
      "New best_val_rmse: 0.3278\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 270 val_rmse: 0.3335\n",
      "Still best_val_rmse: 0.3278 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.3262\n",
      "New best_val_rmse: 0.3262\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.3275\n",
      "Still best_val_rmse: 0.3262 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.3292\n",
      "Still best_val_rmse: 0.3262 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.3291\n",
      "Still best_val_rmse: 0.3262 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.3303\n",
      "Still best_val_rmse: 0.3262 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 88 val_rmse: 0.3272\n",
      "Still best_val_rmse: 0.3262 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 104 val_rmse: 0.3267\n",
      "Still best_val_rmse: 0.3262 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 120 val_rmse: 0.3223\n",
      "New best_val_rmse: 0.3223\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 136 val_rmse: 0.3259\n",
      "Still best_val_rmse: 0.3223 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 152 val_rmse: 0.343\n",
      "Still best_val_rmse: 0.3223 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 168 val_rmse: 0.3279\n",
      "Still best_val_rmse: 0.3223 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 184 val_rmse: 0.3645\n",
      "Still best_val_rmse: 0.3223 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 200 val_rmse: 0.3284\n",
      "Still best_val_rmse: 0.3223 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 216 val_rmse: 0.3214\n",
      "New best_val_rmse: 0.3214\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 232 val_rmse: 0.321\n",
      "New best_val_rmse: 0.321\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 248 val_rmse: 0.3345\n",
      "Still best_val_rmse: 0.321 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 264 val_rmse: 0.3199\n",
      "New best_val_rmse: 0.3199\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 5 batch_num: 2 val_rmse: 0.3194\n",
      "New best_val_rmse: 0.3194\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 18 val_rmse: 0.3301\n",
      "Still best_val_rmse: 0.3194 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 34 val_rmse: 0.3256\n",
      "Still best_val_rmse: 0.3194 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 50 val_rmse: 0.322\n",
      "Still best_val_rmse: 0.3194 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 66 val_rmse: 0.3192\n",
      "New best_val_rmse: 0.3192\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 82 val_rmse: 0.32\n",
      "Still best_val_rmse: 0.3192 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 98 val_rmse: 0.323\n",
      "Still best_val_rmse: 0.3192 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 114 val_rmse: 0.3207\n",
      "Still best_val_rmse: 0.3192 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 130 val_rmse: 0.3193\n",
      "Still best_val_rmse: 0.3192 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 146 val_rmse: 0.3206\n",
      "Still best_val_rmse: 0.3192 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 162 val_rmse: 0.3213\n",
      "Still best_val_rmse: 0.3192 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 178 val_rmse: 0.318\n",
      "New best_val_rmse: 0.318\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 194 val_rmse: 0.3191\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 210 val_rmse: 0.3326\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 226 val_rmse: 0.3185\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 242 val_rmse: 0.319\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 258 val_rmse: 0.3192\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 274 val_rmse: 0.3203\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 6 batch_num: 12 val_rmse: 0.3203\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 28 val_rmse: 0.3181\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 44 val_rmse: 0.3181\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 60 val_rmse: 0.3186\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 76 val_rmse: 0.3209\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 92 val_rmse: 0.3227\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 108 val_rmse: 0.3207\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 124 val_rmse: 0.3202\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 140 val_rmse: 0.3196\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 156 val_rmse: 0.3206\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 172 val_rmse: 0.3195\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 188 val_rmse: 0.3188\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 204 val_rmse: 0.3187\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 220 val_rmse: 0.3185\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 236 val_rmse: 0.3185\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 252 val_rmse: 0.3185\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 268 val_rmse: 0.3185\n",
      "Still best_val_rmse: 0.318 (from epoch 5)\n",
      "\n",
      "Performance estimates:\n",
      "[0.31026969003605726, 0.3180068755343076]\n",
      "Mean: 0.3141382827851824\n",
      "\n",
      "Fold 3/5\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.3933\n",
      "New best_val_rmse: 0.3933\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.3849\n",
      "New best_val_rmse: 0.3849\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.3801\n",
      "New best_val_rmse: 0.3801\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.3836\n",
      "Still best_val_rmse: 0.3801 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.3547\n",
      "New best_val_rmse: 0.3547\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.3518\n",
      "New best_val_rmse: 0.3518\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.3725\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.3631\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.4089\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 160 val_rmse: 0.3588\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 176 val_rmse: 0.3525\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 192 val_rmse: 0.3764\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 208 val_rmse: 0.3706\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 224 val_rmse: 0.3863\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 240 val_rmse: 0.3619\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 256 val_rmse: 0.3541\n",
      "Still best_val_rmse: 0.3518 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 272 val_rmse: 0.3506\n",
      "New best_val_rmse: 0.3506\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 10 val_rmse: 0.357\n",
      "Still best_val_rmse: 0.3506 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 26 val_rmse: 0.367\n",
      "Still best_val_rmse: 0.3506 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 42 val_rmse: 0.3448\n",
      "New best_val_rmse: 0.3448\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 58 val_rmse: 0.3426\n",
      "New best_val_rmse: 0.3426\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 74 val_rmse: 0.3386\n",
      "New best_val_rmse: 0.3386\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 90 val_rmse: 0.3509\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 106 val_rmse: 0.3499\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 122 val_rmse: 0.3551\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 138 val_rmse: 0.3386\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 154 val_rmse: 0.3448\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 170 val_rmse: 0.4097\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 186 val_rmse: 0.3512\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 202 val_rmse: 0.3742\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 218 val_rmse: 0.399\n",
      "Still best_val_rmse: 0.3386 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 234 val_rmse: 0.3308\n",
      "New best_val_rmse: 0.3308\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 250 val_rmse: 0.3231\n",
      "New best_val_rmse: 0.3231\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 266 val_rmse: 0.3235\n",
      "Still best_val_rmse: 0.3231 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.319\n",
      "New best_val_rmse: 0.319\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.3238\n",
      "Still best_val_rmse: 0.319 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.3439\n",
      "Still best_val_rmse: 0.319 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.3258\n",
      "Still best_val_rmse: 0.319 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.3245\n",
      "Still best_val_rmse: 0.319 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.3158\n",
      "New best_val_rmse: 0.3158\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.3206\n",
      "Still best_val_rmse: 0.3158 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.3128\n",
      "New best_val_rmse: 0.3128\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.3166\n",
      "Still best_val_rmse: 0.3128 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 148 val_rmse: 0.3541\n",
      "Still best_val_rmse: 0.3128 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 164 val_rmse: 0.3501\n",
      "Still best_val_rmse: 0.3128 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 180 val_rmse: 0.3673\n",
      "Still best_val_rmse: 0.3128 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 196 val_rmse: 0.318\n",
      "Still best_val_rmse: 0.3128 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 212 val_rmse: 0.3179\n",
      "Still best_val_rmse: 0.3128 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 228 val_rmse: 0.3046\n",
      "New best_val_rmse: 0.3046\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 244 val_rmse: 0.3082\n",
      "Still best_val_rmse: 0.3046 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 260 val_rmse: 0.3091\n",
      "Still best_val_rmse: 0.3046 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 276 val_rmse: 0.3045\n",
      "New best_val_rmse: 0.3045\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.3094\n",
      "Still best_val_rmse: 0.3045 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.3128\n",
      "Still best_val_rmse: 0.3045 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.3023\n",
      "New best_val_rmse: 0.3023\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.3037\n",
      "Still best_val_rmse: 0.3023 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.3045\n",
      "Still best_val_rmse: 0.3023 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 94 val_rmse: 0.3032\n",
      "Still best_val_rmse: 0.3023 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 110 val_rmse: 0.3018\n",
      "New best_val_rmse: 0.3018\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 126 val_rmse: 0.3382\n",
      "Still best_val_rmse: 0.3018 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 142 val_rmse: 0.3478\n",
      "Still best_val_rmse: 0.3018 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 158 val_rmse: 0.2992\n",
      "New best_val_rmse: 0.2992\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 3 batch_num: 166 val_rmse: 0.3005\n",
      "Still best_val_rmse: 0.2992 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 182 val_rmse: 0.3055\n",
      "Still best_val_rmse: 0.2992 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 198 val_rmse: 0.2969\n",
      "New best_val_rmse: 0.2969\n",
      "\n",
      "8 steps took 5.97 seconds\n",
      "Epoch: 3 batch_num: 206 val_rmse: 0.3009\n",
      "Still best_val_rmse: 0.2969 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 222 val_rmse: 0.3048\n",
      "Still best_val_rmse: 0.2969 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 238 val_rmse: 0.2949\n",
      "New best_val_rmse: 0.2949\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 3 batch_num: 246 val_rmse: 0.3011\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 262 val_rmse: 0.3056\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.3103\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.3167\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.2961\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.2989\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.3281\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.306\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 80 val_rmse: 0.3338\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 96 val_rmse: 0.3088\n",
      "Still best_val_rmse: 0.2949 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 112 val_rmse: 0.2906\n",
      "New best_val_rmse: 0.2906\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 4 batch_num: 120 val_rmse: 0.3081\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 136 val_rmse: 0.2931\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 144 val_rmse: 0.3003\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 160 val_rmse: 0.2974\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 168 val_rmse: 0.3312\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 184 val_rmse: 0.2929\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 192 val_rmse: 0.2981\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 4 batch_num: 200 val_rmse: 0.291\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 4 batch_num: 208 val_rmse: 0.2966\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 4 batch_num: 216 val_rmse: 0.2925\n",
      "Still best_val_rmse: 0.2906 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 4 batch_num: 224 val_rmse: 0.2892\n",
      "New best_val_rmse: 0.2892\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 4 batch_num: 232 val_rmse: 0.3019\n",
      "Still best_val_rmse: 0.2892 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 248 val_rmse: 0.3009\n",
      "Still best_val_rmse: 0.2892 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 264 val_rmse: 0.2907\n",
      "Still best_val_rmse: 0.2892 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 272 val_rmse: 0.2889\n",
      "New best_val_rmse: 0.2889\n",
      "\n",
      "8 steps took 6.23 seconds\n",
      "Epoch: 5 batch_num: 2 val_rmse: 0.2915\n",
      "Still best_val_rmse: 0.2889 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 10 val_rmse: 0.3055\n",
      "Still best_val_rmse: 0.2889 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 26 val_rmse: 0.297\n",
      "Still best_val_rmse: 0.2889 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 34 val_rmse: 0.2993\n",
      "Still best_val_rmse: 0.2889 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 42 val_rmse: 0.3035\n",
      "Still best_val_rmse: 0.2889 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 58 val_rmse: 0.2877\n",
      "New best_val_rmse: 0.2877\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 5 batch_num: 66 val_rmse: 0.288\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 74 val_rmse: 0.3042\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 90 val_rmse: 0.2945\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 98 val_rmse: 0.2949\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 106 val_rmse: 0.2908\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 114 val_rmse: 0.3135\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 130 val_rmse: 0.2892\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 138 val_rmse: 0.2928\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 146 val_rmse: 0.3027\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 162 val_rmse: 0.2953\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 5 batch_num: 170 val_rmse: 0.2908\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 178 val_rmse: 0.2922\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 186 val_rmse: 0.2935\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 194 val_rmse: 0.2898\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 202 val_rmse: 0.2971\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 210 val_rmse: 0.295\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 218 val_rmse: 0.2891\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 226 val_rmse: 0.2989\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 234 val_rmse: 0.3229\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 250 val_rmse: 0.2924\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 5 batch_num: 258 val_rmse: 0.2905\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 266 val_rmse: 0.2904\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 274 val_rmse: 0.2918\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 6.2 seconds\n",
      "Epoch: 6 batch_num: 4 val_rmse: 0.3003\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 20 val_rmse: 0.3054\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 36 val_rmse: 0.2941\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 44 val_rmse: 0.2975\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 52 val_rmse: 0.2974\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 60 val_rmse: 0.2935\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 68 val_rmse: 0.2901\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 76 val_rmse: 0.2917\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 6 batch_num: 84 val_rmse: 0.296\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 92 val_rmse: 0.2964\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 6 batch_num: 100 val_rmse: 0.2938\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 108 val_rmse: 0.2919\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 116 val_rmse: 0.2916\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 124 val_rmse: 0.2905\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 132 val_rmse: 0.2921\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 140 val_rmse: 0.2957\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 148 val_rmse: 0.2982\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 156 val_rmse: 0.2981\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 164 val_rmse: 0.297\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 172 val_rmse: 0.2956\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 6 batch_num: 180 val_rmse: 0.2941\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 188 val_rmse: 0.294\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 196 val_rmse: 0.2937\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 204 val_rmse: 0.2937\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 212 val_rmse: 0.2935\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 220 val_rmse: 0.2931\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 228 val_rmse: 0.293\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 236 val_rmse: 0.2928\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 244 val_rmse: 0.2926\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 252 val_rmse: 0.2925\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 260 val_rmse: 0.2925\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 268 val_rmse: 0.2925\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 276 val_rmse: 0.2925\n",
      "Still best_val_rmse: 0.2877 (from epoch 5)\n",
      "\n",
      "Performance estimates:\n",
      "[0.31026969003605726, 0.3180068755343076, 0.2876757769300274]\n",
      "Mean: 0.30531744750013073\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.3687\n",
      "New best_val_rmse: 0.3687\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.3795\n",
      "Still best_val_rmse: 0.3687 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.3909\n",
      "Still best_val_rmse: 0.3687 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.3946\n",
      "Still best_val_rmse: 0.3687 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.3792\n",
      "Still best_val_rmse: 0.3687 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.3673\n",
      "New best_val_rmse: 0.3673\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.3629\n",
      "New best_val_rmse: 0.3629\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.3691\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.3942\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 160 val_rmse: 0.3781\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 176 val_rmse: 0.3944\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 192 val_rmse: 0.374\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 208 val_rmse: 0.368\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 224 val_rmse: 0.3902\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 240 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 256 val_rmse: 0.3866\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 272 val_rmse: 0.3648\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 10 val_rmse: 0.3736\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 26 val_rmse: 0.37\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 42 val_rmse: 0.3657\n",
      "Still best_val_rmse: 0.3629 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 58 val_rmse: 0.3616\n",
      "New best_val_rmse: 0.3616\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 74 val_rmse: 0.3645\n",
      "Still best_val_rmse: 0.3616 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 90 val_rmse: 0.3613\n",
      "New best_val_rmse: 0.3613\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 106 val_rmse: 0.3831\n",
      "Still best_val_rmse: 0.3613 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 122 val_rmse: 0.3589\n",
      "New best_val_rmse: 0.3589\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 138 val_rmse: 0.36\n",
      "Still best_val_rmse: 0.3589 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 154 val_rmse: 0.3646\n",
      "Still best_val_rmse: 0.3589 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 170 val_rmse: 0.3594\n",
      "Still best_val_rmse: 0.3589 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 186 val_rmse: 0.3593\n",
      "Still best_val_rmse: 0.3589 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 202 val_rmse: 0.3644\n",
      "Still best_val_rmse: 0.3589 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 218 val_rmse: 0.3592\n",
      "Still best_val_rmse: 0.3589 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 234 val_rmse: 0.352\n",
      "New best_val_rmse: 0.352\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 250 val_rmse: 0.3508\n",
      "New best_val_rmse: 0.3508\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 266 val_rmse: 0.3601\n",
      "Still best_val_rmse: 0.3508 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.3533\n",
      "Still best_val_rmse: 0.3508 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.3498\n",
      "New best_val_rmse: 0.3498\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.3576\n",
      "Still best_val_rmse: 0.3498 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.3621\n",
      "Still best_val_rmse: 0.3498 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.3533\n",
      "Still best_val_rmse: 0.3498 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.3531\n",
      "Still best_val_rmse: 0.3498 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.3528\n",
      "Still best_val_rmse: 0.3498 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.3458\n",
      "New best_val_rmse: 0.3458\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.3547\n",
      "Still best_val_rmse: 0.3458 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 148 val_rmse: 0.3452\n",
      "New best_val_rmse: 0.3452\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 164 val_rmse: 0.3413\n",
      "New best_val_rmse: 0.3413\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 180 val_rmse: 0.3495\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 196 val_rmse: 0.3474\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 212 val_rmse: 0.3537\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 228 val_rmse: 0.3443\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 244 val_rmse: 0.3429\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 260 val_rmse: 0.346\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 276 val_rmse: 0.3603\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.3686\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.392\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.3983\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.407\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.3835\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 94 val_rmse: 0.3933\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 110 val_rmse: 0.3654\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 126 val_rmse: 0.3684\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 142 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 158 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 174 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 190 val_rmse: 0.3727\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 206 val_rmse: 0.3658\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 222 val_rmse: 0.3684\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 238 val_rmse: 0.3643\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 254 val_rmse: 0.3638\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 270 val_rmse: 0.3662\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.3632\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.3632\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.3689\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.3649\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.3639\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 88 val_rmse: 0.3644\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 104 val_rmse: 0.3639\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 120 val_rmse: 0.3632\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 136 val_rmse: 0.3654\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 152 val_rmse: 0.3644\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 168 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 184 val_rmse: 0.3638\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 200 val_rmse: 0.3647\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 216 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 232 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 248 val_rmse: 0.3637\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 264 val_rmse: 0.364\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 5 batch_num: 2 val_rmse: 0.3636\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 18 val_rmse: 0.3632\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 34 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 50 val_rmse: 0.3638\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 66 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 82 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 98 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 114 val_rmse: 0.3632\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 130 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 146 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 162 val_rmse: 0.3639\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 178 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 194 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 210 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 226 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 242 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 258 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 274 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 6 batch_num: 12 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 28 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 44 val_rmse: 0.3636\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 60 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 76 val_rmse: 0.3633\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 92 val_rmse: 0.3634\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 108 val_rmse: 0.3636\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 124 val_rmse: 0.3636\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 140 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 156 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 172 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 188 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 204 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 220 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 6 batch_num: 236 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 252 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 6 batch_num: 268 val_rmse: 0.3635\n",
      "Still best_val_rmse: 0.3413 (from epoch 2)\n",
      "\n",
      "Performance estimates:\n",
      "[0.31026969003605726, 0.3180068755343076, 0.2876757769300274, 0.34133909013497055]\n",
      "Mean: 0.31432285815884065\n",
      "\n",
      "Fold 5/5\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.3652\n",
      "New best_val_rmse: 0.3652\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.3848\n",
      "Still best_val_rmse: 0.3652 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.3682\n",
      "Still best_val_rmse: 0.3652 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.368\n",
      "Still best_val_rmse: 0.3652 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.3553\n",
      "New best_val_rmse: 0.3553\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.3502\n",
      "New best_val_rmse: 0.3502\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.4021\n",
      "Still best_val_rmse: 0.3502 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.3766\n",
      "Still best_val_rmse: 0.3502 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.3514\n",
      "Still best_val_rmse: 0.3502 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 160 val_rmse: 0.3823\n",
      "Still best_val_rmse: 0.3502 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 176 val_rmse: 0.357\n",
      "Still best_val_rmse: 0.3502 (from epoch 0)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 192 val_rmse: 0.3607\n",
      "Still best_val_rmse: 0.3502 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 208 val_rmse: 0.3474\n",
      "New best_val_rmse: 0.3474\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 224 val_rmse: 0.3856\n",
      "Still best_val_rmse: 0.3474 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 240 val_rmse: 0.3862\n",
      "Still best_val_rmse: 0.3474 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 256 val_rmse: 0.4084\n",
      "Still best_val_rmse: 0.3474 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 272 val_rmse: 0.345\n",
      "New best_val_rmse: 0.345\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 10 val_rmse: 0.3582\n",
      "Still best_val_rmse: 0.345 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 26 val_rmse: 0.361\n",
      "Still best_val_rmse: 0.345 (from epoch 0)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 42 val_rmse: 0.3364\n",
      "New best_val_rmse: 0.3364\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 58 val_rmse: 0.3419\n",
      "Still best_val_rmse: 0.3364 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 74 val_rmse: 0.3303\n",
      "New best_val_rmse: 0.3303\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 90 val_rmse: 0.33\n",
      "New best_val_rmse: 0.33\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 1 batch_num: 106 val_rmse: 0.3302\n",
      "Still best_val_rmse: 0.33 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 122 val_rmse: 0.3335\n",
      "Still best_val_rmse: 0.33 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 138 val_rmse: 0.3354\n",
      "Still best_val_rmse: 0.33 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 154 val_rmse: 0.3264\n",
      "New best_val_rmse: 0.3264\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 170 val_rmse: 0.3296\n",
      "Still best_val_rmse: 0.3264 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 186 val_rmse: 0.3338\n",
      "Still best_val_rmse: 0.3264 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 202 val_rmse: 0.3184\n",
      "New best_val_rmse: 0.3184\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 218 val_rmse: 0.3223\n",
      "Still best_val_rmse: 0.3184 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 234 val_rmse: 0.3283\n",
      "Still best_val_rmse: 0.3184 (from epoch 1)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 1 batch_num: 250 val_rmse: 0.3553\n",
      "Still best_val_rmse: 0.3184 (from epoch 1)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 1 batch_num: 266 val_rmse: 0.3248\n",
      "Still best_val_rmse: 0.3184 (from epoch 1)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.3101\n",
      "New best_val_rmse: 0.3101\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.3204\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.3515\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.3286\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.3156\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.33\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.32\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.3451\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.3194\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 148 val_rmse: 0.3138\n",
      "Still best_val_rmse: 0.3101 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 164 val_rmse: 0.2983\n",
      "New best_val_rmse: 0.2983\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 2 batch_num: 172 val_rmse: 0.3403\n",
      "Still best_val_rmse: 0.2983 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 188 val_rmse: 0.3319\n",
      "Still best_val_rmse: 0.2983 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 204 val_rmse: 0.2947\n",
      "New best_val_rmse: 0.2947\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 2 batch_num: 212 val_rmse: 0.2957\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 2 batch_num: 220 val_rmse: 0.3234\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 2 batch_num: 236 val_rmse: 0.2977\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 2 batch_num: 244 val_rmse: 0.2978\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 2 batch_num: 252 val_rmse: 0.3045\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 2 batch_num: 268 val_rmse: 0.3267\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 6 val_rmse: 0.2981\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.3021\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.3023\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.3011\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.2972\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 3 batch_num: 70 val_rmse: 0.3017\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 86 val_rmse: 0.3189\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 102 val_rmse: 0.3106\n",
      "Still best_val_rmse: 0.2947 (from epoch 2)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 118 val_rmse: 0.2937\n",
      "New best_val_rmse: 0.2937\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 3 batch_num: 126 val_rmse: 0.3544\n",
      "Still best_val_rmse: 0.2937 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 142 val_rmse: 0.2933\n",
      "New best_val_rmse: 0.2933\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 3 batch_num: 150 val_rmse: 0.2904\n",
      "New best_val_rmse: 0.2904\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 3 batch_num: 158 val_rmse: 0.2924\n",
      "Still best_val_rmse: 0.2904 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 3 batch_num: 166 val_rmse: 0.2975\n",
      "Still best_val_rmse: 0.2904 (from epoch 3)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 3 batch_num: 174 val_rmse: 0.3208\n",
      "Still best_val_rmse: 0.2904 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 190 val_rmse: 0.2879\n",
      "New best_val_rmse: 0.2879\n",
      "\n",
      "8 steps took 5.96 seconds\n",
      "Epoch: 3 batch_num: 198 val_rmse: 0.307\n",
      "Still best_val_rmse: 0.2879 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 214 val_rmse: 0.3032\n",
      "Still best_val_rmse: 0.2879 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 3 batch_num: 230 val_rmse: 0.3003\n",
      "Still best_val_rmse: 0.2879 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 3 batch_num: 246 val_rmse: 0.2841\n",
      "New best_val_rmse: 0.2841\n",
      "\n",
      "8 steps took 5.98 seconds\n",
      "Epoch: 3 batch_num: 254 val_rmse: 0.2905\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 3 batch_num: 262 val_rmse: 0.2917\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 3 batch_num: 270 val_rmse: 0.2965\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 6.22 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.3081\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.291\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.2908\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.2984\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.2956\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.3218\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.2919\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.3231\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 88 val_rmse: 0.2854\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 96 val_rmse: 0.2905\n",
      "Still best_val_rmse: 0.2841 (from epoch 3)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 4 batch_num: 104 val_rmse: 0.2817\n",
      "New best_val_rmse: 0.2817\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 4 batch_num: 112 val_rmse: 0.3101\n",
      "Still best_val_rmse: 0.2817 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 128 val_rmse: 0.3258\n",
      "Still best_val_rmse: 0.2817 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 144 val_rmse: 0.314\n",
      "Still best_val_rmse: 0.2817 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 160 val_rmse: 0.2956\n",
      "Still best_val_rmse: 0.2817 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 168 val_rmse: 0.2787\n",
      "New best_val_rmse: 0.2787\n",
      "\n",
      "8 steps took 5.97 seconds\n",
      "Epoch: 4 batch_num: 176 val_rmse: 0.3052\n",
      "Still best_val_rmse: 0.2787 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 192 val_rmse: 0.3224\n",
      "Still best_val_rmse: 0.2787 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 208 val_rmse: 0.3088\n",
      "Still best_val_rmse: 0.2787 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 4 batch_num: 224 val_rmse: 0.3078\n",
      "Still best_val_rmse: 0.2787 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 4 batch_num: 240 val_rmse: 0.2821\n",
      "Still best_val_rmse: 0.2787 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 248 val_rmse: 0.2779\n",
      "New best_val_rmse: 0.2779\n",
      "\n",
      "8 steps took 5.97 seconds\n",
      "Epoch: 4 batch_num: 256 val_rmse: 0.2805\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 4 batch_num: 264 val_rmse: 0.2922\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 4 batch_num: 272 val_rmse: 0.2948\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 6.22 seconds\n",
      "Epoch: 5 batch_num: 2 val_rmse: 0.2846\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 10 val_rmse: 0.3015\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 26 val_rmse: 0.2855\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 34 val_rmse: 0.3172\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 50 val_rmse: 0.2825\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 5 batch_num: 58 val_rmse: 0.3034\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 74 val_rmse: 0.2846\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 82 val_rmse: 0.3116\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 98 val_rmse: 0.2841\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 5 batch_num: 106 val_rmse: 0.2877\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 5 batch_num: 114 val_rmse: 0.2965\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 122 val_rmse: 0.3267\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 138 val_rmse: 0.2833\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 146 val_rmse: 0.3008\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 5 batch_num: 162 val_rmse: 0.288\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 170 val_rmse: 0.2971\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 178 val_rmse: 0.2936\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 186 val_rmse: 0.2897\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 194 val_rmse: 0.287\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 202 val_rmse: 0.2893\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 210 val_rmse: 0.2918\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 5 batch_num: 218 val_rmse: 0.2939\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 226 val_rmse: 0.3014\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 5 batch_num: 242 val_rmse: 0.2846\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 250 val_rmse: 0.2916\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 258 val_rmse: 0.2927\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 5 batch_num: 266 val_rmse: 0.2845\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 5 batch_num: 274 val_rmse: 0.285\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 6.31 seconds\n",
      "Epoch: 6 batch_num: 4 val_rmse: 0.2909\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 12 val_rmse: 0.2894\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 20 val_rmse: 0.2881\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 28 val_rmse: 0.2899\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 36 val_rmse: 0.2896\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 44 val_rmse: 0.2912\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 52 val_rmse: 0.2929\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 60 val_rmse: 0.2928\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 68 val_rmse: 0.2923\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 76 val_rmse: 0.29\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 84 val_rmse: 0.2871\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 92 val_rmse: 0.2892\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 100 val_rmse: 0.2929\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 108 val_rmse: 0.2931\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 116 val_rmse: 0.2947\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 124 val_rmse: 0.2952\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 132 val_rmse: 0.2916\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 140 val_rmse: 0.2889\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 6 batch_num: 148 val_rmse: 0.2871\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.93 seconds\n",
      "Epoch: 6 batch_num: 156 val_rmse: 0.2873\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 164 val_rmse: 0.2887\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 172 val_rmse: 0.2911\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 6 batch_num: 180 val_rmse: 0.2923\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 188 val_rmse: 0.2921\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 196 val_rmse: 0.2916\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 6 batch_num: 204 val_rmse: 0.291\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 212 val_rmse: 0.2911\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 220 val_rmse: 0.2914\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.94 seconds\n",
      "Epoch: 6 batch_num: 228 val_rmse: 0.2913\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.91 seconds\n",
      "Epoch: 6 batch_num: 236 val_rmse: 0.291\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 244 val_rmse: 0.291\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.97 seconds\n",
      "Epoch: 6 batch_num: 252 val_rmse: 0.2909\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.95 seconds\n",
      "Epoch: 6 batch_num: 260 val_rmse: 0.2909\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.92 seconds\n",
      "Epoch: 6 batch_num: 268 val_rmse: 0.2909\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "8 steps took 5.97 seconds\n",
      "Epoch: 6 batch_num: 276 val_rmse: 0.2909\n",
      "Still best_val_rmse: 0.2779 (from epoch 4)\n",
      "\n",
      "Performance estimates:\n",
      "[0.31026969003605726, 0.3180068755343076, 0.2876757769300274, 0.34133909013497055, 0.27793171539140704]\n",
      "Mean: 0.30704462960535395\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "SEED = 1000\n",
    "list_val_rmse = []\n",
    "\n",
    "kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
    "    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
    "    model_path = f\"model_{fold + 1}.pth\"\n",
    "        \n",
    "    set_random_seed(SEED + fold)\n",
    "    \n",
    "    train_dataset = LitDataset(train_df.loc[train_indices])    \n",
    "    val_dataset = LitDataset(train_df.loc[val_indices])    \n",
    "        \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                              drop_last=True, shuffle=True, num_workers=2)    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            drop_last=False, shuffle=False, num_workers=2)    \n",
    "        \n",
    "    set_random_seed(SEED + fold)    \n",
    "    \n",
    "    model = LitModel().to(DEVICE)\n",
    "    \n",
    "#     optimizer = create_optimizer(model)     \n",
    "    optimizer = AdamW(model.parameters(),lr=1e-5)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_training_steps=NUM_EPOCHS * len(train_loader),\n",
    "        num_warmup_steps=50)    \n",
    "    \n",
    "    list_val_rmse.append(train(model, model_path, train_loader,\n",
    "                               val_loader, optimizer, scheduler=scheduler))\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\nPerformance estimates:\")\n",
    "    print(list_val_rmse)\n",
    "    print(\"Mean:\", np.array(list_val_rmse).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33f61c4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:30:41.672735Z",
     "iopub.status.busy": "2021-11-13T20:30:41.672077Z",
     "iopub.status.idle": "2021-11-13T20:30:41.674722Z",
     "shell.execute_reply": "2021-11-13T20:30:41.675130Z"
    },
    "papermill": {
     "duration": 0.415507,
     "end_time": "2021-11-13T20:30:41.675257",
     "exception": false,
     "start_time": "2021-11-13T20:30:41.259750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86da",
   "metadata": {
    "papermill": {
     "duration": 0.433864,
     "end_time": "2021-11-13T20:30:42.528909",
     "exception": false,
     "start_time": "2021-11-13T20:30:42.095045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c3f9072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:30:43.397717Z",
     "iopub.status.busy": "2021-11-13T20:30:43.396543Z",
     "iopub.status.idle": "2021-11-13T20:30:43.399961Z",
     "shell.execute_reply": "2021-11-13T20:30:43.399556Z"
    },
    "papermill": {
     "duration": 0.446874,
     "end_time": "2021-11-13T20:30:43.400078",
     "exception": false,
     "start_time": "2021-11-13T20:30:42.953204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set= 20#512\n",
    "test_dataset = LitDataset(train_df[:test_set], inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "368fb31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:30:44.239436Z",
     "iopub.status.busy": "2021-11-13T20:30:44.238608Z",
     "iopub.status.idle": "2021-11-13T20:35:03.813285Z",
     "shell.execute_reply": "2021-11-13T20:35:03.812644Z"
    },
    "papermill": {
     "duration": 260.002531,
     "end_time": "2021-11-13T20:35:03.814504",
     "exception": false,
     "start_time": "2021-11-13T20:30:43.811973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_1.pth\n",
      "\n",
      "Using model_2.pth\n",
      "\n",
      "Using model_3.pth\n",
      "\n",
      "Using model_4.pth\n",
      "\n",
      "Using model_5.pth\n"
     ]
    }
   ],
   "source": [
    "all_predictions = np.zeros((len(list_val_rmse), len(train_df[:test_set])))\n",
    "\n",
    "test_dataset = LitDataset(train_df[:test_set], inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "for index in range(len(list_val_rmse)):            \n",
    "    model_path = f\"model_{index + 1}.pth\"\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_predictions[index] = predict(model, test_loader)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a42c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:35:04.655957Z",
     "iopub.status.busy": "2021-11-13T20:35:04.655298Z",
     "iopub.status.idle": "2021-11-13T20:35:04.659997Z",
     "shell.execute_reply": "2021-11-13T20:35:04.660392Z"
    },
    "papermill": {
     "duration": 0.428404,
     "end_time": "2021-11-13T20:35:04.660536",
     "exception": false,
     "start_time": "2021-11-13T20:35:04.232132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = all_predictions.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf131ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:35:05.500327Z",
     "iopub.status.busy": "2021-11-13T20:35:05.498736Z",
     "iopub.status.idle": "2021-11-13T20:35:05.500927Z",
     "shell.execute_reply": "2021-11-13T20:35:05.501332Z"
    },
    "papermill": {
     "duration": 0.426996,
     "end_time": "2021-11-13T20:35:05.501488",
     "exception": false,
     "start_time": "2021-11-13T20:35:05.074492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_train_df = train_df[:test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b9f60f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:35:06.348231Z",
     "iopub.status.busy": "2021-11-13T20:35:06.342000Z",
     "iopub.status.idle": "2021-11-13T20:35:06.351890Z",
     "shell.execute_reply": "2021-11-13T20:35:06.352311Z"
    },
    "papermill": {
     "duration": 0.437946,
     "end_time": "2021-11-13T20:35:06.352486",
     "exception": false,
     "start_time": "2021-11-13T20:35:05.914540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "new_train_df['predicted_jac_score']= predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47839bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:35:07.216462Z",
     "iopub.status.busy": "2021-11-13T20:35:07.215610Z",
     "iopub.status.idle": "2021-11-13T20:35:07.220473Z",
     "shell.execute_reply": "2021-11-13T20:35:07.220873Z"
    },
    "papermill": {
     "duration": 0.447249,
     "end_time": "2021-11-13T20:35:07.221013",
     "exception": false,
     "start_time": "2021-11-13T20:35:06.773764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>require_text</th>\n",
       "      <th>jac_score</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_jac_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.515666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.112406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>208</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.458796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.117264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>&lt;s&gt;மனித உடலில் எத்தனை எலும்புகள் உள்ளன?&lt;/s&gt;&lt;/s...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.115725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>&lt;s&gt;காளிதாசன் எங்கு பிறந்தார்?&lt;/s&gt;&lt;/s&gt;ைப்பில் ஒ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.517318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>இந்திய</td>\n",
       "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;s&gt;காளிதாசன் எங்கு பிறந்தார்?&lt;/s&gt;&lt;/s&gt;காளிதாசன்...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.298427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசுமீ</td>\n",
       "      <td>ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;s&gt;காளிதாசன் எங்கு பிறந்தார்?&lt;/s&gt;&lt;/s&gt;ைப்பில் ஒ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.205068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசுமீரில் பிறந்தார்</td>\n",
       "      <td>ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>&lt;s&gt;காளிதாசன் எங்கு பிறந்தார்?&lt;/s&gt;&lt;/s&gt;ைப்பில் ஒ...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.368548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசு</td>\n",
       "      <td>ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;s&gt;காளிதாசன் எங்கு பிறந்தார்?&lt;/s&gt;&lt;/s&gt;ைப்பில் ஒ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.226533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>&lt;s&gt;பென்சிலின் கண்டுபிடித்தவர் யார்?&lt;/s&gt;&lt;/s&gt;சர்...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.727901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>&lt;s&gt;பென்சிலின் கண்டுபிடித்தவர் யார்?&lt;/s&gt;&lt;/s&gt;சர்...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.624110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Fleming</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>&lt;s&gt;பென்சிலின் கண்டுபிடித்தவர் யார்?&lt;/s&gt;&lt;/s&gt;சர்...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.386068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>ஃபிளெமிங்</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>&lt;s&gt;பென்சிலின் கண்டுபிடித்தவர் யார்?&lt;/s&gt;&lt;/s&gt;சர்...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.526256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>சர் அலெக்ஸாண்டர்</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>&lt;s&gt;பென்சிலின் கண்டுபிடித்தவர் யார்?&lt;/s&gt;&lt;/s&gt;சர்...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.501262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>&lt;s&gt;தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு (Lullaby</td>\n",
       "      <td>குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>&lt;s&gt;தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.310574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு (Lullaby</td>\n",
       "      <td>குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>&lt;s&gt;தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.292155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு (Lullaby) ஆகும். தாலாட்டு</td>\n",
       "      <td>குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>&lt;s&gt;தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.207115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு (Lullaby) ஆகும்</td>\n",
       "      <td>குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>&lt;s&gt;தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.228850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   answer_text  \\\n",
       "0                          206   \n",
       "1                          206   \n",
       "2                          206   \n",
       "3                          206   \n",
       "4                          206   \n",
       "5                   காசுமீரில்   \n",
       "6                   காசுமீரில்   \n",
       "7                   காசுமீரில்   \n",
       "8                   காசுமீரில்   \n",
       "9                   காசுமீரில்   \n",
       "10  சர் அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "11  சர் அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "12  சர் அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "13  சர் அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "14  சர் அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "15                    தாலாட்டு   \n",
       "16                    தாலாட்டு   \n",
       "17                    தாலாட்டு   \n",
       "18                    தாலாட்டு   \n",
       "19                    தாலாட்டு   \n",
       "\n",
       "                                             question  \\\n",
       "0                மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1                மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "2                மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "3                மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "4                மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "5                          காளிதாசன் எங்கு பிறந்தார்?   \n",
       "6                          காளிதாசன் எங்கு பிறந்தார்?   \n",
       "7                          காளிதாசன் எங்கு பிறந்தார்?   \n",
       "8                          காளிதாசன் எங்கு பிறந்தார்?   \n",
       "9                          காளிதாசன் எங்கு பிறந்தார்?   \n",
       "10                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "11                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "12                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "13                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "14                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "15  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "16  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "17  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "18  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "19  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "\n",
       "                                            pred_text  \\\n",
       "0                                                 206   \n",
       "1    206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "2                                                 208   \n",
       "3    206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "4    206 (மார்பெலும்பு மூன்று பகுதிகளாகக் கருதப்பட...   \n",
       "5                                          காசுமீரில்   \n",
       "6                                              இந்திய   \n",
       "7                                              காசுமீ   \n",
       "8                                காசுமீரில் பிறந்தார்   \n",
       "9                                                காசு   \n",
       "10                         சர் அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "11                             அலெக்ஸாண்டர் ஃபிளெமிங்   \n",
       "12  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Fleming   \n",
       "13                                          ஃபிளெமிங்   \n",
       "14                                   சர் அலெக்ஸாண்டர்   \n",
       "15                                           தாலாட்டு   \n",
       "16                                  தாலாட்டு (Lullaby   \n",
       "17                                  தாலாட்டு (Lullaby   \n",
       "18                 தாலாட்டு (Lullaby) ஆகும். தாலாட்டு   \n",
       "19                           தாலாட்டு (Lullaby) ஆகும்   \n",
       "\n",
       "                                         require_text  jac_score  \\\n",
       "0   ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   1.000000   \n",
       "1   ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667   \n",
       "2   ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.000000   \n",
       "3   ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.166667   \n",
       "4   ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   0.142857   \n",
       "5   ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...   1.000000   \n",
       "6   காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...   0.000000   \n",
       "7   ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...   0.000000   \n",
       "8   ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...   0.500000   \n",
       "9   ைப்பில் ஒரு புத்தகத்தை எழுதினார், அது காளிதாசன...   0.000000   \n",
       "10  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   1.000000   \n",
       "11  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   0.666667   \n",
       "12  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   0.500000   \n",
       "13  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   0.333333   \n",
       "14  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   0.666667   \n",
       "15  குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...   1.000000   \n",
       "16  குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...   0.500000   \n",
       "17  குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...   0.500000   \n",
       "18  குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...   0.333333   \n",
       "19  குழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...   0.333333   \n",
       "\n",
       "                                              excerpt  target  \\\n",
       "0   <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    1.00   \n",
       "1   <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.17   \n",
       "2   <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.00   \n",
       "3   <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.17   \n",
       "4   <s>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</s></s...    0.14   \n",
       "5   <s>காளிதாசன் எங்கு பிறந்தார்?</s></s>ைப்பில் ஒ...    1.00   \n",
       "6   <s>காளிதாசன் எங்கு பிறந்தார்?</s></s>காளிதாசன்...    0.00   \n",
       "7   <s>காளிதாசன் எங்கு பிறந்தார்?</s></s>ைப்பில் ஒ...    0.00   \n",
       "8   <s>காளிதாசன் எங்கு பிறந்தார்?</s></s>ைப்பில் ஒ...    0.50   \n",
       "9   <s>காளிதாசன் எங்கு பிறந்தார்?</s></s>ைப்பில் ஒ...    0.00   \n",
       "10  <s>பென்சிலின் கண்டுபிடித்தவர் யார்?</s></s>சர்...    1.00   \n",
       "11  <s>பென்சிலின் கண்டுபிடித்தவர் யார்?</s></s>சர்...    0.67   \n",
       "12  <s>பென்சிலின் கண்டுபிடித்தவர் யார்?</s></s>சர்...    0.50   \n",
       "13  <s>பென்சிலின் கண்டுபிடித்தவர் யார்?</s></s>சர்...    0.33   \n",
       "14  <s>பென்சிலின் கண்டுபிடித்தவர் யார்?</s></s>சர்...    0.67   \n",
       "15  <s>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...    1.00   \n",
       "16  <s>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...    0.50   \n",
       "17  <s>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...    0.50   \n",
       "18  <s>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...    0.33   \n",
       "19  <s>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும்...    0.33   \n",
       "\n",
       "    predicted_jac_score  \n",
       "0              0.515666  \n",
       "1              0.112406  \n",
       "2              0.458796  \n",
       "3              0.117264  \n",
       "4              0.115725  \n",
       "5              0.517318  \n",
       "6              0.298427  \n",
       "7              0.205068  \n",
       "8              0.368548  \n",
       "9              0.226533  \n",
       "10             0.727901  \n",
       "11             0.624110  \n",
       "12             0.386068  \n",
       "13             0.526256  \n",
       "14             0.501262  \n",
       "15             0.607800  \n",
       "16             0.310574  \n",
       "17             0.292155  \n",
       "18             0.207115  \n",
       "19             0.228850  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b46b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T20:35:08.054621Z",
     "iopub.status.busy": "2021-11-13T20:35:08.053900Z",
     "iopub.status.idle": "2021-11-13T20:35:08.073513Z",
     "shell.execute_reply": "2021-11-13T20:35:08.073072Z"
    },
    "papermill": {
     "duration": 0.437371,
     "end_time": "2021-11-13T20:35:08.073629",
     "exception": false,
     "start_time": "2021-11-13T20:35:07.636258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_train_df.to_csv('reranking_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e8e1c",
   "metadata": {
    "papermill": {
     "duration": 0.417002,
     "end_time": "2021-11-13T20:35:08.910590",
     "exception": false,
     "start_time": "2021-11-13T20:35:08.493588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff7911",
   "metadata": {
    "papermill": {
     "duration": 0.483992,
     "end_time": "2021-11-13T20:35:09.828139",
     "exception": false,
     "start_time": "2021-11-13T20:35:09.344147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd8e1a",
   "metadata": {
    "papermill": {
     "duration": 0.414619,
     "end_time": "2021-11-13T20:35:10.658494",
     "exception": false,
     "start_time": "2021-11-13T20:35:10.243875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e4ac5",
   "metadata": {
    "papermill": {
     "duration": 0.413534,
     "end_time": "2021-11-13T20:35:11.492592",
     "exception": false,
     "start_time": "2021-11-13T20:35:11.079058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f9a45",
   "metadata": {
    "papermill": {
     "duration": 0.4308,
     "end_time": "2021-11-13T20:35:12.340180",
     "exception": false,
     "start_time": "2021-11-13T20:35:11.909380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f155f9",
   "metadata": {
    "papermill": {
     "duration": 0.458214,
     "end_time": "2021-11-13T20:35:13.212725",
     "exception": false,
     "start_time": "2021-11-13T20:35:12.754511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443177e",
   "metadata": {
    "papermill": {
     "duration": 0.827219,
     "end_time": "2021-11-13T20:35:14.507786",
     "exception": false,
     "start_time": "2021-11-13T20:35:13.680567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39baa53",
   "metadata": {
    "papermill": {
     "duration": 0.417043,
     "end_time": "2021-11-13T20:35:15.647510",
     "exception": false,
     "start_time": "2021-11-13T20:35:15.230467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c464c2",
   "metadata": {
    "papermill": {
     "duration": 0.416303,
     "end_time": "2021-11-13T20:35:16.478327",
     "exception": false,
     "start_time": "2021-11-13T20:35:16.062024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad413d1",
   "metadata": {
    "papermill": {
     "duration": 0.41428,
     "end_time": "2021-11-13T20:35:17.307903",
     "exception": false,
     "start_time": "2021-11-13T20:35:16.893623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad382e2",
   "metadata": {
    "papermill": {
     "duration": 0.414122,
     "end_time": "2021-11-13T20:35:18.136594",
     "exception": false,
     "start_time": "2021-11-13T20:35:17.722472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb8449",
   "metadata": {
    "papermill": {
     "duration": 0.43205,
     "end_time": "2021-11-13T20:35:18.993335",
     "exception": false,
     "start_time": "2021-11-13T20:35:18.561285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ff062",
   "metadata": {
    "papermill": {
     "duration": 0.41852,
     "end_time": "2021-11-13T20:35:19.830533",
     "exception": false,
     "start_time": "2021-11-13T20:35:19.412013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20468.703177,
   "end_time": "2021-11-13T20:35:23.617773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-13T14:54:14.914596",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
