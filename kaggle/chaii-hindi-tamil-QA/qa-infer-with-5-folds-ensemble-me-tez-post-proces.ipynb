{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7c4308",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:16.601396Z",
     "iopub.status.busy": "2021-09-21T02:32:16.600323Z",
     "iopub.status.idle": "2021-09-21T02:32:16.601955Z",
     "shell.execute_reply": "2021-09-21T02:32:16.602352Z",
     "shell.execute_reply.started": "2021-09-20T04:20:08.118394Z"
    },
    "papermill": {
     "duration": 0.03945,
     "end_time": "2021-09-21T02:32:16.602550",
     "exception": false,
     "start_time": "2021-09-21T02:32:16.563100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854e0c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:16.743047Z",
     "iopub.status.busy": "2021-09-21T02:32:16.742388Z",
     "iopub.status.idle": "2021-09-21T02:32:26.453287Z",
     "shell.execute_reply": "2021-09-21T02:32:26.452380Z",
     "shell.execute_reply.started": "2021-09-20T04:20:08.127637Z"
    },
    "papermill": {
     "duration": 9.8212,
     "end_time": "2021-09-21T02:32:26.453437",
     "exception": false,
     "start_time": "2021-09-21T02:32:16.632237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-cloud 0.1.13 requires tensorflow<3.0,>=1.15.0, which is not installed.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda112, which is not installed.\r\n",
      "cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda110, which is not installed.\r\n",
      "s3fs 2021.6.1 requires fsspec==2021.06.1, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "pytorch-lightning 1.3.8 requires fsspec[http]!=2021.06.0,>=2021.05.0, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires dask<=2021.5.1,>=2021.4.0, but you have dask 2021.6.2 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires distributed<=2021.5.1,>=2.22.0, but you have distributed 2021.6.2 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# ! pip install datasets transformers\n",
    "!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af2919a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:26.521205Z",
     "iopub.status.busy": "2021-09-21T02:32:26.520432Z",
     "iopub.status.idle": "2021-09-21T02:32:26.950676Z",
     "shell.execute_reply": "2021-09-21T02:32:26.950123Z",
     "shell.execute_reply.started": "2021-09-20T04:20:17.693882Z"
    },
    "papermill": {
     "duration": 0.465588,
     "end_time": "2021-09-21T02:32:26.950814",
     "exception": false,
     "start_time": "2021-09-21T02:32:26.485226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e5b5f",
   "metadata": {
    "papermill": {
     "duration": 0.02981,
     "end_time": "2021-09-21T02:32:27.010868",
     "exception": false,
     "start_time": "2021-09-21T02:32:26.981058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc29019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:27.075500Z",
     "iopub.status.busy": "2021-09-21T02:32:27.074827Z",
     "iopub.status.idle": "2021-09-21T02:32:34.101507Z",
     "shell.execute_reply": "2021-09-21T02:32:34.100981Z",
     "shell.execute_reply.started": "2021-09-20T04:20:18.398238Z"
    },
    "papermill": {
     "duration": 7.060674,
     "end_time": "2021-09-21T02:32:34.101642",
     "exception": false,
     "start_time": "2021-09-21T02:32:27.040968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_checkpoint = \"distilbert-base-uncased\"\n",
    "# model_checkpoint = \"deepset/xlm-roberta-large-squad2\"\n",
    "# model_checkpoint = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-base-squad2\"\n",
    "model_checkpoint = \"../input/pipeline-for-qa-train-with-5-folds/chaii-trained-model-0\"\n",
    "\n",
    "from transformers import XLMTokenizer,AutoTokenizer\n",
    "# tokenizer = XLMTokenizer.from_pretrained('xlm-mlm-en-2048')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6660a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.166569Z",
     "iopub.status.busy": "2021-09-21T02:32:34.166030Z",
     "iopub.status.idle": "2021-09-21T02:32:34.169610Z",
     "shell.execute_reply": "2021-09-21T02:32:34.170000Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.478989Z"
    },
    "papermill": {
     "duration": 0.037882,
     "end_time": "2021-09-21T02:32:34.170134",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.132252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8e486",
   "metadata": {
    "papermill": {
     "duration": 0.029722,
     "end_time": "2021-09-21T02:32:34.230098",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.200376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Doc_stride is used to handle large text: tokens>512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25014d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.294872Z",
     "iopub.status.busy": "2021-09-21T02:32:34.293605Z",
     "iopub.status.idle": "2021-09-21T02:32:34.296388Z",
     "shell.execute_reply": "2021-09-21T02:32:34.295981Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.484617Z"
    },
    "papermill": {
     "duration": 0.03622,
     "end_time": "2021-09-21T02:32:34.296495",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.260275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 384 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736460c",
   "metadata": {
    "papermill": {
     "duration": 0.029339,
     "end_time": "2021-09-21T02:32:34.355839",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.326500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd1aec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.420993Z",
     "iopub.status.busy": "2021-09-21T02:32:34.420428Z",
     "iopub.status.idle": "2021-09-21T02:32:34.460396Z",
     "shell.execute_reply": "2021-09-21T02:32:34.459762Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.495135Z"
    },
    "papermill": {
     "duration": 0.074013,
     "end_time": "2021-09-21T02:32:34.460516",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.386503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
    "test_dataset = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da414b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.525157Z",
     "iopub.status.busy": "2021-09-21T02:32:34.523607Z",
     "iopub.status.idle": "2021-09-21T02:32:34.526017Z",
     "shell.execute_reply": "2021-09-21T02:32:34.526478Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.540492Z"
    },
    "papermill": {
     "duration": 0.036456,
     "end_time": "2021-09-21T02:32:34.526629",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.490173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a329f4",
   "metadata": {
    "papermill": {
     "duration": 0.031434,
     "end_time": "2021-09-21T02:32:34.590723",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.559289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac56c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.660156Z",
     "iopub.status.busy": "2021-09-21T02:32:34.659426Z",
     "iopub.status.idle": "2021-09-21T02:32:34.662626Z",
     "shell.execute_reply": "2021-09-21T02:32:34.663025Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.546553Z"
    },
    "papermill": {
     "duration": 0.041339,
     "end_time": "2021-09-21T02:32:34.663153",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.621814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In some padding required on left side\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "def prepare_validation_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84153e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.726574Z",
     "iopub.status.busy": "2021-09-21T02:32:34.726049Z",
     "iopub.status.idle": "2021-09-21T02:32:34.729851Z",
     "shell.execute_reply": "2021-09-21T02:32:34.729429Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.558353Z"
    },
    "papermill": {
     "duration": 0.037262,
     "end_time": "2021-09-21T02:32:34.729961",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.692699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features = prepare_validation_features(test_dataset[:5])\n",
    "# print(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced10cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:34.823706Z",
     "iopub.status.busy": "2021-09-21T02:32:34.822930Z",
     "iopub.status.idle": "2021-09-21T02:32:35.217531Z",
     "shell.execute_reply": "2021-09-21T02:32:35.217118Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.5719Z"
    },
    "papermill": {
     "duration": 0.457242,
     "end_time": "2021-09-21T02:32:35.217651",
     "exception": false,
     "start_time": "2021-09-21T02:32:34.760409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8b625f6ab0404ab4f1df31a03dcbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " validation_features = test_dataset.map(\n",
    "        prepare_validation_features,\n",
    "        batched=True,\n",
    "        remove_columns=test_dataset.column_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b685944f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:35.284513Z",
     "iopub.status.busy": "2021-09-21T02:32:35.283913Z",
     "iopub.status.idle": "2021-09-21T02:32:35.287862Z",
     "shell.execute_reply": "2021-09-21T02:32:35.287444Z",
     "shell.execute_reply.started": "2021-09-20T04:20:25.997447Z"
    },
    "papermill": {
     "duration": 0.039562,
     "end_time": "2021-09-21T02:32:35.287971",
     "exception": false,
     "start_time": "2021-09-21T02:32:35.248409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import collections\n",
    "\n",
    "\n",
    "# def postprocess_qa_predictions(examples, features, start_logits_cons, end_logits_cons, n_best_size = 20, \n",
    "#                                max_answer_length = 30):\n",
    "#     all_start_logits = start_logits_cons\n",
    "#     all_end_logits = end_logits_cons\n",
    "# #     all_start_logits, all_end_logits = raw_predictions\n",
    "#     # Build a map example to its corresponding features.\n",
    "#     example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "#     features_per_example = collections.defaultdict(list)\n",
    "#     for i, feature in enumerate(features):\n",
    "#         features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "#     # The dictionaries we have to fill.\n",
    "#     predictions = collections.OrderedDict()\n",
    "\n",
    "#     # Logging.\n",
    "#     print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "#     # Let's loop over all the examples!\n",
    "#     for example_index, example in enumerate(tqdm(examples)):\n",
    "#         # Those are the indices of the features associated to the current example.\n",
    "#         feature_indices = features_per_example[example_index]\n",
    "\n",
    "#         min_null_score = None # Only used if squad_v2 is True.\n",
    "#         valid_answers = []\n",
    "        \n",
    "#         context = example[\"context\"]\n",
    "#         # Looping through all the features associated to the current example.\n",
    "#         for feature_index in feature_indices:\n",
    "#             # We grab the predictions of the model for this feature.\n",
    "#             start_logits = all_start_logits[feature_index]\n",
    "#             end_logits = all_end_logits[feature_index]\n",
    "#             # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "#             # context.\n",
    "#             offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "#             # Update minimum null prediction.\n",
    "#             cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "#             feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "#             if min_null_score is None or min_null_score < feature_null_score:\n",
    "#                 min_null_score = feature_null_score\n",
    "\n",
    "#             # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "#             start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "#             end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "#             for start_index in start_indexes:\n",
    "#                 for end_index in end_indexes:\n",
    "#                     # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "#                     # to part of the input_ids that are not in the context.\n",
    "#                     if (\n",
    "#                         start_index >= len(offset_mapping)\n",
    "#                         or end_index >= len(offset_mapping)\n",
    "#                         or offset_mapping[start_index] is None\n",
    "#                         or offset_mapping[end_index] is None\n",
    "#                     ):\n",
    "#                         continue\n",
    "#                     # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "#                     if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "#                         continue\n",
    "\n",
    "#                     start_char = offset_mapping[start_index][0]\n",
    "#                     end_char = offset_mapping[end_index][1]\n",
    "#                     valid_answers.append(\n",
    "#                         {\n",
    "#                             \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "#                             \"text\": context[start_char: end_char]\n",
    "#                         }\n",
    "#                     )\n",
    "        \n",
    "#         if len(valid_answers) > 0:\n",
    "#             best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "#         else:\n",
    "#             # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "#             # failure.\n",
    "#             best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "#         # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "# #         if not squad_v2:\n",
    "#         predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "# #         else:\n",
    "# #             answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "# #             predictions[example[\"id\"]] = answer\n",
    "\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73cc38f",
   "metadata": {
    "papermill": {
     "duration": 0.031114,
     "end_time": "2021-09-21T02:32:35.349575",
     "exception": false,
     "start_time": "2021-09-21T02:32:35.318461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a39445d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:35.415543Z",
     "iopub.status.busy": "2021-09-21T02:32:35.415023Z",
     "iopub.status.idle": "2021-09-21T02:32:36.355528Z",
     "shell.execute_reply": "2021-09-21T02:32:36.354533Z",
     "shell.execute_reply.started": "2021-09-20T04:20:26.00528Z"
    },
    "papermill": {
     "duration": 0.974556,
     "end_time": "2021-09-21T02:32:36.355748",
     "exception": false,
     "start_time": "2021-09-21T02:32:35.381192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "gc.collect()\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa20f2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:32:36.469514Z",
     "iopub.status.busy": "2021-09-21T02:32:36.468715Z",
     "iopub.status.idle": "2021-09-21T02:35:34.825288Z",
     "shell.execute_reply": "2021-09-21T02:35:34.825866Z",
     "shell.execute_reply.started": "2021-09-20T04:20:26.844876Z"
    },
    "papermill": {
     "duration": 178.415276,
     "end_time": "2021-09-21T02:35:34.826078",
     "exception": false,
     "start_time": "2021-09-21T02:32:36.410802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting using model 0 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 0 complete\n",
      "-----------------------------------\n",
      "predicting using model 1 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 1 complete\n",
      "-----------------------------------\n",
      "predicting using model 2 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 2 complete\n",
      "-----------------------------------\n",
      "predicting using model 3 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 3 complete\n",
      "-----------------------------------\n",
      "predicting using model 4 start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of model 4 complete\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = []\n",
    "for i in range(folds):\n",
    "    print(f'predicting using model {i} start')\n",
    "    model_checkpoint = f\"../input/pipeline-for-qa-train-with-5-folds/chaii-trained-model-{i}\"\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "    trainer = Trainer(model)\n",
    "    raw_predictions.append(trainer.predict(validation_features))\n",
    "    print(f'prediction of model {i} complete')\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb7d2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:34.900391Z",
     "iopub.status.busy": "2021-09-21T02:35:34.899874Z",
     "iopub.status.idle": "2021-09-21T02:35:34.903749Z",
     "shell.execute_reply": "2021-09-21T02:35:34.903329Z",
     "shell.execute_reply.started": "2021-09-20T04:22:55.233885Z"
    },
    "papermill": {
     "duration": 0.041415,
     "end_time": "2021-09-21T02:35:34.903871",
     "exception": false,
     "start_time": "2021-09-21T02:35:34.862456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa799e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:34.978289Z",
     "iopub.status.busy": "2021-09-21T02:35:34.977017Z",
     "iopub.status.idle": "2021-09-21T02:35:34.979396Z",
     "shell.execute_reply": "2021-09-21T02:35:34.979758Z",
     "shell.execute_reply.started": "2021-09-20T04:22:55.240588Z"
    },
    "papermill": {
     "duration": 0.041633,
     "end_time": "2021-09-21T02:35:34.979909",
     "exception": false,
     "start_time": "2021-09-21T02:35:34.938276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41f0d8",
   "metadata": {
    "papermill": {
     "duration": 0.034844,
     "end_time": "2021-09-21T02:35:35.049536",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.014692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2381175c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.125279Z",
     "iopub.status.busy": "2021-09-21T02:35:35.124636Z",
     "iopub.status.idle": "2021-09-21T02:35:35.128798Z",
     "shell.execute_reply": "2021-09-21T02:35:35.129335Z",
     "shell.execute_reply.started": "2021-09-20T04:22:55.249941Z"
    },
    "papermill": {
     "duration": 0.045306,
     "end_time": "2021-09-21T02:35:35.129507",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.084201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "start_logits_cons = 0\n",
    "end_logits_cons = 0\n",
    "for raw_prediction in raw_predictions:\n",
    "    sc, ec = raw_prediction.predictions\n",
    "    sc = sc/folds\n",
    "    ec = ec/folds\n",
    "    start_logits_cons += sc\n",
    "    end_logits_cons += ec\n",
    "print(len(start_logits_cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31f0f926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.205772Z",
     "iopub.status.busy": "2021-09-21T02:35:35.204401Z",
     "iopub.status.idle": "2021-09-21T02:35:35.206719Z",
     "shell.execute_reply": "2021-09-21T02:35:35.207221Z",
     "shell.execute_reply.started": "2021-09-20T04:22:55.26291Z"
    },
    "papermill": {
     "duration": 0.042433,
     "end_time": "2021-09-21T02:35:35.207345",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.164912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_logits_cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f01ccd",
   "metadata": {
    "papermill": {
     "duration": 0.03515,
     "end_time": "2021-09-21T02:35:35.277316",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.242166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e84fc8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.354525Z",
     "iopub.status.busy": "2021-09-21T02:35:35.353995Z",
     "iopub.status.idle": "2021-09-21T02:35:35.419869Z",
     "shell.execute_reply": "2021-09-21T02:35:35.419031Z",
     "shell.execute_reply.started": "2021-09-20T04:22:55.270814Z"
    },
    "papermill": {
     "duration": 0.106906,
     "end_time": "2021-09-21T02:35:35.419994",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.313088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "import collections\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tez\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89f6cf99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.502044Z",
     "iopub.status.busy": "2021-09-21T02:35:35.500784Z",
     "iopub.status.idle": "2021-09-21T02:35:35.503488Z",
     "shell.execute_reply": "2021-09-21T02:35:35.503058Z",
     "shell.execute_reply.started": "2021-09-20T04:24:08.900105Z"
    },
    "papermill": {
     "duration": 0.047157,
     "end_time": "2021-09-21T02:35:35.503594",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.456437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiModel(tez.Model):\n",
    "    def __init__(self, model_name, num_train_steps, steps_per_epoch, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.model_name = model_name\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "\n",
    "        hidden_dropout_prob: float = 0.0\n",
    "        layer_norm_eps: float = 1e-7\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(model_name)\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name, config=config)\n",
    "        self.output = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids=None, start_positions=None, end_positions=None):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out[0]\n",
    "        logits = self.output(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        return (start_logits, end_logits), 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7149ae55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.580565Z",
     "iopub.status.busy": "2021-09-21T02:35:35.579128Z",
     "iopub.status.idle": "2021-09-21T02:35:35.581373Z",
     "shell.execute_reply": "2021-09-21T02:35:35.581819Z",
     "shell.execute_reply.started": "2021-09-20T04:24:11.454547Z"
    },
    "papermill": {
     "duration": 0.043013,
     "end_time": "2021-09-21T02:35:35.581944",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.538931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"ids\": torch.tensor(self.data[item][\"input_ids\"], dtype=torch.long),\n",
    "            \"mask\": torch.tensor(self.data[item][\"attention_mask\"], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1c7e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.657879Z",
     "iopub.status.busy": "2021-09-21T02:35:35.657306Z",
     "iopub.status.idle": "2021-09-21T02:35:35.661154Z",
     "shell.execute_reply": "2021-09-21T02:35:35.660728Z",
     "shell.execute_reply.started": "2021-09-20T04:24:11.801096Z"
    },
    "papermill": {
     "duration": 0.045,
     "end_time": "2021-09-21T02:35:35.661262",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.616262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5537b223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:35.733379Z",
     "iopub.status.busy": "2021-09-21T02:35:35.732754Z",
     "iopub.status.idle": "2021-09-21T02:35:37.660173Z",
     "shell.execute_reply": "2021-09-21T02:35:37.659638Z",
     "shell.execute_reply.started": "2021-09-20T04:25:45.838168Z"
    },
    "papermill": {
     "duration": 1.964845,
     "end_time": "2021-09-21T02:35:37.660309",
     "exception": false,
     "start_time": "2021-09-21T02:35:35.695464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"../input/xlmrob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3ff4814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:35:37.744894Z",
     "iopub.status.busy": "2021-09-21T02:35:37.744331Z",
     "iopub.status.idle": "2021-09-21T02:41:17.243049Z",
     "shell.execute_reply": "2021-09-21T02:41:17.241662Z",
     "shell.execute_reply.started": "2021-09-20T04:25:48.360718Z"
    },
    "papermill": {
     "duration": 339.546237,
     "end_time": "2021-09-21T02:41:17.243219",
     "exception": false,
     "start_time": "2021-09-21T02:35:37.696982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b62948f6b44141b5073a5c54574bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61f4a9324214daf86f719806542a38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 10%|█         | 1/10 [00:49<07:23, 49.28s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 20%|██        | 2/10 [01:20<05:11, 38.89s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 30%|███       | 3/10 [01:52<04:09, 35.60s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 40%|████      | 4/10 [02:24<03:23, 34.00s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 50%|█████     | 5/10 [02:56<02:46, 33.38s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 60%|██████    | 6/10 [03:28<02:11, 32.86s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 70%|███████   | 7/10 [04:00<01:37, 32.59s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 80%|████████  | 8/10 [04:33<01:05, 32.81s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 90%|█████████ | 9/10 [05:06<00:32, 32.69s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 10/10 [05:38<00:00, 33.87s/it]\n"
     ]
    }
   ],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "\n",
    "test_data = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "test_features = test_dataset.map(\n",
    "    partial(\n",
    "        prepare_validation_features, \n",
    "        tokenizer=tokenizer,\n",
    "        pad_on_right=pad_on_right, \n",
    "        max_length=max_length,\n",
    "        doc_stride=doc_stride\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")\n",
    "test_feats_small = test_features.map(\n",
    "    lambda example: example, remove_columns=['example_id', 'offset_mapping']\n",
    ")\n",
    "\n",
    "fin_start_logits = None\n",
    "fin_end_logits = None\n",
    "\n",
    "for fold_ in tqdm(range(10)):\n",
    "    model = ChaiiModel(model_name=\"../input/xlmrob\", num_train_steps=0, steps_per_epoch=0, learning_rate=0)\n",
    "    model.load(f\"../input/deepsetsquad2-v2/pytorch_model_f{fold_}.bin\", weights_only=True)\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        ChaiiDataset(test_feats_small), \n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "\n",
    "    for b_idx, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(\"cuda\")\n",
    "            output, _, _ = model(**data)\n",
    "            start = output[0].detach().cpu().numpy()\n",
    "            end = output[1].detach().cpu().numpy()\n",
    "            start_logits.append(start)\n",
    "            end_logits.append(end)\n",
    "\n",
    "    start_logits = np.vstack(start_logits)\n",
    "    end_logits = np.vstack(end_logits)\n",
    "    \n",
    "    if fin_start_logits is None:\n",
    "        fin_start_logits = start_logits\n",
    "        fin_end_logits = end_logits\n",
    "    else:\n",
    "        fin_start_logits += start_logits\n",
    "        fin_end_logits += end_logits\n",
    "        \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c0985dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:17.337667Z",
     "iopub.status.busy": "2021-09-21T02:41:17.336376Z",
     "iopub.status.idle": "2021-09-21T02:41:17.339178Z",
     "shell.execute_reply": "2021-09-21T02:41:17.338752Z",
     "shell.execute_reply.started": "2021-09-20T04:31:49.447252Z"
    },
    "papermill": {
     "duration": 0.051019,
     "end_time": "2021-09-21T02:41:17.339288",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.288269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_logits = fin_start_logits/10\n",
    "end_logits = fin_end_logits/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc98d2e",
   "metadata": {
    "papermill": {
     "duration": 0.043766,
     "end_time": "2021-09-21T02:41:17.426843",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.383077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensembled logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baedb795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:17.520228Z",
     "iopub.status.busy": "2021-09-21T02:41:17.519543Z",
     "iopub.status.idle": "2021-09-21T02:41:17.528945Z",
     "shell.execute_reply": "2021-09-21T02:41:17.528464Z",
     "shell.execute_reply.started": "2021-09-20T04:31:51.839664Z"
    },
    "papermill": {
     "duration": 0.058819,
     "end_time": "2021-09-21T02:41:17.529055",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.470236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "normalizer = torch.nn.Softmax(dim=1)\n",
    "\n",
    "start_logits = normalizer(torch.from_numpy(start_logits))\n",
    "end_logits = normalizer(torch.from_numpy(end_logits))\n",
    "\n",
    "start_logits = start_logits.numpy()\n",
    "end_logits = end_logits.numpy()\n",
    "\n",
    "\n",
    "start_logits_cons = normalizer(torch.from_numpy(start_logits_cons))\n",
    "end_logits_cons = normalizer(torch.from_numpy(end_logits_cons))\n",
    "\n",
    "start_logits_cons = start_logits_cons.numpy()\n",
    "end_logits_cons = end_logits_cons.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad09bf64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:17.621324Z",
     "iopub.status.busy": "2021-09-21T02:41:17.620744Z",
     "iopub.status.idle": "2021-09-21T02:41:17.626429Z",
     "shell.execute_reply": "2021-09-21T02:41:17.627047Z",
     "shell.execute_reply.started": "2021-09-20T04:37:09.806299Z"
    },
    "papermill": {
     "duration": 0.054755,
     "end_time": "2021-09-21T02:41:17.627200",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.572445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 384)\n",
      "(67, 384)\n"
     ]
    }
   ],
   "source": [
    "print(start_logits.shape)\n",
    "print(start_logits_cons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c88c76b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:17.727325Z",
     "iopub.status.busy": "2021-09-21T02:41:17.726573Z",
     "iopub.status.idle": "2021-09-21T02:41:17.729693Z",
     "shell.execute_reply": "2021-09-21T02:41:17.729274Z",
     "shell.execute_reply.started": "2021-09-20T04:32:12.40752Z"
    },
    "papermill": {
     "duration": 0.058745,
     "end_time": "2021-09-21T02:41:17.729821",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.671076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = 0.15#0.05#0.1#0.2#0.3#0.4#0.5\n",
    "model2 = 0.85#0.95#0.9#0.8#0.7#0.6#0.5\n",
    "\n",
    "final_start_logits = model1*start_logits_cons + model2*start_logits\n",
    "final_end_logits = model1*end_logits_cons + model2*end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b07a1",
   "metadata": {
    "papermill": {
     "duration": 0.042595,
     "end_time": "2021-09-21T02:41:17.815490",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.772895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17537232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:17.991650Z",
     "iopub.status.busy": "2021-09-21T02:41:17.989940Z",
     "iopub.status.idle": "2021-09-21T02:41:17.992312Z",
     "shell.execute_reply": "2021-09-21T02:41:17.992706Z",
     "shell.execute_reply.started": "2021-09-20T04:34:49.415903Z"
    },
    "papermill": {
     "duration": 0.134857,
     "end_time": "2021-09-21T02:41:17.992873",
     "exception": false,
     "start_time": "2021-09-21T02:41:17.858016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess_qa_predictions(\n",
    "    examples, tokenizer, features, raw_predictions, n_best_size=20, max_answer_length=30, squad_v2=False\n",
    "):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None  # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char:end_char],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a96c88e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:18.082453Z",
     "iopub.status.busy": "2021-09-21T02:41:18.081659Z",
     "iopub.status.idle": "2021-09-21T02:41:18.557632Z",
     "shell.execute_reply": "2021-09-21T02:41:18.558234Z",
     "shell.execute_reply.started": "2021-09-20T04:41:15.957645Z"
    },
    "papermill": {
     "duration": 0.52315,
     "end_time": "2021-09-21T02:41:18.558440",
     "exception": false,
     "start_time": "2021-09-21T02:41:18.035290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 67 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# final_predictions = postprocess_qa_predictions(test_dataset, tokenizer, validation_features, (start_logits, end_logits))\n",
    "# final_predictions = postprocess_qa_predictions(test_dataset, tokenizer, validation_features, (start_logits_cons, end_logits_cons))\n",
    "final_predictions = postprocess_qa_predictions(test_dataset,  tokenizer, test_features, (final_start_logits, final_end_logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "722c8d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:18.707841Z",
     "iopub.status.busy": "2021-09-21T02:41:18.706947Z",
     "iopub.status.idle": "2021-09-21T02:41:18.709193Z",
     "shell.execute_reply": "2021-09-21T02:41:18.708522Z",
     "shell.execute_reply.started": "2021-09-20T04:46:16.684095Z"
    },
    "papermill": {
     "duration": 0.081221,
     "end_time": "2021-09-21T02:41:18.709353",
     "exception": false,
     "start_time": "2021-09-21T02:41:18.628132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "for p1, p2 in final_predictions.items():\n",
    "    p2 = \" \".join(p2.split())\n",
    "    p2 = p2.strip(punctuation)\n",
    "#     submission.append((p1, p2))\n",
    "    submission.append(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "771ce365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:18.874569Z",
     "iopub.status.busy": "2021-09-21T02:41:18.873707Z",
     "iopub.status.idle": "2021-09-21T02:41:18.907760Z",
     "shell.execute_reply": "2021-09-21T02:41:18.908716Z",
     "shell.execute_reply.started": "2021-09-20T04:46:18.400587Z"
    },
    "papermill": {
     "duration": 0.126433,
     "end_time": "2021-09-21T02:41:18.908941",
     "exception": false,
     "start_time": "2021-09-21T02:41:18.782508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>28 नवम्बर 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       28 नवम्बर 2007  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_data\n",
    "test[\"PredictionString\"] = submission\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa6893",
   "metadata": {
    "papermill": {
     "duration": 0.078361,
     "end_time": "2021-09-21T02:41:19.068676",
     "exception": false,
     "start_time": "2021-09-21T02:41:18.990315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5677b22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:19.292524Z",
     "iopub.status.busy": "2021-09-21T02:41:19.291060Z",
     "iopub.status.idle": "2021-09-21T02:41:19.315631Z",
     "shell.execute_reply": "2021-09-21T02:41:19.314806Z",
     "shell.execute_reply.started": "2021-09-20T04:46:23.893085Z"
    },
    "papermill": {
     "duration": 0.144909,
     "end_time": "2021-09-21T02:41:19.315944",
     "exception": false,
     "start_time": "2021-09-21T02:41:19.171035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
    "bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
    "\n",
    "tamil_ad = \"கி.பி\"\n",
    "tamil_bc = \"கி.மு\"\n",
    "tamil_km = \"கி.மீ\"\n",
    "hindi_ad = \"ई\"\n",
    "hindi_bc = \"ई.पू\"\n",
    "\n",
    "\n",
    "cleaned_preds = []\n",
    "for pred, context in test[[\"PredictionString\", \"context\"]].to_numpy():\n",
    "    if pred == \"\":\n",
    "        cleaned_preds.append(pred)\n",
    "        continue\n",
    "    while any([pred.startswith(y) for y in bad_starts]):\n",
    "        pred = pred[1:]\n",
    "    while any([pred.endswith(y) for y in bad_endings]):\n",
    "        if pred.endswith(\"...\"):\n",
    "            pred = pred[:-3]\n",
    "        else:\n",
    "            pred = pred[:-1]\n",
    "    \n",
    "    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
    "        pred = pred+\".\"\n",
    "\n",
    "    cleaned_preds.append(pred)\n",
    "\n",
    "test[\"PredictionString\"] = cleaned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74255971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:19.590132Z",
     "iopub.status.busy": "2021-09-21T02:41:19.589111Z",
     "iopub.status.idle": "2021-09-21T02:41:19.608134Z",
     "shell.execute_reply": "2021-09-21T02:41:19.608912Z",
     "shell.execute_reply.started": "2021-09-20T04:46:25.132343Z"
    },
    "papermill": {
     "duration": 0.121589,
     "end_time": "2021-09-21T02:41:19.609139",
     "exception": false,
     "start_time": "2021-09-21T02:41:19.487550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>28 नवम्बर 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       28 नवम्बर 2007  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ef57a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T02:41:19.775482Z",
     "iopub.status.busy": "2021-09-21T02:41:19.774629Z",
     "iopub.status.idle": "2021-09-21T02:41:19.782216Z",
     "shell.execute_reply": "2021-09-21T02:41:19.781439Z",
     "shell.execute_reply.started": "2021-09-20T04:46:26.963676Z"
    },
    "papermill": {
     "duration": 0.093397,
     "end_time": "2021-09-21T02:41:19.782385",
     "exception": false,
     "start_time": "2021-09-21T02:41:19.688988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[['id','PredictionString']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166dea6",
   "metadata": {
    "papermill": {
     "duration": 0.046477,
     "end_time": "2021-09-21T02:41:19.908101",
     "exception": false,
     "start_time": "2021-09-21T02:41:19.861624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada86ba5",
   "metadata": {
    "papermill": {
     "duration": 0.047205,
     "end_time": "2021-09-21T02:41:20.002886",
     "exception": false,
     "start_time": "2021-09-21T02:41:19.955681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19af074",
   "metadata": {
    "papermill": {
     "duration": 0.046637,
     "end_time": "2021-09-21T02:41:20.096945",
     "exception": false,
     "start_time": "2021-09-21T02:41:20.050308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 552.735056,
   "end_time": "2021-09-21T02:41:22.947946",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-21T02:32:10.212890",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "21208901356f4407b42e262a70a14ee4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36ef8373218c45c79002c606b79f5b3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39b62948f6b44141b5073a5c54574bf6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6f236ad17a9e46b0bb056681a0485f41",
        "IPY_MODEL_874fb181a15046069b85cf3a5d69c292"
       ],
       "layout": "IPY_MODEL_cbb9c2cac20b4ec8ac8458889c9a413a"
      }
     },
     "55148d5ab18b43a199f6678b2ca1ae55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8181c4deab9441629e1706551af2894e",
       "max": 67.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f41e8434c98246c791905fb369106760",
       "value": 67.0
      }
     },
     "63f163d0f8bc4e42add24f619f67f9a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f236ad17a9e46b0bb056681a0485f41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36ef8373218c45c79002c606b79f5b3b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_82f93c61f02e4e2e8dce3e5da32df565",
       "value": 1.0
      }
     },
     "8181c4deab9441629e1706551af2894e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82f93c61f02e4e2e8dce3e5da32df565": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "839a624e83a4479e93797a404ff5a54f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a9c3ab483b6c429dae708d41091ae111",
       "placeholder": "​",
       "style": "IPY_MODEL_88062af74b32403a84842404a9eae3f8",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fb37b900290&gt;"
      }
     },
     "874fb181a15046069b85cf3a5d69c292": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ac5748f5d816410e83433973aeaa13ad",
       "placeholder": "​",
       "style": "IPY_MODEL_63f163d0f8bc4e42add24f619f67f9a7",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fb375bbe2d0&gt;"
      }
     },
     "88062af74b32403a84842404a9eae3f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "98371ef6f0ce40d6b05d734b9559ceee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a9c3ab483b6c429dae708d41091ae111": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac5748f5d816410e83433973aeaa13ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b61f4a9324214daf86f719806542a38b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_55148d5ab18b43a199f6678b2ca1ae55",
        "IPY_MODEL_e761ff66381d432bb8f5838efd05a3c6"
       ],
       "layout": "IPY_MODEL_d3311b05683f4f529f1152ff1b7ff06c"
      }
     },
     "b7757b85c0b04cdfb358226eda51b954": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21208901356f4407b42e262a70a14ee4",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_98371ef6f0ce40d6b05d734b9559ceee",
       "value": 1.0
      }
     },
     "bbcec0b00f5e445e8cdbef5e3ef4fe32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbb9c2cac20b4ec8ac8458889c9a413a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3311b05683f4f529f1152ff1b7ff06c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e761ff66381d432bb8f5838efd05a3c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbcec0b00f5e445e8cdbef5e3ef4fe32",
       "placeholder": "​",
       "style": "IPY_MODEL_fec20f66b910422ba001423293b0300b",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fb3744eacd0&gt;"
      }
     },
     "f327b9869f864d9489dcd526c5bf9ade": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f41e8434c98246c791905fb369106760": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fe8b625f6ab0404ab4f1df31a03dcbd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7757b85c0b04cdfb358226eda51b954",
        "IPY_MODEL_839a624e83a4479e93797a404ff5a54f"
       ],
       "layout": "IPY_MODEL_f327b9869f864d9489dcd526c5bf9ade"
      }
     },
     "fec20f66b910422ba001423293b0300b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
