{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "valued-bruce",
   "metadata": {
    "papermill": {
     "duration": 0.030115,
     "end_time": "2021-05-09T02:54:43.921272",
     "exception": false,
     "start_time": "2021-05-09T02:54:43.891157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this Notebook\n",
    "\n",
    "After carefull considerations and doing a lot of experiments with tfidf and Bert-Based models , I strongly feel Bert-based models might do better if trained and used in the right way. [This](https://www.kaggle.com/c/shopee-product-matching/discussion/231510) dicussion thread talks about the usage of different approaches for text and discusses why BERT-base model might be better.\n",
    "\n",
    "I started with normal Hugging Face BERT type models , but I found Sentence transformers pre-trained models a better idea . As sentence transformer models were already trained in a siamese fashion especially for information retreival and semantic similarity tasks it's much better idea to start with them and then fine-tune it on our data. I have used <b> paraphrase-xlm-r-multilingual-v1 </b> from sentence transformers , one can try with other very good models also . I have uploaded all models for offline use [here](https://www.kaggle.com/tanulsingh077/sentence-transformer-models)\n",
    "\n",
    "One more additional thing which has come as a result of experimentation is to train with full data instead of splitting and then saving models on eval set. To avoid overfitting one can use strong regularizers like using fully connected layer on top of bert output , weight decay,etc\n",
    "\n",
    "This is the inference notebook , you can find the training notebook [here](https://www.kaggle.com/tanulsingh077/metric-learning-pipeline-only-text-sbert)\n",
    "\n",
    "# Additional Utils\n",
    "\n",
    "I have added a function get_neighbours_cos_sim which is cosine similarity equivalent for ragnar's get_neighbours function for knn. Now one can use both to find the best threshold and see which similarity function works best for you ,<b> one thing to note however is that normalize the embeddings if you use cosine similarity</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saving-worthy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:54:43.986213Z",
     "iopub.status.busy": "2021-05-09T02:54:43.984725Z",
     "iopub.status.idle": "2021-05-09T02:55:59.175097Z",
     "shell.execute_reply": "2021-05-09T02:55:59.174004Z"
    },
    "papermill": {
     "duration": 75.222662,
     "end_time": "2021-05-09T02:55:59.175255",
     "exception": false,
     "start_time": "2021-05-09T02:54:43.952593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../input/faiss170latestcpugpu/\r\n",
      "Processing /kaggle/input/faiss170latestcpugpu/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: faiss-gpu\r\n",
      "Successfully installed faiss-gpu-1.7.0\r\n",
      "Processing /kaggle/input/arcface-baseline/Keras_Applications-1.0.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.15.0)\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Processing /kaggle/input/arcface-baseline/efficientnet-1.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.18.1)\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.4.0)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.5)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.4)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2021.3.17)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.3.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n",
      "RAPIDS 0.16.0\n",
      "TF 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install --no-index --find-links '/kaggle/input/faiss-170-latest-cpu-gpu/' faiss-cpu==1.7.0\n",
    "!pip install --no-index --find-links '../input/faiss170latestcpugpu/' faiss-gpu==1.7.0\n",
    "!pip install ../input/arcface-baseline/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install ../input/arcface-baseline/efficientnet-1.1.0-py3-none-any.whl\n",
    "import efficientnet.tfkeras as efn\n",
    "import faiss\n",
    "\n",
    "import numpy as np, pandas as pd, gc\n",
    "import math\n",
    "import cv2, matplotlib.pyplot as plt\n",
    "import cudf, cuml, cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import tensorflow as tf\n",
    "print('RAPIDS',cuml.__version__)\n",
    "print('TF',tf.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# Preliminaries\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import transformers\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-salvation",
   "metadata": {
    "papermill": {
     "duration": 0.032565,
     "end_time": "2021-05-09T02:55:59.240851",
     "exception": false,
     "start_time": "2021-05-09T02:55:59.208286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signal-visitor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:55:59.320458Z",
     "iopub.status.busy": "2021-05-09T02:55:59.318816Z",
     "iopub.status.idle": "2021-05-09T02:56:01.548965Z",
     "shell.execute_reply": "2021-05-09T02:56:01.548209Z"
    },
    "papermill": {
     "duration": 2.275519,
     "end_time": "2021-05-09T02:56:01.549159",
     "exception": false,
     "start_time": "2021-05-09T02:55:59.273640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "################################################  ADJUSTING FOR CV OR SUBMIT ##############################################\n",
    "\n",
    "CHECK_SUB = False\n",
    "GET_CV = True\n",
    "\n",
    "test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "if len(test)>2: GET_CV = False\n",
    "else: print('this submission notebook will compute CV score, but commit notebook will not')\n",
    "\n",
    "\n",
    "################################################# MODEL ###################################################################\n",
    "\n",
    "# transformer_model = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n",
    "transformer_model = '../input/paraphrase-xlm-r-multilingual-v1/paraphrase-xlm-r-multilingual-v1/'\n",
    "TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model)\n",
    "\n",
    "################################################ MODEL PATH ###############################################################\n",
    "\n",
    "# TEXT_MODEL_PATH = '../input/best-multilingual-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin'\n",
    "TEXT_MODEL_PATH = '../input/sbert-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin'\n",
    "\n",
    "model_params = {\n",
    "    'n_classes':11014,\n",
    "    'model_name':transformer_model,\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-andrew",
   "metadata": {
    "papermill": {
     "duration": 0.055296,
     "end_time": "2021-05-09T02:56:01.664215",
     "exception": false,
     "start_time": "2021-05-09T02:56:01.608919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "physical-executive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:01.791874Z",
     "iopub.status.busy": "2021-05-09T02:56:01.790937Z",
     "iopub.status.idle": "2021-05-09T02:56:01.794606Z",
     "shell.execute_reply": "2021-05-09T02:56:01.795189Z"
    },
    "papermill": {
     "duration": 0.073751,
     "end_time": "2021-05-09T02:56:01.795370",
     "exception": false,
     "start_time": "2021-05-09T02:56:01.721619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        \n",
    "    return df, df_cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-index",
   "metadata": {
    "papermill": {
     "duration": 0.05556,
     "end_time": "2021-05-09T02:56:01.906281",
     "exception": false,
     "start_time": "2021-05-09T02:56:01.850721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "delayed-concrete",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.024760Z",
     "iopub.status.busy": "2021-05-09T02:56:02.024027Z",
     "iopub.status.idle": "2021-05-09T02:56:02.030205Z",
     "shell.execute_reply": "2021-05-09T02:56:02.030766Z"
    },
    "papermill": {
     "duration": 0.068935,
     "end_time": "2021-05-09T02:56:02.030960",
     "exception": false,
     "start_time": "2021-05-09T02:56:01.962025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legal-success",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.152644Z",
     "iopub.status.busy": "2021-05-09T02:56:02.151319Z",
     "iopub.status.idle": "2021-05-09T02:56:02.155395Z",
     "shell.execute_reply": "2021-05-09T02:56:02.156132Z"
    },
    "papermill": {
     "duration": 0.069962,
     "end_time": "2021-05-09T02:56:02.156325",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.086363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complicated-removal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.280826Z",
     "iopub.status.busy": "2021-05-09T02:56:02.280062Z",
     "iopub.status.idle": "2021-05-09T02:56:02.293915Z",
     "shell.execute_reply": "2021-05-09T02:56:02.294866Z"
    },
    "papermill": {
     "duration": 0.080936,
     "end_time": "2021-05-09T02:56:02.295060",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.214124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbors_knn(df, embeddings, KNN = 50, threshold=0.7):\n",
    "    '''\n",
    "    https://www.kaggle.com/ragnar123/unsupervised-baseline-arcface?scriptVersionId=57121538\n",
    "    '''\n",
    "\n",
    "#     model = NearestNeighbors(n_neighbors = KNN)\n",
    "#     model.fit(embeddings)\n",
    "#     distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    model = faiss.IndexFlatIP(embeddings.shape[1])  # build the index cosine\n",
    "    model.add(text_embeddings)    # add vectors to the index\n",
    "    distances, indices = model.search(embeddings, KNN)\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        thresholds = list(np.arange(0,2,0.1))\n",
    "        \n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            idx = np.where(distances[k,] < 0.60)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "            predictions.append(posting_ids)\n",
    "    \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            idx = np.where(distances[k,] > threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "artistic-salem",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.393174Z",
     "iopub.status.busy": "2021-05-09T02:56:02.391209Z",
     "iopub.status.idle": "2021-05-09T02:56:02.393873Z",
     "shell.execute_reply": "2021-05-09T02:56:02.394325Z"
    },
    "papermill": {
     "duration": 0.050753,
     "end_time": "2021-05-09T02:56:02.394454",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.343701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbours_cos_sim(df, embeddings, threshold, KNN):\n",
    "    '''\n",
    "    When using cos_sim use normalized features else use normal features\n",
    "    '''\n",
    "    embeddings = cupy.array(embeddings)\n",
    "    \n",
    "    if GET_CV:\n",
    "        thresholds = list(np.arange(0.5,0.7,0.05))\n",
    "\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            \n",
    "################################################# Code for Getting Preds #########################################\n",
    "            preds = []\n",
    "            CHUNK = 1024*4\n",
    "\n",
    "            print('Finding similar titles...for threshold :',threshold)\n",
    "            CTS = len(embeddings)//CHUNK\n",
    "            if len(embeddings)%CHUNK!=0: CTS += 1\n",
    "\n",
    "            for j in range( CTS ):\n",
    "                a = j*CHUNK\n",
    "                b = (j+1)*CHUNK\n",
    "                b = min(b,len(embeddings))\n",
    "\n",
    "                cts = cupy.matmul(embeddings,embeddings[a:b].T).T\n",
    "\n",
    "                for k in range(b-a):\n",
    "                    IDX = cupy.where(cts[k,]>threshold)[0]\n",
    "                    o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "                    o = ' '.join(o)\n",
    "                    preds.append(o)\n",
    "######################################################################################################################\n",
    "            df['pred_matches'] = preds\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "            \n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "            \n",
    "    else:\n",
    "        preds = []\n",
    "        CHUNK = 1024*4\n",
    "#         threshold = 0.7\n",
    "\n",
    "        print('Finding similar texts...for threshold :',threshold)\n",
    "        CTS = len(embeddings)//CHUNK\n",
    "        if len(embeddings)%CHUNK!=0: CTS += 1\n",
    "\n",
    "        for j in range( CTS ):\n",
    "            a = j*CHUNK\n",
    "            b = (j+1)*CHUNK\n",
    "            b = min(b,len(embeddings))\n",
    "            print('chunk',a,'to',b)\n",
    "\n",
    "            cts = cupy.matmul(embeddings,embeddings[a:b].T).T\n",
    "\n",
    "            for k in range(b-a):\n",
    "                IDX = cupy.where(cts[k,]>threshold)[0][:KNN]\n",
    "                o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "                preds.append(o)\n",
    "            \n",
    "        del cts\n",
    "        gc.collect()\n",
    "    return df, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-jewelry",
   "metadata": {
    "papermill": {
     "duration": 0.03459,
     "end_time": "2021-05-09T02:56:02.463945",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.429355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moved-plain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.540294Z",
     "iopub.status.busy": "2021-05-09T02:56:02.538933Z",
     "iopub.status.idle": "2021-05-09T02:56:02.540832Z",
     "shell.execute_reply": "2021-05-09T02:56:02.541247Z"
    },
    "papermill": {
     "duration": 0.043232,
     "end_time": "2021-05-09T02:56:02.541364",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.498132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        text = row.title\n",
    "        \n",
    "        text = TOKENIZER(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        input_ids = text['input_ids'][0]\n",
    "        attention_mask = text['attention_mask'][0]  \n",
    "        \n",
    "        return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "practical-headquarters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.622808Z",
     "iopub.status.busy": "2021-05-09T02:56:02.622227Z",
     "iopub.status.idle": "2021-05-09T02:56:02.625386Z",
     "shell.execute_reply": "2021-05-09T02:56:02.624846Z"
    },
    "papermill": {
     "duration": 0.049894,
     "end_time": "2021-05-09T02:56:02.625612",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.575718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='bert-base-uncased',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(ShopeeNet, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
    "        final_in_features = self.transformer.config.hidden_size\n",
    "        \n",
    "        self.use_fc = use_fc\n",
    "    \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask):\n",
    "        feature = self.extract_feat(input_ids,attention_mask)\n",
    "        return F.normalize(feature)\n",
    "\n",
    "    def extract_feat(self, input_ids,attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "\n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.fc(features)\n",
    "            features = self.bn(features)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-trace",
   "metadata": {
    "papermill": {
     "duration": 0.036551,
     "end_time": "2021-05-09T02:56:02.698730",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.662179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Faiss KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sunrise-gardening",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.785858Z",
     "iopub.status.busy": "2021-05-09T02:56:02.785037Z",
     "iopub.status.idle": "2021-05-09T02:56:02.788702Z",
     "shell.execute_reply": "2021-05-09T02:56:02.788234Z"
    },
    "papermill": {
     "duration": 0.053677,
     "end_time": "2021-05-09T02:56:02.788803",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.735126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_faiss_neighbors_knn(df, embeddings, KNN = 50, upper_threshold=0.7, lower_threshold =0.7, print_distances=False):\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    model = faiss.IndexFlatIP(embeddings.shape[1])  # build the index cosine\n",
    "    model = faiss.index_cpu_to_all_gpus(model)  \n",
    "    model.add(embeddings)    # add vectors to the index\n",
    "    distances, indices = model.search(embeddings, KNN)\n",
    "    if print_distances:\n",
    "        print(distances)\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        thresholds = list(np.arange(0.65,0.95,0.01))\n",
    "        \n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] > threshold)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        predictions_upper_threshold = [] \n",
    "        predictions_lower_threshold = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            idx = np.where(distances[k,] > upper_threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "            predictions.append(posting_ids)\n",
    "        predictions_upper_threshold = predictions\n",
    "        predictions_lower_threshold = predictions\n",
    "        \n",
    "    \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "#         predictions = []\n",
    "#         for k in tqdm(range(embeddings.shape[0])):\n",
    "#             idx = np.where(distances[k,] > threshold)[0]\n",
    "#             ids = indices[k,idx]\n",
    "#             posting_ids = df['posting_id'].iloc[ids].values\n",
    "#             predictions.append(posting_ids)\n",
    "        predictions_upper_threshold = []\n",
    "        predictions_lower_threshold = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            idx = np.where(distances[k,] > upper_threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions_upper_threshold.append(posting_ids)\n",
    "            \n",
    "            idx = np.where(distances[k,] > lower_threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions_lower_threshold.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions_upper_threshold, predictions_lower_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-mounting",
   "metadata": {
    "papermill": {
     "duration": 0.034617,
     "end_time": "2021-05-09T02:56:02.858535",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.823918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cosmetic-background",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:02.936678Z",
     "iopub.status.busy": "2021-05-09T02:56:02.935196Z",
     "iopub.status.idle": "2021-05-09T02:56:02.937903Z",
     "shell.execute_reply": "2021-05-09T02:56:02.938360Z"
    },
    "papermill": {
     "duration": 0.045627,
     "end_time": "2021-05-09T02:56:02.938476",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.892849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embeddings(df):\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeNet(**model_params)\n",
    "    model.eval()\n",
    "    \n",
    "    model.load_state_dict(dict(list(torch.load(TEXT_MODEL_PATH).items())[:-1]))\n",
    "    model = model.to(device)\n",
    "\n",
    "    text_dataset = ShopeeDataset(df)\n",
    "    text_loader = torch.utils.data.DataLoader(\n",
    "        text_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask in tqdm(text_loader): \n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            feat = model(input_ids, attention_mask)\n",
    "            text_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(text_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amazing-aggregate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:03.025694Z",
     "iopub.status.busy": "2021-05-09T02:56:03.025014Z",
     "iopub.status.idle": "2021-05-09T02:56:12.001664Z",
     "shell.execute_reply": "2021-05-09T02:56:12.000686Z"
    },
    "papermill": {
     "duration": 9.027624,
     "end_time": "2021-05-09T02:56:12.001807",
     "exception": false,
     "start_time": "2021-05-09T02:56:02.974183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,df_cu = read_dataset()\n",
    "# df_cu = cudf.concat(10000*[df_cu], axis=0)\n",
    "# df_cu.reset_index(drop = True, inplace = True)\n",
    "del df_cu\n",
    "gc.collect()\n",
    "# df =  pd.concat(500*[df], axis=0)\n",
    "# df =  pd.concat(11500*[df], axis=0)\n",
    "# df =  pd.concat(15000*[df], axis=0)\n",
    "# df.reset_index(drop = True, inplace = True)\n",
    "# df.head(n=10)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "consolidated-village",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:12.074028Z",
     "iopub.status.busy": "2021-05-09T02:56:12.073367Z",
     "iopub.status.idle": "2021-05-09T02:56:47.298588Z",
     "shell.execute_reply": "2021-05-09T02:56:47.298106Z"
    },
    "papermill": {
     "duration": 35.262903,
     "end_time": "2021-05-09T02:56:47.298717",
     "exception": false,
     "start_time": "2021-05-09T02:56:12.035814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (3, 768)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "text_embeddings = get_text_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "canadian-right",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:47.375789Z",
     "iopub.status.busy": "2021-05-09T02:56:47.375219Z",
     "iopub.status.idle": "2021-05-09T02:56:48.072002Z",
     "shell.execute_reply": "2021-05-09T02:56:48.069302Z"
    },
    "papermill": {
     "duration": 0.738321,
     "end_time": "2021-05-09T02:56:48.072137",
     "exception": false,
     "start_time": "2021-05-09T02:56:47.333816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1268.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12.5 and 0.70 -> 0.719 \n",
    "# 12.5 and 0.71 -> 0.721\n",
    "# 12.5 and 0.73 -> 0.724\n",
    "# 12.5 and 0.75 -> 0.725\n",
    "# 12.5 and 0.76 -> 0.726\n",
    "# 12.5 and 0.76 and tfidf -> 0.732\n",
    "# 12.5 and 0.77 and tfidf -> 0.733\n",
    "# 12.5 and 0.78 and tfidf -> 0.734\n",
    "# 12.5 and 0.79 and tfidf -> 0.734 better\n",
    "# 12.5 and 0.80 and tfidf -> 0.734 more better\n",
    "# 12.5 and 0.81 and tfidf -> 0.735\n",
    "# 12.5 and 0.82 and tfidf -> 0.735 better\n",
    "# 12.5 and 0.83 and tfidf -> 0.736\n",
    "# 12.5 and 0.84 and tfidf -> 0.735\n",
    "\n",
    "\n",
    "\n",
    "# __, 12.5 , 0.79(norm) -> 0.727\n",
    "# 0.83, 12.5 , 0.79(norm) -> 0.725\n",
    "# 0.84, 12.5 , 0.79(norm) -> 0.724\n",
    "# 0.82, 12.5 , 0.79(norm) -> 0.726\n",
    "# 0.81, 12.5 , 0.79(norm) -> 0.726\n",
    "# 0.80, 12.5 , 0.79(norm) -> 0.726\n",
    "# 0.79, 12.5 , 0.79(norm) -> 0.727\n",
    "\n",
    "\n",
    "# threshold = 0.79\n",
    "# # df,text_predictions = get_neighbours_cos_sim(df, text_embeddings, threshold, KNN = 50)\n",
    "# try:\n",
    "#     df,text_predictions = get_neighbors_knn(df, text_embeddings, KNN=50, threshold=threshold)\n",
    "# except:\n",
    "#     df,text_predictions = get_neighbors_knn(df, text_embeddings, KNN=3, threshold=threshold)\n",
    "# test = df\n",
    "# test['preds'] = text_predictions\n",
    "# del text_predictions, df, text_embeddings\n",
    "# gc.collect()\n",
    "\n",
    "#\n",
    "#text_KNN =200 , 12.5 , 0.9, 0.75, tfidf=10000 -> 0.729\n",
    "#text_KNN =200 , 12.5 , 0.9, 0.75, tfidf=5000 -> 0.724\n",
    "#text_KNN =200 , 12.5 , 0.9, 0.65, tfidf=5000 -> 0.721\n",
    "#text_KNN =200 , 12.5 , 0.9, 0.70, tfidf=10000 -> 0.730\n",
    "#text_KNN =150 , 12.5 , 0.9, 0.70, tfidf=10000 -> 0.730\n",
    "#text_KNN =150 , 12.5 , 0.87, 0.70, 0.9, 0.70, tfidf=10000 -> 0.730\n",
    "#text_KNN =150 , 12.5 , 0.85, 0.70, 0.9, 0.70, tfidf=10000 -> 0.730\n",
    "#text_KNN =150 , 12.5 , 0.85, 0.70, 0.9, 0.70, tfidf=10000  New model -> 0.691 \n",
    "#text_KNN =150 , 12.5 , 0.85, 0.70, 0.9, 0.70, tfidf=10000 New model  better version1->\n",
    "#text_KNN =100 , 12.5 , 0.85, 0.70, 0.9, 0.70, tfidf=10000\n",
    "#image_KNN=50, 0.80 text_KNN =100 , 0.85, 0.70, 0.9, 0.70 tfidf=10000 L2norm -> 0.721\n",
    "#image_KNN=50, 0.75 text_KNN =100 , 0.85, 0.70, 0.9, 0.70 tfidf=10000 L2norm -> 0.726\n",
    "\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.70, 0.9, 0.70 tfidf=10000 L2norm -> 0.730\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.70, 0.9, 0.70 tfidf=25000 L2norm -> 0.734\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.70, 0.85, 0.70 tfidf=25000 L2norm -> 0.735\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm -> 0.736\n",
    "# KNN=50, 0.75, 0.65 , 0.75, 0.65, 0.75, 0.65 tfidf=25000 L2norm -> 0.729\n",
    "# KNN=50, 0.75, 0.65 , 0.80, 0.65, 0.80, 0.65 tfidf=25000 L2norm -> 0.735\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm , quora -> 0.518\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm , +quora 0.9 -> 0.558\n",
    "# KNN=50, 0.75, 0.65 , 0.80, 0.65, 0.85, 0.65 tfidf=25000 L2norm -> 0.734\n",
    "# KNN=50, 0.75, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm -> 0.736\n",
    "# KNN=50, 0.80, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm\n",
    "\n",
    "\n",
    "text_KNN = 50#100#150#200\n",
    "text_upper_threshold = 0.85#0.75#0.85#0.9\n",
    "text_lower_threshold = 0.65#0.70\n",
    "print_distance = False#True\n",
    "df, text_upper_predictions, text_lower_predictions = get_faiss_neighbors_knn(df, text_embeddings, KNN=text_KNN,\n",
    "                                                                             upper_threshold=text_upper_threshold, \n",
    "                                                                             lower_threshold=text_lower_threshold,\n",
    "                                                                            print_distances=print_distance)\n",
    "\n",
    "test = df\n",
    "test['text_upper_pred_multi'] = text_upper_predictions\n",
    "test['text_lower_pred_multi'] = text_lower_predictions\n",
    "\n",
    "# print(test.head())\n",
    "del text_upper_predictions, text_lower_predictions, df, text_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prospective-turkish",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:48.157951Z",
     "iopub.status.busy": "2021-05-09T02:56:48.157317Z",
     "iopub.status.idle": "2021-05-09T02:56:48.167716Z",
     "shell.execute_reply": "2021-05-09T02:56:48.168123Z"
    },
    "papermill": {
     "duration": 0.059548,
     "end_time": "2021-05-09T02:56:48.168265",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.108717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>text_upper_pred_multi</th>\n",
       "      <th>text_lower_pred_multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title text_upper_pred_multi  \\\n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...     [test_2255846744]   \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...     [test_3588702337]   \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_multi  \n",
       "0     [test_2255846744]  \n",
       "1     [test_3588702337]  \n",
       "2     [test_4015706929]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-firmware",
   "metadata": {
    "papermill": {
     "duration": 0.036658,
     "end_time": "2021-05-09T02:56:48.241469",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.204811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "norman-creativity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:48.319477Z",
     "iopub.status.busy": "2021-05-09T02:56:48.318720Z",
     "iopub.status.idle": "2021-05-09T02:56:48.321454Z",
     "shell.execute_reply": "2021-05-09T02:56:48.321041Z"
    },
    "papermill": {
     "duration": 0.043504,
     "end_time": "2021-05-09T02:56:48.321559",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.278055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # transformer_model = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n",
    "# transformer_model = '../input/quora-distilbert-multilingual/quora-distilbert-multilingual/'\n",
    "# TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model)\n",
    "\n",
    "# ################################################ MODEL PATH ###############################################################\n",
    "\n",
    "# # TEXT_MODEL_PATH = '../input/best-multilingual-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin'\n",
    "# TEXT_MODEL_PATH = '../input/training-pipeline-xlm-t-better-version/sentence_transfomer_quora_xlm_best_loss_num_epochs_25_arcface.bin'\n",
    "\n",
    "# model_params = {\n",
    "#     'n_classes':4036,\n",
    "#     'model_name':transformer_model,\n",
    "#     'use_fc':False,\n",
    "#     'fc_dim':512,\n",
    "#     'dropout':0.3,\n",
    "# }\n",
    "# text_embeddings = get_text_embeddings(test)\n",
    "# text_KNN = 50#100#150#200\n",
    "# text_upper_threshold = 0.90#0.80#0.75#0.85#0.9\n",
    "# text_lower_threshold = 0.65#0.70\n",
    "# print_distance = False#True\n",
    "# df, text_upper_predictions, text_lower_predictions = get_faiss_neighbors_knn(test, text_embeddings, KNN=text_KNN,\n",
    "#                                                                              upper_threshold=text_upper_threshold, \n",
    "#                                                                              lower_threshold=text_lower_threshold,\n",
    "#                                                                             print_distances=print_distance)\n",
    "\n",
    "# test['text_upper_pred_multi_quora'] = text_upper_predictions\n",
    "# test['text_lower_pred_multi_quora'] = text_lower_predictions\n",
    "\n",
    "# # print(test.head())\n",
    "# del text_upper_predictions, text_lower_predictions, df, text_embeddings\n",
    "# gc.collect()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-question",
   "metadata": {
    "papermill": {
     "duration": 0.039183,
     "end_time": "2021-05-09T02:56:48.397285",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.358102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "other-effect",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:48.737814Z",
     "iopub.status.busy": "2021-05-09T02:56:48.737237Z",
     "iopub.status.idle": "2021-05-09T02:56:48.741523Z",
     "shell.execute_reply": "2021-05-09T02:56:48.741115Z"
    },
    "papermill": {
     "duration": 0.303596,
     "end_time": "2021-05-09T02:56:48.741640",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.438044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will restrict TensorFlow to max 1GB GPU RAM\n",
      "then RAPIDS can use 15GB GPU RAM\n"
     ]
    }
   ],
   "source": [
    "# RESTRICT TENSORFLOW TO 1GB OF GPU RAM\n",
    "# SO THAT WE HAVE 15GB RAM FOR RAPIDS\n",
    "LIMIT = 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "precious-snake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:48.831232Z",
     "iopub.status.busy": "2021-05-09T02:56:48.830552Z",
     "iopub.status.idle": "2021-05-09T02:56:48.833685Z",
     "shell.execute_reply": "2021-05-09T02:56:48.833246Z"
    },
    "papermill": {
     "duration": 0.0546,
     "end_time": "2021-05-09T02:56:48.833795",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.779195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "technical-belgium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:48.917102Z",
     "iopub.status.busy": "2021-05-09T02:56:48.916543Z",
     "iopub.status.idle": "2021-05-09T02:56:55.159830Z",
     "shell.execute_reply": "2021-05-09T02:56:55.158761Z"
    },
    "papermill": {
     "duration": 6.288277,
     "end_time": "2021-05-09T02:56:55.159994",
     "exception": false,
     "start_time": "2021-05-09T02:56:48.871717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 11011\n",
    "IMAGE_SIZE = [512, 512]\n",
    "margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.7, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = margin([x, label])\n",
    "\n",
    "output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "#     model.load_weights('../input/shopee-efficientnetb3-arcmarginproduct/EfficientNetB3_512_42.h5')\n",
    "#     model.load_weights('../input/ragnar-best-val-score-weights/EfficientNetB3_512_42.h5')\n",
    "model.load_weights('../input/ragnar715score/EfficientNetB3_512_42.h5')\n",
    "# print(model.summary())\n",
    "model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dress-explanation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:55.244000Z",
     "iopub.status.busy": "2021-05-09T02:56:55.242202Z",
     "iopub.status.idle": "2021-05-09T02:56:55.244578Z",
     "shell.execute_reply": "2021-05-09T02:56:55.244979Z"
    },
    "papermill": {
     "duration": 0.047049,
     "end_time": "2021-05-09T02:56:55.245110",
     "exception": false,
     "start_time": "2021-05-09T02:56:55.198061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE =8 \n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "#     image = tf.image.resize_with_pad(image, target_width = IMAGE_SIZE[0], target_height = IMAGE_SIZE[1])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "flush-boring",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:55.328672Z",
     "iopub.status.busy": "2021-05-09T02:56:55.328155Z",
     "iopub.status.idle": "2021-05-09T02:56:59.792704Z",
     "shell.execute_reply": "2021-05-09T02:56:59.793204Z"
    },
    "papermill": {
     "duration": 4.510707,
     "end_time": "2021-05-09T02:56:59.793362",
     "exception": false,
     "start_time": "2021-05-09T02:56:55.282655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing image embeddings...\n",
      "chunk 0 to 3\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "image embeddings shape (3, 1536)\n"
     ]
    }
   ],
   "source": [
    "BASE = '../input/shopee-product-matching/test_images/'\n",
    "if GET_CV: \n",
    "    BASE = '../input/shopee-product-matching/train_images/'\n",
    "    test = df\n",
    "\n",
    "# WGT = '../input/effnetb0/efficientnetb0_notop.h5'\n",
    "# model = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n",
    "model = model\n",
    "\n",
    "embeds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "print('Computing image embeddings...')\n",
    "CTS = len(test)//CHUNK\n",
    "if len(test)%CHUNK!=0: CTS += 1\n",
    "image_path=BASE+test['image']\n",
    "\n",
    "for i,j in enumerate( range( CTS ) ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(test))\n",
    "    print('chunk',a,'to',b)\n",
    "    \n",
    "#     test_gen = DataGenerator(test.iloc[a:b], batch_size=32, path=BASE)\n",
    "    test_gen = get_dataset(image_path[a:b])\n",
    "    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n",
    "#     image_embeddings = model.predict(test_gen)\n",
    "    embeds.append(image_embeddings)\n",
    "\n",
    "    #if i>=1: break\n",
    "    \n",
    "del model\n",
    "_ = gc.collect()\n",
    "image_embeddings = np.concatenate(embeds)\n",
    "print('image embeddings shape',image_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "environmental-momentum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:56:59.883202Z",
     "iopub.status.busy": "2021-05-09T02:56:59.882590Z",
     "iopub.status.idle": "2021-05-09T02:57:00.323224Z",
     "shell.execute_reply": "2021-05-09T02:57:00.324371Z"
    },
    "papermill": {
     "duration": 0.492169,
     "end_time": "2021-05-09T02:57:00.324575",
     "exception": false,
     "start_time": "2021-05-09T02:56:59.832406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2516.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# KNN=50, 0.75, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm Eff_b0:0.75 0.65 -> 0.729\n",
    "# KNN=50, 0.80, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm Eff_b0:0.80 0.65 -> 0.733\n",
    "# KNN=50, 0.85, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm Eff_b0:0.85 0.65 -> 0.734\n",
    "print_distances = False#True\n",
    "\n",
    "image_KNN = 50#100#150#200\n",
    "image_upper_threshold = 0.85#0.75\n",
    "image_lower_threshold = 0.60\n",
    "df, image_upper_predictions, image_lower_predictions = get_faiss_neighbors_knn(test, image_embeddings, KNN=image_KNN, \n",
    "                                                                               upper_threshold=image_upper_threshold, \n",
    "                                                                                lower_threshold=image_lower_threshold,\n",
    "                                                                              print_distances=print_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "answering-teach",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:00.471458Z",
     "iopub.status.busy": "2021-05-09T02:57:00.470692Z",
     "iopub.status.idle": "2021-05-09T02:57:00.717005Z",
     "shell.execute_reply": "2021-05-09T02:57:00.716148Z"
    },
    "papermill": {
     "duration": 0.325788,
     "end_time": "2021-05-09T02:57:00.717143",
     "exception": false,
     "start_time": "2021-05-09T02:57:00.391355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>text_upper_pred_multi</th>\n",
       "      <th>text_lower_pred_multi</th>\n",
       "      <th>image_upper_preds</th>\n",
       "      <th>image_lower_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title text_upper_pred_multi  \\\n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...     [test_2255846744]   \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...     [test_3588702337]   \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_multi  image_upper_preds  image_lower_preds  \n",
       "0     [test_2255846744]  [test_2255846744]  [test_2255846744]  \n",
       "1     [test_3588702337]  [test_3588702337]  [test_3588702337]  \n",
       "2     [test_4015706929]  [test_4015706929]  [test_4015706929]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test['preds2'] = preds\n",
    "test['image_upper_preds'] = image_upper_predictions\n",
    "test['image_lower_preds'] = image_lower_predictions\n",
    "del image_embeddings, image_upper_predictions, image_lower_predictions, df\n",
    "_ = gc.collect()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-tourism",
   "metadata": {
    "papermill": {
     "duration": 0.040651,
     "end_time": "2021-05-09T02:57:00.798071",
     "exception": false,
     "start_time": "2021-05-09T02:57:00.757420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# image model 2(Eff_B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rubber-needle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:00.890309Z",
     "iopub.status.busy": "2021-05-09T02:57:00.889273Z",
     "iopub.status.idle": "2021-05-09T02:57:04.023495Z",
     "shell.execute_reply": "2021-05-09T02:57:04.022399Z"
    },
    "papermill": {
     "duration": 3.185236,
     "end_time": "2021-05-09T02:57:04.023637",
     "exception": false,
     "start_time": "2021-05-09T02:57:00.838401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 5\n",
    "# BATCH_SIZE = 4\n",
    "IMAGE_SIZE = [384, 384]\n",
    "# Seed\n",
    "SEED = 42\n",
    "# Learning rate\n",
    "LR = 0.001\n",
    "# Verbosity\n",
    "VERBOSE = 2\n",
    "N_CLASSES = 11011\n",
    "\n",
    "inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3))\n",
    "x = efn.EfficientNetB0(weights = None, include_top = False)(inp)\n",
    "#     x = efn.EfficientNetB4(include_top = False, weights = 'imagenet')(inp)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "output = tf.keras.layers.Dense(N_CLASSES, activation = 'softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n",
    "\n",
    "model.load_weights('../input/shopee-training-baseline-efficientnetb4/EfficientNetB0_384_42.h5')\n",
    "# model.summary()\n",
    "# print('----------------------------')\n",
    "model = tf.keras.models.Model(inputs = inp, outputs = model.layers[-4].output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mechanical-above",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:04.114747Z",
     "iopub.status.busy": "2021-05-09T02:57:04.114201Z",
     "iopub.status.idle": "2021-05-09T02:57:04.118097Z",
     "shell.execute_reply": "2021-05-09T02:57:04.117592Z"
    },
    "papermill": {
     "duration": 0.05157,
     "end_time": "2021-05-09T02:57:04.118260",
     "exception": false,
     "start_time": "2021-05-09T02:57:04.066690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE =8 \n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "#     image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.image.resize_with_pad(image, target_width = IMAGE_SIZE[0], target_height = IMAGE_SIZE[1])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "designing-touch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:04.211304Z",
     "iopub.status.busy": "2021-05-09T02:57:04.210074Z",
     "iopub.status.idle": "2021-05-09T02:57:06.249122Z",
     "shell.execute_reply": "2021-05-09T02:57:06.249512Z"
    },
    "papermill": {
     "duration": 2.090172,
     "end_time": "2021-05-09T02:57:06.249671",
     "exception": false,
     "start_time": "2021-05-09T02:57:04.159499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing image embeddings...\n",
      "chunk 0 to 3\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "image embeddings shape (3, 1280)\n"
     ]
    }
   ],
   "source": [
    "BASE = '../input/shopee-product-matching/test_images/'\n",
    "if GET_CV: \n",
    "    BASE = '../input/shopee-product-matching/train_images/'\n",
    "    test = df\n",
    "\n",
    "# WGT = '../input/effnetb0/efficientnetb0_notop.h5'\n",
    "# model = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n",
    "model = model\n",
    "\n",
    "embeds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "print('Computing image embeddings...')\n",
    "CTS = len(test)//CHUNK\n",
    "if len(test)%CHUNK!=0: CTS += 1\n",
    "image_path=BASE+test['image']\n",
    "\n",
    "for i,j in enumerate( range( CTS ) ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(test))\n",
    "    print('chunk',a,'to',b)\n",
    "    \n",
    "#     test_gen = DataGenerator(test.iloc[a:b], batch_size=32, path=BASE)\n",
    "    test_gen = get_dataset(image_path[a:b])\n",
    "    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n",
    "#     image_embeddings = model.predict(test_gen)\n",
    "    embeds.append(image_embeddings)\n",
    "\n",
    "    #if i>=1: break\n",
    "    \n",
    "del model\n",
    "_ = gc.collect()\n",
    "image_embeddings = np.concatenate(embeds)\n",
    "print('image embeddings shape',image_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lyric-recording",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:06.352688Z",
     "iopub.status.busy": "2021-05-09T02:57:06.351809Z",
     "iopub.status.idle": "2021-05-09T02:57:06.715934Z",
     "shell.execute_reply": "2021-05-09T02:57:06.715489Z"
    },
    "papermill": {
     "duration": 0.423989,
     "end_time": "2021-05-09T02:57:06.716139",
     "exception": false,
     "start_time": "2021-05-09T02:57:06.292150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2775.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# KNN=50, 0.80, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm Eff_b0:0.9 ->0.736\n",
    "# KNN=50, 0.80, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm Eff_b0:0.85 -> 0.735\n",
    "# KNN=50, 0.80, 0.65 , 0.85, 0.65, 0.85, 0.65 tfidf=25000 L2norm Eff_b0:0.95 -> 0.736\n",
    "print_distances = False#True \n",
    "\n",
    "image_KNN = 50#100#150#200\n",
    "image_upper_threshold = 0.85#0.75#0.90#0.75\n",
    "image_lower_threshold = 0.60\n",
    "df, image_upper_predictions, image_lower_predictions = get_faiss_neighbors_knn(test, image_embeddings, KNN=image_KNN, \n",
    "                                                                               upper_threshold=image_upper_threshold, \n",
    "                                                                                lower_threshold=image_lower_threshold,\n",
    "                                                                              print_distances=print_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "alien-appendix",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:06.807803Z",
     "iopub.status.busy": "2021-05-09T02:57:06.807006Z",
     "iopub.status.idle": "2021-05-09T02:57:07.037307Z",
     "shell.execute_reply": "2021-05-09T02:57:07.036664Z"
    },
    "papermill": {
     "duration": 0.277633,
     "end_time": "2021-05-09T02:57:07.037453",
     "exception": false,
     "start_time": "2021-05-09T02:57:06.759820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>text_upper_pred_multi</th>\n",
       "      <th>text_lower_pred_multi</th>\n",
       "      <th>image_upper_preds</th>\n",
       "      <th>image_lower_preds</th>\n",
       "      <th>image_upper_preds_b0</th>\n",
       "      <th>image_lower_preds_b0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title text_upper_pred_multi  \\\n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...     [test_2255846744]   \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...     [test_3588702337]   \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_multi  image_upper_preds  image_lower_preds  \\\n",
       "0     [test_2255846744]  [test_2255846744]  [test_2255846744]   \n",
       "1     [test_3588702337]  [test_3588702337]  [test_3588702337]   \n",
       "2     [test_4015706929]  [test_4015706929]  [test_4015706929]   \n",
       "\n",
       "  image_upper_preds_b0 image_lower_preds_b0  \n",
       "0    [test_2255846744]    [test_2255846744]  \n",
       "1    [test_3588702337]    [test_3588702337]  \n",
       "2    [test_4015706929]    [test_4015706929]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test['preds2'] = preds\n",
    "test['image_upper_preds_b0'] = image_upper_predictions\n",
    "test['image_lower_preds_b0'] = image_lower_predictions\n",
    "del image_embeddings, image_upper_predictions, image_lower_predictions, df\n",
    "_ = gc.collect()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-oliver",
   "metadata": {
    "papermill": {
     "duration": 0.043362,
     "end_time": "2021-05-09T02:57:07.124808",
     "exception": false,
     "start_time": "2021-05-09T02:57:07.081446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "natural-edwards",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:07.218722Z",
     "iopub.status.busy": "2021-05-09T02:57:07.217854Z",
     "iopub.status.idle": "2021-05-09T02:57:21.377739Z",
     "shell.execute_reply": "2021-05-09T02:57:21.377127Z"
    },
    "papermill": {
     "duration": 14.209017,
     "end_time": "2021-05-09T02:57:21.377867",
     "exception": false,
     "start_time": "2021-05-09T02:57:07.168850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing text embeddings...\n",
      "text embeddings shape (3, 26)\n"
     ]
    }
   ],
   "source": [
    "# test = df\n",
    "# test = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "# test =  pd.concat(2*[test], axis=0)\n",
    "print('Computing text embeddings...')\n",
    "model = TfidfVectorizer(stop_words='english', binary=True, max_features=25000)\n",
    "# model = TfidfVectorizer(stop_words='english', binary=True, max_features=10000)\n",
    "# model = TfidfVectorizer(stop_words='english', binary=True, max_features=5000)\n",
    "test_gf = cudf.DataFrame(test)\n",
    "# text_embeddings = model.fit_transform(test_gf.title).toarray()\n",
    "text_embeddings = model.fit_transform(test_gf.title.str.lower()).toarray()\n",
    "print('text embeddings shape',text_embeddings.shape)\n",
    "del model\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "invisible-shareware",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:21.488492Z",
     "iopub.status.busy": "2021-05-09T02:57:21.487802Z",
     "iopub.status.idle": "2021-05-09T02:57:22.136213Z",
     "shell.execute_reply": "2021-05-09T02:57:22.137836Z"
    },
    "papermill": {
     "duration": 0.711544,
     "end_time": "2021-05-09T02:57:22.138719",
     "exception": false,
     "start_time": "2021-05-09T02:57:21.427175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2799.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>text_upper_pred_multi</th>\n",
       "      <th>text_lower_pred_multi</th>\n",
       "      <th>image_upper_preds</th>\n",
       "      <th>image_lower_preds</th>\n",
       "      <th>image_upper_preds_b0</th>\n",
       "      <th>image_lower_preds_b0</th>\n",
       "      <th>text_upper_pred_tfidf</th>\n",
       "      <th>text_lower_pred_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title text_upper_pred_multi  \\\n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...     [test_2255846744]   \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...     [test_3588702337]   \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_multi  image_upper_preds  image_lower_preds  \\\n",
       "0     [test_2255846744]  [test_2255846744]  [test_2255846744]   \n",
       "1     [test_3588702337]  [test_3588702337]  [test_3588702337]   \n",
       "2     [test_4015706929]  [test_4015706929]  [test_4015706929]   \n",
       "\n",
       "  image_upper_preds_b0 image_lower_preds_b0 text_upper_pred_tfidf  \\\n",
       "0    [test_2255846744]    [test_2255846744]     [test_2255846744]   \n",
       "1    [test_3588702337]    [test_3588702337]     [test_3588702337]   \n",
       "2    [test_4015706929]    [test_4015706929]     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_tfidf  \n",
       "0     [test_2255846744]  \n",
       "1     [test_3588702337]  \n",
       "2     [test_4015706929]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings = cupy.asnumpy(text_embeddings)\n",
    "\n",
    "text_KNN = 50#100#150#200\n",
    "text_upper_threshold = 0.85#0.80#0.75#0.85\n",
    "text_lower_threshold = 0.65#0.70\n",
    "df, text_upper_predictions, text_lower_predictions = get_faiss_neighbors_knn(test, text_embeddings, KNN=text_KNN, upper_threshold=text_upper_threshold, \n",
    "                                        lower_threshold=text_lower_threshold)\n",
    "\n",
    "test['text_upper_pred_tfidf'] = text_upper_predictions\n",
    "test['text_lower_pred_tfidf'] = text_lower_predictions\n",
    "\n",
    "# print(test.head())\n",
    "del text_upper_predictions, text_lower_predictions, text_embeddings\n",
    "gc.collect()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "familiar-strip",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:22.316346Z",
     "iopub.status.busy": "2021-05-09T02:57:22.315541Z",
     "iopub.status.idle": "2021-05-09T02:57:22.317964Z",
     "shell.execute_reply": "2021-05-09T02:57:22.318664Z"
    },
    "papermill": {
     "duration": 0.089385,
     "end_time": "2021-05-09T02:57:22.318855",
     "exception": false,
     "start_time": "2021-05-09T02:57:22.229470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# CHUNK = 1024*4\n",
    "\n",
    "# # 12.5 and 0.71 -> 0.731\n",
    "# # 12.5 and 0.72 -> 0.731 better\n",
    "# # 12.5 and 0.73 -> 0.732 \n",
    "# # 12.5 and 0.74 -> 0.732\n",
    "# # 12.5 and 0.75 -> 0.732\n",
    "# # 12.5 and 0.76 -> 0.732 best\n",
    "# text_threshold = 0.76#.76#0.7\n",
    "\n",
    "# print('Finding similar titles...')\n",
    "# CTS = len(test)//CHUNK\n",
    "# if len(test)%CHUNK!=0: CTS += 1\n",
    "# for j in range( CTS ):\n",
    "    \n",
    "#     a = j*CHUNK\n",
    "#     b = (j+1)*CHUNK\n",
    "#     b = min(b,len(test))\n",
    "#     print('chunk',a,'to',b)\n",
    "    \n",
    "#     # COSINE SIMILARITY DISTANCE\n",
    "#     cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
    "# #     print(cts)\n",
    "#     for k in range(b-a):\n",
    "#         IDX = cupy.where(cts[k,]>text_threshold)[0][:50]\n",
    "# # #         print(IDX)\n",
    "# # #         print(cts[k])\n",
    "# #         temp_dict = {}\n",
    "# #         IDX = cupy.asnumpy(IDX)\n",
    "# #         for i in IDX:\n",
    "# #             temp_dict[i]=cts[k][i]\n",
    "# # #         print(temp_dict)\n",
    "# #         temp_dict =dict(sorted(temp_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# # #         print(temp_dict)\n",
    "# # #         print('-----------')\n",
    "# #         final_IDX = np.fromiter(temp_dict.keys(), dtype=int)[:50]\n",
    "# #         o = test.iloc[final_IDX].posting_id.values\n",
    "#         o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "#         preds.append(o)\n",
    "# del text_embeddings\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "constant-domestic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:22.474059Z",
     "iopub.status.busy": "2021-05-09T02:57:22.473389Z",
     "iopub.status.idle": "2021-05-09T02:57:22.475773Z",
     "shell.execute_reply": "2021-05-09T02:57:22.476366Z"
    },
    "papermill": {
     "duration": 0.083351,
     "end_time": "2021-05-09T02:57:22.476546",
     "exception": false,
     "start_time": "2021-05-09T02:57:22.393195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNN = 50\n",
    "# if len(test)==3: KNN = 3\n",
    "# # model = NearestNeighbors(n_neighbors=KNN)\n",
    "# # model.fit(image_embeddings)\n",
    "# text_embeddings = cupy.asnumpy(text_embeddings)\n",
    "\n",
    "# # model = faiss.IndexFlatL2(text_embeddings.shape[1])   # build the index\n",
    "# model = faiss.IndexFlatIP(text_embeddings.shape[1])  # build the index cosine\n",
    "# model.add(text_embeddings)    # add vectors to the index\n",
    "# preds = []\n",
    "\n",
    "# # __, 12.5 , 0.76 -> 0.726\n",
    "# # 0.83, 12.5 , 0.76 -> 0.726\n",
    "# # 0.83, 12.5 , 0.7 -> 0.719\n",
    "# # __, 12.5 , 0.76(norm) -> 0.726\n",
    "# # __, 12.5 , 0.77(norm) -> 0.727\n",
    "# # __, 12.5 , 0.78(norm) -> 0.727\n",
    "# # __, 12.5 , 0.79(norm) -> 0.727\n",
    "# # __, 12.5 , 0.80(norm) -> 0.726\n",
    "\n",
    "# text_threshold = 0.79\n",
    "# # distances, indices = model.kneighbors(image_embeddings)\n",
    "# distances, indices = model.search(text_embeddings, KNN)\n",
    "# # print(distances)\n",
    "# for k in tqdm(range(text_embeddings.shape[0])):\n",
    "#     idx = np.where(distances[k,] > text_threshold)[0]\n",
    "#     ids = indices[k,idx]\n",
    "#     posting_ids = test['posting_id'].iloc[ids].values\n",
    "#     preds.append(posting_ids)    \n",
    "\n",
    "# del model, text_embeddings\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "inappropriate-sampling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:22.628711Z",
     "iopub.status.busy": "2021-05-09T02:57:22.627885Z",
     "iopub.status.idle": "2021-05-09T02:57:22.630275Z",
     "shell.execute_reply": "2021-05-09T02:57:22.630678Z"
    },
    "papermill": {
     "duration": 0.080567,
     "end_time": "2021-05-09T02:57:22.630798",
     "exception": false,
     "start_time": "2021-05-09T02:57:22.550231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text_embeddings_np = cupy.asnumpy(text_embeddings)\n",
    "# # print(text_embeddings)\n",
    "# # text_embeddings = text_embeddings/np.max(text_embeddings)\n",
    "# # faiss.normalize_L2(text_embeddings_np)\n",
    "# print(np.max(text_embeddings_np))\n",
    "# model = faiss.IndexFlatIP(text_embeddings_np.shape[1])   # build the index\n",
    "# model.add(text_embeddings_np)    # add vectors to the index\n",
    "# distances, indices = model.search(text_embeddings_np, KNN)\n",
    "# print(distances)\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fitting-shark",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:22.740686Z",
     "iopub.status.busy": "2021-05-09T02:57:22.740013Z",
     "iopub.status.idle": "2021-05-09T02:57:22.742533Z",
     "shell.execute_reply": "2021-05-09T02:57:22.742915Z"
    },
    "papermill": {
     "duration": 0.051664,
     "end_time": "2021-05-09T02:57:22.743041",
     "exception": false,
     "start_time": "2021-05-09T02:57:22.691377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test['preds4'] = preds\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-showcase",
   "metadata": {
    "papermill": {
     "duration": 0.04497,
     "end_time": "2021-05-09T02:57:22.833354",
     "exception": false,
     "start_time": "2021-05-09T02:57:22.788384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# phash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "progressive-forum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:22.952955Z",
     "iopub.status.busy": "2021-05-09T02:57:22.952122Z",
     "iopub.status.idle": "2021-05-09T02:57:22.956304Z",
     "shell.execute_reply": "2021-05-09T02:57:22.955882Z"
    },
    "papermill": {
     "duration": 0.077775,
     "end_time": "2021-05-09T02:57:22.956410",
     "exception": false,
     "start_time": "2021-05-09T02:57:22.878635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>text_upper_pred_multi</th>\n",
       "      <th>text_lower_pred_multi</th>\n",
       "      <th>image_upper_preds</th>\n",
       "      <th>image_lower_preds</th>\n",
       "      <th>image_upper_preds_b0</th>\n",
       "      <th>image_lower_preds_b0</th>\n",
       "      <th>text_upper_pred_tfidf</th>\n",
       "      <th>text_lower_pred_tfidf</th>\n",
       "      <th>preds3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title text_upper_pred_multi  \\\n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...     [test_2255846744]   \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...     [test_3588702337]   \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_multi  image_upper_preds  image_lower_preds  \\\n",
       "0     [test_2255846744]  [test_2255846744]  [test_2255846744]   \n",
       "1     [test_3588702337]  [test_3588702337]  [test_3588702337]   \n",
       "2     [test_4015706929]  [test_4015706929]  [test_4015706929]   \n",
       "\n",
       "  image_upper_preds_b0 image_lower_preds_b0 text_upper_pred_tfidf  \\\n",
       "0    [test_2255846744]    [test_2255846744]     [test_2255846744]   \n",
       "1    [test_3588702337]    [test_3588702337]     [test_3588702337]   \n",
       "2    [test_4015706929]    [test_4015706929]     [test_4015706929]   \n",
       "\n",
       "  text_lower_pred_tfidf             preds3  \n",
       "0     [test_2255846744]  [test_2255846744]  \n",
       "1     [test_3588702337]  [test_3588702337]  \n",
       "2     [test_4015706929]  [test_4015706929]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
    "test['preds3'] = test.image_phash.map(tmp)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-citation",
   "metadata": {
    "papermill": {
     "duration": 0.045576,
     "end_time": "2021-05-09T02:57:23.047878",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.002302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "charming-authority",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:23.147232Z",
     "iopub.status.busy": "2021-05-09T02:57:23.146503Z",
     "iopub.status.idle": "2021-05-09T02:57:23.148912Z",
     "shell.execute_reply": "2021-05-09T02:57:23.149303Z"
    },
    "papermill": {
     "duration": 0.055028,
     "end_time": "2021-05-09T02:57:23.149426",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.094398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def combine_for_sub(row):\n",
    "#     x = np.concatenate([row.preds, row.preds2, row.preds3, row.preds4])\n",
    "#     return ' '.join( np.unique(x) )\n",
    "\n",
    "# def combine_for_sub(row):\n",
    "#     multi = set(row['text_lower_pred_multi'])\n",
    "#     tfidf = set(row['text_lower_pred_tfidf'])\n",
    "#     final_text_preds = list(multi.intersection(tfidf))\n",
    "#     x = np.concatenate([row.preds2, row.preds3, row['text_upper_pred_tfidf'], row['text_upper_pred_multi'],final_text_preds ])\n",
    "#     return ' '.join( np.unique(x) )\n",
    "\n",
    "# def combine_for_sub(row):\n",
    "#     multi = set(row['text_lower_pred_multi'])\n",
    "#     tfidf = set(row['text_lower_pred_tfidf'])\n",
    "#     image_lower = set(row['image_lower_preds'])\n",
    "#     final_text_preds = list(multi.intersection(tfidf))\n",
    "# #     image_multi_preds = list(multi.intersection(image_lower))\n",
    "# #     image_tfidf_preds = list(tfidf.intersection(image_lower))\n",
    "#     x = np.concatenate([row['image_upper_preds'], row.preds3, row['text_upper_pred_tfidf'], \n",
    "#                         row['text_upper_pred_multi'], final_text_preds])# image_multi_preds, image_tfidf_preds ])\n",
    "#     return ' '.join( np.unique(x) )\n",
    "\n",
    "def combine_for_sub(row):\n",
    "    multi = set(row['text_lower_pred_multi'])\n",
    "    tfidf = set(row['text_lower_pred_tfidf'])\n",
    "    image_lower = set(row['image_lower_preds'])\n",
    "    image_lower_b0 = set(row['image_lower_preds_b0'])\n",
    "    final_text_preds = list(multi.intersection(tfidf))\n",
    "    final_image_preds = list(image_lower_b0.intersection(image_lower))\n",
    "    x = np.concatenate([row['image_upper_preds'], row.preds3, row['text_upper_pred_tfidf'], \n",
    "                        row['text_upper_pred_multi'], final_text_preds, final_image_preds,\n",
    "                       row['image_upper_preds_b0']])\n",
    "    return ' '.join( np.unique(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "threatened-medline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:23.245510Z",
     "iopub.status.busy": "2021-05-09T02:57:23.244969Z",
     "iopub.status.idle": "2021-05-09T02:57:23.337312Z",
     "shell.execute_reply": "2021-05-09T02:57:23.336811Z"
    },
    "papermill": {
     "duration": 0.142082,
     "end_time": "2021-05-09T02:57:23.337424",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.195342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['matches'] = test.apply(combine_for_sub,axis=1)\n",
    "test[['posting_id','matches']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "applicable-majority",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T02:57:23.433475Z",
     "iopub.status.busy": "2021-05-09T02:57:23.432737Z",
     "iopub.status.idle": "2021-05-09T02:57:23.435147Z",
     "shell.execute_reply": "2021-05-09T02:57:23.435632Z"
    },
    "papermill": {
     "duration": 0.051959,
     "end_time": "2021-05-09T02:57:23.435752",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.383793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-principle",
   "metadata": {
    "papermill": {
     "duration": 0.046607,
     "end_time": "2021-05-09T02:57:23.531819",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.485212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-flood",
   "metadata": {
    "papermill": {
     "duration": 0.046927,
     "end_time": "2021-05-09T02:57:23.626235",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.579308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-suspension",
   "metadata": {
    "papermill": {
     "duration": 0.046175,
     "end_time": "2021-05-09T02:57:23.719002",
     "exception": false,
     "start_time": "2021-05-09T02:57:23.672827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 167.947736,
   "end_time": "2021-05-09T02:57:26.581323",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-09T02:54:38.633587",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
