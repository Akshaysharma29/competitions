{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T04:31:49.897626Z",
     "iopub.status.busy": "2021-04-03T04:31:49.896848Z",
     "iopub.status.idle": "2021-04-03T04:31:49.899849Z",
     "shell.execute_reply": "2021-04-03T04:31:49.899355Z"
    },
    "papermill": {
     "duration": 0.013892,
     "end_time": "2021-04-03T04:31:49.900012",
     "exception": false,
     "start_time": "2021-04-03T04:31:49.886120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change tokeniztion  taken from link given in -> https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\n",
    "# Increse number of epoch to 40\n",
    "# Increse number of lr to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T04:31:49.917279Z",
     "iopub.status.busy": "2021-04-03T04:31:49.916652Z",
     "iopub.status.idle": "2021-04-03T04:31:55.905027Z",
     "shell.execute_reply": "2021-04-03T04:31:55.904385Z"
    },
    "papermill": {
     "duration": 5.998907,
     "end_time": "2021-04-03T04:31:55.905156",
     "exception": false,
     "start_time": "2021-04-03T04:31:49.906249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import backend as K\n",
    "copyfile(src = \"../input/tokenization/tokenization.py\", dst = \"../working/tokenization.py\")\n",
    "import tokenization\n",
    "# from bert import tokenization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T04:31:55.922469Z",
     "iopub.status.busy": "2021-04-03T04:31:55.921318Z",
     "iopub.status.idle": "2021-04-03T04:31:55.924186Z",
     "shell.execute_reply": "2021-04-03T04:31:55.923776Z"
    },
    "papermill": {
     "duration": 0.012633,
     "end_time": "2021-04-03T04:31:55.924292",
     "exception": false,
     "start_time": "2021-04-03T04:31:55.911659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EPOCHS = 40#25\n",
    "BATCH_SIZE = 32\n",
    "# Seed\n",
    "SEED = 123\n",
    "# Verbosity\n",
    "VERBOSE = 1\n",
    "LR = 0.001#0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T04:31:55.970084Z",
     "iopub.status.busy": "2021-04-03T04:31:55.959323Z",
     "iopub.status.idle": "2021-04-03T12:10:42.359679Z",
     "shell.execute_reply": "2021-04-03T12:10:42.359168Z"
    },
    "papermill": {
     "duration": 27526.429715,
     "end_time": "2021-04-03T12:10:42.359813",
     "exception": false,
     "start_time": "2021-04-03T04:31:55.930098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11014 classes\n",
      "Epoch 1/40\n",
      "718/718 [==============================] - 722s 959ms/step - loss: 19.8816 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.5640 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.56404, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.4979 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4677 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 16.56404 to 16.46775, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.4457 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4730 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.46775\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 16.4258 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4550 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 16.46775 to 16.45497, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 16.4097 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4447 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 16.45497 to 16.44468, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 16.4018 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4366 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 16.44468 to 16.43661, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.4005 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4325 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 16.43661 to 16.43246, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3874 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4058 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 16.43246 to 16.40580, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3775 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4089 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.40580\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3715 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4106 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.40580\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3731 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.4045 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 16.40580 to 16.40454, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3666 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3919 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss improved from 16.40454 to 16.39191, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3377 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3884 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 16.39191 to 16.38845, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3512 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3928 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 16.38845\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 684s 954ms/step - loss: 16.3454 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3881 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 16.38845 to 16.38814, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3299 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3875 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 16.38814 to 16.38747, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3134 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3815 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss improved from 16.38747 to 16.38155, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3300 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3794 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss improved from 16.38155 to 16.37939, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3299 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3896 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 16.37939\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3377 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3775 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss improved from 16.37939 to 16.37754, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3063 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3761 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 16.37754 to 16.37611, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3042 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3677 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 16.37611 to 16.36767, saving model to Bert_123_Epochs_40.h5\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3104 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3786 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 16.36767\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3064 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3719 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 16.36767\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.3061 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3740 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 16.36767\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3010 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3817 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 16.36767\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3010 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3727 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 16.36767\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.2943 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3706 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 16.36767\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.2850 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3743 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 16.36767\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 684s 952ms/step - loss: 16.3022 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3797 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 16.36767\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.3034 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3819 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 16.36767\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 684s 952ms/step - loss: 16.2960 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3774 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 16.36767\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 683s 952ms/step - loss: 16.2871 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3786 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 16.36767\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 683s 952ms/step - loss: 16.2865 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3752 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 16.36767\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.2872 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3751 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 16.36767\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.2892 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3738 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 16.36767\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.2829 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3766 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 16.36767\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 684s 953ms/step - loss: 16.2837 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3755 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 16.36767\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.2875 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3758 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 16.36767\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 16.2805 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.3783 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 16.36767\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 1024)         0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProdu (None, 11014)        11278336    tf.__operators__.getitem[0][0]   \n",
      "                                                                 label[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 11014)        0           head/arc_margin[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 346,420,225\n",
      "Trainable params: 346,420,224\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def read_and_preprocess():\n",
    "    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "    df['matches'] = df['label_group'].map(tmp)\n",
    "    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "    encoder = LabelEncoder()\n",
    "    df['label_group'] = encoder.fit_transform(df['label_group'])\n",
    "    N_CLASSES = df['label_group'].nunique()\n",
    "    print(f'We have {N_CLASSES} classes')\n",
    "    x_train, x_val, y_train, y_val = train_test_split(df[['title']], df['label_group'], shuffle = True, stratify = df['label_group'], random_state = SEED, test_size = 0.33)\n",
    "    return df, N_CLASSES, x_train, x_val, y_train, y_val\n",
    "\n",
    "# Return tokens, masks and segments from a text array or series\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "\n",
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "# Function to build bert model\n",
    "def build_bert_model(bert_layer, max_len = 512):\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = margin([clf_output, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = LR),\n",
    "                  loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "                  metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "def load_train_and_evaluate(x_train, x_val, y_train, y_val):\n",
    "    seed_everything(SEED)\n",
    "    # Load BERT from the Tensorflow Hub\n",
    "    module_url = \"../input/bert-en-uncased-l24-h1024-a16-1\"\n",
    "#     module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tf.gfile = tf.io.gfile #Heck to solve\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "#     tokenizer = tokenization.FullTokenizer(vocab_file=\"../input/bert-vocab/vocab.txt\",do_lower_case=True)\n",
    "    x_train = bert_encode(x_train['title'].values, tokenizer, max_len = 70)\n",
    "    x_val = bert_encode(x_val['title'].values, tokenizer, max_len = 70)\n",
    "    y_train = y_train.values\n",
    "    y_val = y_val.values\n",
    "    # Add targets to train and val\n",
    "    x_train = (x_train[0], x_train[1], x_train[2], y_train)\n",
    "    x_val = (x_val[0], x_val[1], x_val[2], y_val)\n",
    "    bert_model = build_bert_model(bert_layer, max_len = 70)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'Bert_{SEED}_Epochs_{EPOCHS}.h5', \n",
    "                                                    monitor = 'val_loss', \n",
    "                                                    verbose = VERBOSE, \n",
    "                                                    save_best_only = True,\n",
    "                                                    save_weights_only = True, \n",
    "                                                    mode = 'min')\n",
    "    history = bert_model.fit(x_train, y_train,\n",
    "                             validation_data = (x_val, y_val),\n",
    "                             epochs = EPOCHS, \n",
    "                             callbacks = [checkpoint],\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             verbose = VERBOSE)\n",
    "    print(bert_model.summary())\n",
    "    \n",
    "\n",
    "df, N_CLASSES, x_train, x_val, y_train, y_val = read_and_preprocess()\n",
    "load_train_and_evaluate(x_train, x_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.368408,
     "end_time": "2021-04-03T12:10:58.118624",
     "exception": false,
     "start_time": "2021-04-03T12:10:50.750216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.786331,
     "end_time": "2021-04-03T12:11:13.557494",
     "exception": false,
     "start_time": "2021-04-03T12:11:05.771163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.428252,
     "end_time": "2021-04-03T12:11:29.080485",
     "exception": false,
     "start_time": "2021-04-03T12:11:21.652233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.780336,
     "end_time": "2021-04-03T12:11:44.430315",
     "exception": false,
     "start_time": "2021-04-03T12:11:36.649979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 8.097694,
     "end_time": "2021-04-03T12:11:59.845645",
     "exception": false,
     "start_time": "2021-04-03T12:11:51.747951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27628.436282,
   "end_time": "2021-04-03T12:12:13.371794",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-03T04:31:44.935512",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
